{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "import multiprocessing\n",
    "\n",
    "# Numeric computation\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy  # For linear algebra (e.g., Cholesky decomposition)\n",
    "from scipy.spatial import ConvexHull, Delaunay # For sampling and NTR\n",
    "from scipy.optimize import minimize #For projection to the NTR\n",
    "from scipy.spatial.distance import pdist, squareform #For projection to the NTR\n",
    "from scipy.special import roots_hermite # Polynomials of the form e^(-x^2)\n",
    "from scipy.special import roots_hermitenorm # Polynomials of the form e^(-x^(2)/2)\n",
    "\n",
    "# Gaussian Process Regression (GPR)\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import (Kernel, ScaleKernel, MaternKernel, \n",
    "                              GridInterpolationKernel, ProductKernel)\n",
    "from gpytorch.utils.grid import choose_grid_size\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from torch.nn import ModuleList  # Correct import for ModuleList (For SKIP)\n",
    "from gpytorch.variational import (CholeskyVariationalDistribution, \n",
    "                                  VariationalStrategy)  # For SVGP\n",
    "from gpytorch.lazy import MatmulLazyTensor, InterpolatedLazyTensor\n",
    "from gpytorch.settings import fast_pred_var\n",
    "\n",
    "# Optimization\n",
    "import cyipopt\n",
    "from cyipopt import Problem\n",
    "\n",
    "# Quasi-Monte Carlo (QMC) and sparse grids\n",
    "import Tasmanian  # Tasmanian Sparse Grid library\n",
    "from torch.quasirandom import SobolEngine\n",
    "import chaospy as cp\n",
    "\n",
    "# We can save our No-trade-regions (Convex hulls) as .pkl files\n",
    "import pickle\n",
    "    #Save\n",
    "    # with open(\"convex_hulls_array.pkl\", \"wb\") as file:\n",
    "    #     pickle.dump(convex_hulls, file)\n",
    "    #Open\n",
    "    # with open(\"convex_hulls_array.pkl\", \"rb\") as file:\n",
    "    #     loaded_hulls = pickle.load(file)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from cycler import cycler\n",
    "import scienceplots  # For custom style based on science plots\n",
    "\n",
    "# Parallel processing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Logging configuration\n",
    "import logging\n",
    "logging.basicConfig(filename='optimization_log.txt', \n",
    "                    filemode='w',\n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Random seed setup\n",
    "random_seed = 121001\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "multiprocessing.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a custom plotting style and updating scienceplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('science')\n",
    "\n",
    "custom = True\n",
    "if custom:\n",
    "\n",
    "    colors = ['#094a84','#cc2300', \n",
    "                '#009437', '#cc7700',\n",
    "                '#694878', '#383838',\n",
    "                '#7e7e7e']\n",
    "    mpl.rcParams['axes.prop_cycle'] = cycler('color', \n",
    "                                            ['#094a84','#cc2300', \n",
    "                                            '#009437', '#cc7700',\n",
    "                                            '#694878', '#383838',\n",
    "                                            '#7e7e7e'])\n",
    "\n",
    "    mpl.rcParams['figure.facecolor'] = '#ffffff'  # Lightest Snow Storm background\n",
    "    mpl.rcParams['axes.facecolor'] = '#FCFDFE'    # Same light background inside plots\n",
    "    mpl.rcParams['axes.facecolor'] = '#ffffff'    # Same light background inside plots\n",
    "    # mpl.rcParams['axes.facecolor'] = '#3B4252'    # Same light background inside plots\n",
    "    # # mpl.rcParams['axes.facecolor'] = '#ffffff'    # Same light background inside plots\n",
    "    # mpl.rcParams['axes.edgecolor'] = '#3B4252'    # Dark Slate from Polar Night for edges\n",
    "    # mpl.rcParams['axes.labelcolor'] = '#3B4252'   # Text color for labels using Dark Slate\n",
    "    # mpl.rcParams['xtick.color'] = '#3B4252'       # Tick color from Polar Night palette\n",
    "    # mpl.rcParams['ytick.color'] = '#3B4252'\n",
    "\n",
    "    mpl.rcParams['font.size'] = 11\n",
    "    mpl.rcParams['axes.titlesize'] = 11\n",
    "    mpl.rcParams['axes.labelsize'] = 11\n",
    "    mpl.rcParams['legend.fontsize'] = 11\n",
    "\n",
    "    # Remove spines\n",
    "    # mpl.rcParams['axes.spines.top'] = False\n",
    "    # mpl.rcParams['axes.spines.right'] = False\n",
    "    # mpl.rcParams['axes.spines.bottom'] = False\n",
    "    # mpl.rcParams['axes.spines.left'] = False\n",
    "\n",
    "    # Grid settings\n",
    "    mpl.rcParams['axes.grid'] = True\n",
    "    mpl.rcParams['grid.color'] = '#e2e3e4'        # Subtle grid lines using light Snow Storm color\n",
    "    mpl.rcParams['grid.linestyle'] = '--'\n",
    "    mpl.rcParams['grid.linewidth'] = 0.8\n",
    "    mpl.rcParams['axes.titlecolor'] = 'black'\n",
    "    # Ticks\n",
    "    mpl.rcParams['xtick.major.size'] = 5\n",
    "    mpl.rcParams['ytick.major.size'] = 5\n",
    "    mpl.rcParams['xtick.minor.size'] = 3\n",
    "    mpl.rcParams['ytick.minor.size'] = 3\n",
    "    mpl.rcParams['xtick.direction'] = 'in'\n",
    "    mpl.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # Lines and markers\n",
    "    mpl.rcParams['lines.linewidth'] = 3\n",
    "    mpl.rcParams['lines.markersize'] = 6\n",
    "    mpl.rcParams['lines.markeredgewidth'] = 1.5\n",
    "\n",
    "    # Legends\n",
    "    mpl.rcParams['legend.frameon'] = True\n",
    "    mpl.rcParams['legend.loc'] = 'best'\n",
    "\n",
    "    # Subplots and layout\n",
    "    mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "    mpl.rcParams['figure.dpi'] = 600\n",
    "    mpl.rcParams['figure.autolayout'] = True\n",
    "\n",
    "    # Always save as 'tight'\n",
    "    mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "    mpl.rcParams['savefig.pad_inches'] = 0.02\n",
    "\n",
    "    # Save figures to the folder Figures\n",
    "    output_folder = '../Speciale dokumentet/Figures'\n",
    "    os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ISNAN warning probably stems from my bellman (pi_t1 or xt1).\n",
    "Need to ensure these are tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** : Code takes longer for bigger tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dynamic Portfolio Optimization Parameters =====\n",
      "Number of Assets (D): 2\n",
      "Total Years (T): 6\n",
      "Time Step Size (Delta_t): 1.0\n",
      "Number of Time Steps (step size * T): 6\n",
      "Discount Factor (beta): 0.97\n",
      "Relative Risk Aversion (gamma): 3.0\n",
      "Transaction Cost Rate (tau): 0.005\n",
      "Yearly Net Risk-Free Rate (r): 0.030044121348376644\n",
      "Expected Yearly Net Returns (mu): [0.07 0.07]\n",
      "Covariance Matrix (Sigma):\n",
      "[[0.04 0.03]\n",
      " [0.03 0.04]]\n",
      "Include Consumption: False\n",
      "Minimum Consumption (c_min): 0.0\n",
      "Number of State Points (N): 100\n",
      "merton_p: [0.1903 0.1903]\n",
      "Integration Method: quadrature\n",
      "==============================================\n",
      "\n",
      "Time step 5\n",
      "include consumption: False\n",
      "Step 2a: Approximate NTR\n",
      "[[0.1411 0.1412]\n",
      " [0.0611 0.25  ]\n",
      " [0.0044 0.329 ]\n",
      " [0.003  0.3297]\n",
      " [0.0051 0.3277]\n",
      " [0.25   0.0611]\n",
      " [0.19   0.19  ]\n",
      " [0.3276 0.0063]\n",
      " [0.19   0.19  ]\n",
      " [0.1897 0.1897]\n",
      " [0.3285 0.0045]\n",
      " [0.3284 0.0041]]\n",
      "len tilde_omega_t: 12\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point tensor([0.1580, 0.1789], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [ 0. -0.], Omega: [[0.158  0.1789]], bt: 0.6631\n",
      "No optimizer solution found for point tensor([[ 0.3653, -0.0128]], dtype=torch.float64)!\n",
      "No optimizer solution found for point tensor([[ 0.3088, -0.0097]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1667, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2091], Delta: [-0.     -0.2091], Omega: [[0.1667 0.2075]], bt: 0.6248\n",
      "Best solution found. Point tensor([0.5000, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3102 0.2686], Delta: [-0.3102 -0.2686], Omega: [[0.1898 0.1898]], bt: 0.6176\n",
      "Best solution found. Point tensor([0.0000, 0.3750], dtype=torch.float64), Delta+: [0.0016 0.    ], Delta-: [0.     0.0436], Delta: [ 0.0016 -0.0436], Omega: [[0.0016 0.3314]], bt: 0.6668\n",
      "Best solution found. Point tensor([0.2917, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1017 0.2684], Delta: [-0.1017 -0.2684], Omega: [[0.19 0.19]], bt: 0.6182\n",
      "Best solution found. Point tensor([0.1651, 0.2181], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.    0.009], Delta: [-0.    -0.009], Omega: [[0.1651 0.209 ]], bt: 0.6258\n",
      "Best solution found. Point tensor([0.3750, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1853 0.4353], Delta: [-0.1853 -0.4353], Omega: [[0.1897 0.1897]], bt: 0.6175\n",
      "Best solution found. Point tensor([0.1911, 0.1533], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [ 0. -0.], Omega: [[0.1911 0.1533]], bt: 0.6556\n",
      "Best solution found. Point tensor([0.5417, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3519 0.2686], Delta: [-0.3519 -0.2686], Omega: [[0.1897 0.1897]], bt: 0.6174\n",
      "Best solution found. Point tensor([0.2069, 0.1871], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0142 0.    ], Delta: [-0.0142 -0.    ], Omega: [[0.1927 0.1871]], bt: 0.6202\n",
      "Best solution found. Point tensor([0.1667, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.1257], Delta: [-0.     -0.1257], Omega: [[0.1667 0.2077]], bt: 0.625\n",
      "Best solution found. Point tensor([0.2042, 0.1420], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2042 0.142 ]], bt: 0.6538\n",
      "Best solution found. Point tensor([0.0065, 0.3520], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0243], Delta: [ 0.     -0.0243], Omega: [[0.0065 0.3277]], bt: 0.6657\n",
      "Best solution found. Point tensor([0.1667, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3343], Delta: [-0.     -0.3343], Omega: [[0.1667 0.2073]], bt: 0.6243\n",
      "Best solution found. Point tensor([0.2620, 0.0801], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.262  0.0801]], bt: 0.658\n",
      "Best solution found. Point tensor([0.9167, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.6477 0.    ], Delta: [-0.6477  0.    ], Omega: [[0.269  0.0833]], bt: 0.6444\n",
      "Best solution found. Point tensor([0.4583, 0.0000], dtype=torch.float64), Delta+: [0.     0.0016], Delta-: [0.1271 0.    ], Delta: [-0.1271  0.0016], Omega: [[0.3312 0.0016]], bt: 0.6665\n",
      "Best solution found. Point tensor([0.2083, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0181 0.0598], Delta: [-0.0181 -0.0598], Omega: [[0.1902 0.1902]], bt: 0.6191\n",
      "Best solution found. Point tensor([0.2917, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1018 0.3518], Delta: [-0.1018 -0.3518], Omega: [[0.1899 0.1899]], bt: 0.618\n",
      "Best solution found. Point tensor([0.1949, 0.1526], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1949 0.1526]], bt: 0.6525\n",
      "Best solution found. Point tensor([0.1250, 0.0417], dtype=torch.float64), Delta+: [0.0163 0.0996], Delta-: [0. 0.], Delta: [0.0163 0.0996], Omega: [[0.1413 0.1413]], bt: 0.7169\n",
      "Best solution found. Point tensor([0.1768, 0.1703], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.1768 0.1703]], bt: 0.6529\n",
      "Best solution found. Point tensor([0.4583, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2686 0.352 ], Delta: [-0.2686 -0.352 ], Omega: [[0.1897 0.1897]], bt: 0.6175\n",
      "Best solution found. Point tensor([0.1917, 0.1456], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.1917 0.1456]], bt: 0.6627\n",
      "Best solution found. Point tensor([0.5000, 0.0000], dtype=torch.float64), Delta+: [0.     0.0017], Delta-: [0.1689 0.    ], Delta: [-0.1689  0.0017], Omega: [[0.3311 0.0017]], bt: 0.6664\n",
      "Best solution found. Point tensor([0.0833, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2303], Delta: [ 0.     -0.2303], Omega: [[0.0833 0.2697]], bt: 0.6458\n",
      "Best solution found. Point tensor([0.5833, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.345 0.   ], Delta: [-0.345  0.   ], Omega: [[0.2383 0.125 ]], bt: 0.6349\n",
      "Best solution found. Point tensor([0.0000, 0.8333], dtype=torch.float64), Delta+: [0.0057 0.    ], Delta-: [0.     0.5058], Delta: [ 0.0057 -0.5058], Omega: [[0.0057 0.3275]], bt: 0.6642\n",
      "Best solution found. Point tensor([0.2103, 0.1201], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.2103 0.1201]], bt: 0.6696\n",
      "Best solution found. Point tensor([0.3750, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.185  0.1016], Delta: [-0.185  -0.1016], Omega: [[0.19 0.19]], bt: 0.6185\n",
      "Best solution found. Point tensor([0.1917, 0.1381], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1917 0.1381]], bt: 0.6703\n",
      "Best solution found. Point tensor([0.1579, 0.1776], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.1579 0.1776]], bt: 0.6645\n",
      "Best solution found. Point tensor([0.7917, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4912 0.    ], Delta: [-0.4912  0.    ], Omega: [[0.3005 0.0417]], bt: 0.6554\n",
      "Best solution found. Point tensor([0.0901, 0.2385], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.0901 0.2385]], bt: 0.6714\n",
      "Best solution found. Point tensor([0.1667, 0.8333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.6265], Delta: [-0.     -0.6265], Omega: [[0.1667 0.2068]], bt: 0.6234\n",
      "Best solution found. Point tensor([0.0129, 0.3371], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0142], Delta: [ 0.     -0.0142], Omega: [[0.0129 0.3229]], bt: 0.6641\n",
      "Best solution found. Point tensor([0.1088, 0.2172], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1088 0.2172]], bt: 0.674\n",
      "Best solution found. Point tensor([0.2255, 0.1042], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.2255 0.1042]], bt: 0.6703\n",
      "Best solution found. Point tensor([0.0417, 0.0417], dtype=torch.float64), Delta+: [0.0995 0.0996], Delta-: [0. 0.], Delta: [0.0995 0.0996], Omega: [[0.1412 0.1412]], bt: 0.7166\n",
      "Best solution found. Point tensor([0.0417, 0.8333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5329], Delta: [ 0.     -0.5329], Omega: [[0.0417 0.3004]], bt: 0.6553\n",
      "Best solution found. Point tensor([0.1250, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5537], Delta: [-0.     -0.5537], Omega: [[0.125 0.238]], bt: 0.6342\n",
      "Best solution found. Point tensor([0.2500, 0.0417], dtype=torch.float64), Delta+: [0.     0.0195], Delta-: [0. 0.], Delta: [-0.      0.0195], Omega: [[0.25   0.0612]], bt: 0.6888\n",
      "Best solution found. Point tensor([0.7083, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.439 0.   ], Delta: [-0.439  0.   ], Omega: [[0.2693 0.0833]], bt: 0.6451\n",
      "Best solution found. Point tensor([0.1407, 0.1147], dtype=torch.float64), Delta+: [0.0007 0.0266], Delta-: [0. 0.], Delta: [0.0007 0.0266], Omega: [[0.1414 0.1413]], bt: 0.7172\n",
      "Best solution found. Point tensor([0.2917, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1018 0.3935], Delta: [-0.1018 -0.3935], Omega: [[0.1899 0.1898]], bt: 0.6178\n",
      "No optimizer solution found for point tensor([[-0.0493,  0.3566]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1903, 0.2095], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0002 0.0191], Delta: [-0.0002 -0.0191], Omega: [[0.1901 0.1904]], bt: 0.6194\n",
      "Best solution found. Point tensor([0.4583, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1573 0.    ], Delta: [-0.1573  0.    ], Omega: [[0.301  0.0417]], bt: 0.6565\n",
      "Best solution found. Point tensor([0.0833, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5225], Delta: [ 0.     -0.5225], Omega: [[0.0833 0.2692]], bt: 0.6449\n",
      "Best solution found. Point tensor([0.5000, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3101 0.1435], Delta: [-0.3101 -0.1435], Omega: [[0.1899 0.1899]], bt: 0.618\n",
      "Best solution found. Point tensor([0.3333, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1436 0.4769], Delta: [-0.1436 -0.4769], Omega: [[0.1897 0.1897]], bt: 0.6175\n",
      "Best solution found. Point tensor([0.5833, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3935 0.0601], Delta: [-0.3935 -0.0601], Omega: [[0.1899 0.1899]], bt: 0.618\n",
      "Best solution found. Point tensor([0.2124, 0.1284], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.2124 0.1284]], bt: 0.6593\n",
      "Best solution found. Point tensor([0.2124, 0.1171], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2124 0.1171]], bt: 0.6705\n",
      "Best solution found. Point tensor([0.8750, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.606 0.   ], Delta: [-0.606  0.   ], Omega: [[0.269  0.0833]], bt: 0.6446\n",
      "Best solution found. Point tensor([0.1667, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0839], Delta: [-0.     -0.0839], Omega: [[0.1667 0.2077]], bt: 0.6252\n",
      "Best solution found. Point tensor([0.2369, 0.0308], dtype=torch.float64), Delta+: [0.   0.04], Delta-: [0. 0.], Delta: [-0.    0.04], Omega: [[0.2369 0.0708]], bt: 0.6922\n",
      "Best solution found. Point tensor([0.2202, 0.1215], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2202 0.1215]], bt: 0.6583\n",
      "Best solution found. Point tensor([0.7917, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5537 0.    ], Delta: [-0.5537  0.    ], Omega: [[0.238 0.125]], bt: 0.6342\n",
      "Best solution found. Point tensor([0.5833, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3936 0.1852], Delta: [-0.3936 -0.1852], Omega: [[0.1898 0.1898]], bt: 0.6176\n",
      "Best solution found. Point tensor([0.0000, 0.5000], dtype=torch.float64), Delta+: [0.0016 0.    ], Delta-: [0.     0.1689], Delta: [ 0.0016 -0.1689], Omega: [[0.0016 0.3311]], bt: 0.6664\n",
      "Best solution found. Point tensor([0.2583, 0.0535], dtype=torch.float64), Delta+: [0.     0.0018], Delta-: [0. 0.], Delta: [-0.      0.0018], Omega: [[0.2583 0.0554]], bt: 0.6864\n",
      "Best solution found. Point tensor([0.1222, 0.2064], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1222 0.2064]], bt: 0.6714\n",
      "Best solution found. Point tensor([0.2283, 0.1039], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.2283 0.1039]], bt: 0.6678\n",
      "No optimizer solution found for point tensor([[-0.0455,  0.3623]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.0833, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3973], Delta: [ 0.     -0.3973], Omega: [[0.0833 0.2694]], bt: 0.6453\n",
      "Best solution found. Point tensor([0.3198, 0.0277], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0081 0.    ], Delta: [-0.0081  0.    ], Omega: [[0.3117 0.0277]], bt: 0.6605\n",
      "Best solution found. Point tensor([0.1957, 0.1827], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.    ], Delta: [-0.0001 -0.    ], Omega: [[0.1956 0.1827]], bt: 0.6217\n",
      "Best solution found. Point tensor([0.0417, 0.0833], dtype=torch.float64), Delta+: [0.0996 0.0579], Delta-: [0. 0.], Delta: [0.0996 0.0579], Omega: [[0.1412 0.1412]], bt: 0.7167\n",
      "Best solution found. Point tensor([0.0417, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4912], Delta: [ 0.     -0.4912], Omega: [[0.0417 0.3005]], bt: 0.6554\n",
      "Best solution found. Point tensor([0.1667, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0007], Delta: [-0.     -0.0007], Omega: [[0.1667 0.2077]], bt: 0.6256\n",
      "Best solution found. Point tensor([0.2500, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0602 0.4769], Delta: [-0.0602 -0.4769], Omega: [[0.1898 0.1898]], bt: 0.6177\n",
      "Best solution found. Point tensor([0.1280, 0.1315], dtype=torch.float64), Delta+: [0.0133 0.0098], Delta-: [0. 0.], Delta: [0.0133 0.0098], Omega: [[0.1413 0.1413]], bt: 0.7172\n",
      "Best solution found. Point tensor([0.2746, 0.0549], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2746 0.0549]], bt: 0.6705\n",
      "Best solution found. Point tensor([0.1279, 0.2047], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.1279 0.2047]], bt: 0.6674\n",
      "No optimizer solution found for point tensor([[ 0.3482, -0.0306]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.0000, 0.6250], dtype=torch.float64), Delta+: [0.0052 0.    ], Delta-: [0.     0.2968], Delta: [ 0.0052 -0.2968], Omega: [[0.0052 0.3282]], bt: 0.6651\n",
      "Best solution found. Point tensor([0.3750, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1851 0.2685], Delta: [-0.1851 -0.2685], Omega: [[0.1899 0.1899]], bt: 0.618\n",
      "Best solution found. Point tensor([0.0000, 0.1667], dtype=torch.float64), Delta+: [0.1224 0.    ], Delta-: [0. 0.], Delta: [0.1224 0.    ], Omega: [[0.1224 0.1667]], bt: 0.7103\n",
      "Best solution found. Point tensor([0.0000, 0.9583], dtype=torch.float64), Delta+: [0.0018 0.    ], Delta-: [0.     0.6281], Delta: [ 0.0018 -0.6281], Omega: [[0.0018 0.3303]], bt: 0.6648\n",
      "Best solution found. Point tensor([0.0257, 0.3241], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0108], Delta: [ 0.     -0.0108], Omega: [[0.0257 0.3133]], bt: 0.661\n",
      "Best solution found. Point tensor([0.1688, 0.1681], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.1688 0.1681]], bt: 0.6632\n",
      "Best solution found. Point tensor([0.1629, 0.1712], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1629 0.1712]], bt: 0.666\n",
      "Best solution found. Point tensor([0., 0.], dtype=torch.float64), Delta+: [0.1411 0.1411], Delta-: [0. 0.], Delta: [0.1411 0.1411], Omega: [[0.1411 0.1411]], bt: 0.7163\n",
      "Best solution found. Point tensor([0.1921, 0.2195], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0018 0.0292], Delta: [-0.0018 -0.0292], Omega: [[0.1903 0.1903]], bt: 0.6193\n",
      "Best solution found. Point tensor([0.1822, 0.1641], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1822 0.1641]], bt: 0.6537\n",
      "Best solution found. Point tensor([0.0626, 0.2380], dtype=torch.float64), Delta+: [0.0074 0.    ], Delta-: [0. 0.], Delta: [0.0074 0.    ], Omega: [[0.07  0.238]], bt: 0.6919\n",
      "Best solution found. Point tensor([0.6250, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4352 0.1019], Delta: [-0.4352 -0.1019], Omega: [[0.1898 0.1898]], bt: 0.6177\n",
      "Best solution found. Point tensor([0.2143, 0.1825], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0182 0.0001], Delta: [-0.0182 -0.0001], Omega: [[0.1961 0.1824]], bt: 0.6214\n",
      "No optimizer solution found for point tensor([[ 0.3562, -0.0255]], dtype=torch.float64)!\n",
      "No optimizer solution found for point tensor([[ 0.3553, -0.0045]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1250, 0.0000], dtype=torch.float64), Delta+: [0.0164 0.1411], Delta-: [0. 0.], Delta: [0.0164 0.1411], Omega: [[0.1414 0.1411]], bt: 0.7167\n",
      "Best solution found. Point tensor([0.4167, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2267 0.1017], Delta: [-0.2267 -0.1017], Omega: [[0.19 0.19]], bt: 0.6184\n",
      "Best solution found. Point tensor([0.0008, 0.3201], dtype=torch.float64), Delta+: [0.0091 0.    ], Delta-: [0. 0.], Delta: [ 0.0091 -0.    ], Omega: [[0.0099 0.3201]], bt: 0.67\n",
      "Best solution found. Point tensor([0.1824, 0.1493], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1824 0.1493]], bt: 0.6684\n",
      "Best solution found. Point tensor([0.0833, 0.9167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.6477], Delta: [ 0.     -0.6477], Omega: [[0.0833 0.269 ]], bt: 0.6444\n",
      "Best solution found. Point tensor([0.0466, 0.2171], dtype=torch.float64), Delta+: [0.0387 0.    ], Delta-: [0. 0.], Delta: [0.0387 0.    ], Omega: [[0.0853 0.2171]], bt: 0.6974\n",
      "Best solution found. Point tensor([0.1518, 0.1952], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1518 0.1952]], bt: 0.6531\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 4\n",
      "include consumption: False\n",
      "Step 2a: Approximate NTR\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "[[0.165  0.165 ]\n",
      " [0.1026 0.25  ]\n",
      " [0.025  0.3562]\n",
      " [0.0249 0.3557]\n",
      " [0.0251 0.3552]\n",
      " [0.25   0.1026]\n",
      " [0.2142 0.2142]\n",
      " [0.3562 0.025 ]\n",
      " [0.2142 0.2142]\n",
      " [0.214  0.2139]\n",
      " [0.3558 0.0249]\n",
      " [0.3553 0.0249]]\n",
      "len tilde_omega_t: 12\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point tensor([0.2500, 0.3333], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0356 0.1189], Delta: [-0.0356 -0.1188], Omega: [[0.2144 0.2145]], bt: 0.5703\n",
      "Best solution found. Point tensor([0.1678, 0.2144], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1678 0.2144]], bt: 0.6178\n",
      "Best solution found. Point tensor([0.0417, 0.1250], dtype=torch.float64), Delta+: [0.1231 0.0403], Delta-: [0. 0.], Delta: [0.1231 0.0403], Omega: [[0.1648 0.1653]], bt: 0.669\n",
      "Best solution found. Point tensor([0.4167, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2024 0.3695], Delta: [-0.2024 -0.3695], Omega: [[0.2143 0.2138]], bt: 0.569\n",
      "Best solution found. Point tensor([0.3333, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.119  0.4529], Delta: [-0.119  -0.4529], Omega: [[0.2143 0.2138]], bt: 0.569\n",
      "Best solution found. Point tensor([0.3205, 0.0625], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.3205 0.0625]], bt: 0.617\n",
      "Best solution found. Point tensor([0.0833, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.1048], Delta: [ 0.     -0.1048], Omega: [[0.0833 0.3118]], bt: 0.6043\n",
      "Best solution found. Point tensor([0.5833, 0.0000], dtype=torch.float64), Delta+: [0.    0.025], Delta-: [0.2273 0.    ], Delta: [-0.2273  0.025 ], Omega: [[0.3561 0.025 ]], bt: 0.6177\n",
      "Best solution found. Point tensor([0.2083, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5734], Delta: [-0.     -0.5734], Omega: [[0.2083 0.2182]], bt: 0.5706\n",
      "Best solution found. Point tensor([0.2668, 0.1132], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2668 0.1132]], bt: 0.6199\n",
      "No optimizer solution found for point tensor([[-0.0112,  0.4029]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1878, 0.1969], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1878 0.1969]], bt: 0.6153\n",
      "Best solution found. Point tensor([0.1480, 0.1594], dtype=torch.float64), Delta+: [0.017 0.006], Delta-: [0. 0.], Delta: [0.017 0.006], Omega: [[0.1649 0.1655]], bt: 0.6695\n",
      "Best solution found. Point tensor([0.0900, 0.2791], dtype=torch.float64), Delta+: [0.0006 0.0001], Delta-: [0.0001 0.0002], Delta: [ 0.0005 -0.0001], Omega: [[0.0905 0.279 ]], bt: 0.6305\n",
      "Best solution found. Point tensor([0.1667, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2086], Delta: [-0.     -0.2086], Omega: [[0.1667 0.2498]], bt: 0.5825\n",
      "Best solution found. Point tensor([0.2917, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0769 0.0357], Delta: [-0.0769 -0.0357], Omega: [[0.2148 0.2143]], bt: 0.5704\n",
      "Best solution found. Point tensor([0.2580, 0.0894], dtype=torch.float64), Delta+: [0.     0.0073], Delta-: [0. 0.], Delta: [0.     0.0073], Omega: [[0.258  0.0968]], bt: 0.6452\n",
      "Best solution found. Point tensor([0.3797, 0.0072], dtype=torch.float64), Delta+: [0.     0.0178], Delta-: [0.0232 0.    ], Delta: [-0.0232  0.0178], Omega: [[0.3565 0.025 ]], bt: 0.6184\n",
      "Best solution found. Point tensor([0.2108, 0.2226], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0051], Delta: [-0.     -0.0051], Omega: [[0.2107 0.2175]], bt: 0.5717\n",
      "Best solution found. Point tensor([0.3750, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1603 0.0358], Delta: [-0.1603 -0.0358], Omega: [[0.2147 0.2142]], bt: 0.5701\n",
      "Best solution found. Point tensor([0.3671, 0.0333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0169 0.    ], Delta: [-0.0169  0.    ], Omega: [[0.3502 0.0333]], bt: 0.6164\n",
      "Best solution found. Point tensor([0.2125, 0.2296], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0135], Delta: [-0.     -0.0135], Omega: [[0.2125 0.2162]], bt: 0.5712\n",
      "Best solution found. Point tensor([0.2083, 0.3333], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0024 0.1127], Delta: [-0.0023 -0.1126], Omega: [[0.2061 0.2208]], bt: 0.5726\n",
      "Best solution found. Point tensor([0.2318, 0.1697], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.    ], Delta: [-0. -0.], Omega: [[0.2317 0.1697]], bt: 0.5986\n",
      "Best solution found. Point tensor([0.2468, 0.1422], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2468 0.1422]], bt: 0.611\n",
      "Best solution found. Point tensor([0.3828, 0.0051], dtype=torch.float64), Delta+: [0.     0.0199], Delta-: [0.0264 0.    ], Delta: [-0.0264  0.0199], Omega: [[0.3564 0.025 ]], bt: 0.6183\n",
      "Best solution found. Point tensor([0.1870, 0.1879], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.187  0.1879]], bt: 0.6251\n",
      "Best solution found. Point tensor([0.0364, 0.3656], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0177], Delta: [ 0.     -0.0177], Omega: [[0.0364 0.3479]], bt: 0.6156\n",
      "Best solution found. Point tensor([0.3552, 0.0035], dtype=torch.float64), Delta+: [0.     0.0226], Delta-: [0.0001 0.    ], Delta: [-0.0001  0.0226], Omega: [[0.355  0.0261]], bt: 0.6188\n",
      "Best solution found. Point tensor([0.2358, 0.1363], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0001 0.0001], Delta: [-0.      0.0001], Omega: [[0.2357 0.1364]], bt: 0.6279\n",
      "Best solution found. Point tensor([0.9583, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.6155 0.    ], Delta: [-0.6155 -0.    ], Omega: [[0.3428 0.0417]], bt: 0.6125\n",
      "Best solution found. Point tensor([0.0008, 0.4094], dtype=torch.float64), Delta+: [0.0233 0.    ], Delta-: [0.     0.0524], Delta: [ 0.0233 -0.0524], Omega: [[0.0241 0.3571]], bt: 0.6185\n",
      "Best solution found. Point tensor([0.2126, 0.1703], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0002 0.0002], Delta: [-0.0001  0.    ], Omega: [[0.2125 0.1704]], bt: 0.6171\n",
      "Best solution found. Point tensor([0.7500, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4691 0.    ], Delta: [-0.4691 -0.    ], Omega: [[0.2809 0.125 ]], bt: 0.5918\n",
      "Best solution found. Point tensor([0.2083, 0.0833], dtype=torch.float64), Delta+: [0.   0.05], Delta-: [0. 0.], Delta: [0.   0.05], Omega: [[0.2083 0.1333]], bt: 0.6581\n",
      "Best solution found. Point tensor([0.0833, 0.8333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5223], Delta: [ 0.     -0.5223], Omega: [[0.0833 0.311 ]], bt: 0.603\n",
      "Best solution found. Point tensor([0.4583, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1769 0.    ], Delta: [-0.1769  0.    ], Omega: [[0.2814 0.125 ]], bt: 0.5927\n",
      "Best solution found. Point tensor([0.2500, 0.3750], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0359 0.1605], Delta: [-0.0357 -0.1604], Omega: [[0.2143 0.2146]], bt: 0.5702\n",
      "Best solution found. Point tensor([0.0074, 0.3764], dtype=torch.float64), Delta+: [0.0167 0.    ], Delta-: [0.     0.0193], Delta: [ 0.0167 -0.0193], Omega: [[0.0241 0.3571]], bt: 0.6186\n",
      "Best solution found. Point tensor([0.2557, 0.1264], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2557 0.1264]], bt: 0.6179\n",
      "Best solution found. Point tensor([0.1648, 0.2071], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0001 0.0001], Delta: [0.0001 0.    ], Omega: [[0.1649 0.2071]], bt: 0.628\n",
      "Best solution found. Point tensor([0.2183, 0.1536], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0001 0.0001], Delta: [-0.      0.0001], Omega: [[0.2183 0.1537]], bt: 0.6279\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.2917, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0772 0.2442], Delta: [-0.0772 -0.2442], Omega: [[0.2145 0.2141]], bt: 0.5698\n",
      "Best solution found. Point tensor([0.2083, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4482], Delta: [-0.     -0.4482], Omega: [[0.2083 0.2185]], bt: 0.571\n",
      "Best solution found. Point tensor([0.2083, 0.0417], dtype=torch.float64), Delta+: [0.     0.0916], Delta-: [0. 0.], Delta: [0.     0.0916], Omega: [[0.2083 0.1333]], bt: 0.6579\n",
      "Best solution found. Point tensor([0.1667, 0.8333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5842], Delta: [-0.     -0.5842], Omega: [[0.1667 0.2492]], bt: 0.5813\n",
      "Best solution found. Point tensor([0.0023, 0.3670], dtype=torch.float64), Delta+: [0.0218 0.    ], Delta-: [0.     0.0099], Delta: [ 0.0218 -0.0099], Omega: [[0.0241 0.3571]], bt: 0.6186\n",
      "Best solution found. Point tensor([0.1700, 0.2114], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.17   0.2114]], bt: 0.6186\n",
      "Best solution found. Point tensor([1., 0.], dtype=torch.float64), Delta+: [0.     0.0249], Delta-: [0.6447 0.    ], Delta: [-0.6447  0.0249], Omega: [[0.3553 0.0249]], bt: 0.6164\n",
      "Best solution found. Point tensor([0.2917, 0.4167], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0773 0.2025], Delta: [-0.0772 -0.2024], Omega: [[0.2145 0.2143]], bt: 0.5699\n",
      "Best solution found. Point tensor([0.9167, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.6052 0.    ], Delta: [-0.6052  0.    ], Omega: [[0.3115 0.0833]], bt: 0.6022\n",
      "Best solution found. Point tensor([0.1685, 0.2186], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1685 0.2186]], bt: 0.6129\n",
      "Best solution found. Point tensor([0.0795, 0.3051], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [ 0. -0.], Omega: [[0.0795 0.3051]], bt: 0.6153\n",
      "Best solution found. Point tensor([0.1507, 0.2299], dtype=torch.float64), Delta+: [0.0002 0.0001], Delta-: [0.0001 0.0002], Delta: [ 0.0001 -0.0001], Omega: [[0.1508 0.2299]], bt: 0.6194\n",
      "Best solution found. Point tensor([0.5833, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3689 0.1194], Delta: [-0.3689 -0.1194], Omega: [[0.2144 0.2139]], bt: 0.5693\n",
      "Best solution found. Point tensor([0.2231, 0.1697], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2231 0.1697]], bt: 0.6073\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.3750, 0.4167], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.1606 0.2027], Delta: [-0.1605 -0.2026], Omega: [[0.2145 0.2141]], bt: 0.5696\n",
      "Best solution found. Point tensor([0.3750, 0.5417], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.1607 0.3278], Delta: [-0.1606 -0.3277], Omega: [[0.2144 0.214 ]], bt: 0.5692\n",
      "Best solution found. Point tensor([0.1667, 0.0417], dtype=torch.float64), Delta+: [0.0011 0.1216], Delta-: [0. 0.], Delta: [0.0011 0.1216], Omega: [[0.1677 0.1633]], bt: 0.6684\n",
      "No optimizer solution found for point tensor([[     0.3708,     -0.0003]], dtype=torch.float64)!\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.1003, 0.2316], dtype=torch.float64), Delta+: [0.0154 0.    ], Delta-: [0. 0.], Delta: [0.0154 0.    ], Omega: [[0.1156 0.2316]], bt: 0.6527\n",
      "Best solution found. Point tensor([0.2500, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0358 0.5362], Delta: [-0.0358 -0.5361], Omega: [[0.2142 0.2139]], bt: 0.5691\n",
      "Best solution found. Point tensor([0.1819, 0.2088], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1819 0.2088]], bt: 0.6093\n",
      "Best solution found. Point tensor([0.1250, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2188], Delta: [-0.     -0.2188], Omega: [[0.125  0.2812]], bt: 0.5927\n",
      "Best solution found. Point tensor([0.0417, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3233], Delta: [ 0.     -0.3233], Omega: [[0.0417 0.3433]], bt: 0.6134\n",
      "Best solution found. Point tensor([0.1677, 0.2274], dtype=torch.float64), Delta+: [0.0002 0.0001], Delta-: [0.0002 0.0004], Delta: [-0.0001 -0.0002], Omega: [[0.1676 0.2272]], bt: 0.6052\n",
      "Best solution found. Point tensor([0.1050, 0.2193], dtype=torch.float64), Delta+: [0.0197 0.    ], Delta-: [0. 0.], Delta: [0.0197 0.    ], Omega: [[0.1247 0.2193]], bt: 0.6559\n",
      "Best solution found. Point tensor([0.7917, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5732 0.0001], Delta: [-0.5732 -0.    ], Omega: [[0.2185 0.2083]], bt: 0.5704\n",
      "Best solution found. Point tensor([0.1704, 0.2076], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1704 0.2076]], bt: 0.6219\n",
      "Best solution found. Point tensor([0.1808, 0.1990], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.1808 0.199 ]], bt: 0.6202\n",
      "Best solution found. Point tensor([0.2165, 0.2256], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0018 0.0111], Delta: [-0.0018 -0.0111], Omega: [[0.2147 0.2145]], bt: 0.5707\n",
      "Best solution found. Point tensor([0.0833, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2718], Delta: [ 0.     -0.2718], Omega: [[0.0833 0.3115]], bt: 0.6038\n",
      "Best solution found. Point tensor([0.8750, 0.0000], dtype=torch.float64), Delta+: [0.     0.0249], Delta-: [0.5194 0.    ], Delta: [-0.5194  0.0249], Omega: [[0.3556 0.0249]], bt: 0.6168\n",
      "Best solution found. Point tensor([0.0148, 0.3544], dtype=torch.float64), Delta+: [0.0123 0.    ], Delta-: [0.     0.0007], Delta: [ 0.0123 -0.0006], Omega: [[0.0271 0.3537]], bt: 0.6192\n",
      "Best solution found. Point tensor([0.2917, 0.0417], dtype=torch.float64), Delta+: [0.     0.0306], Delta-: [0. 0.], Delta: [0.     0.0306], Omega: [[0.2917 0.0722]], bt: 0.6359\n",
      "Best solution found. Point tensor([0.0417, 0.2917], dtype=torch.float64), Delta+: [0.0305 0.    ], Delta-: [0. 0.], Delta: [0.0305 0.    ], Omega: [[0.0722 0.2917]], bt: 0.636\n",
      "Best solution found. Point tensor([0.2500, 0.0000], dtype=torch.float64), Delta+: [0.    0.103], Delta-: [0. 0.], Delta: [0.    0.103], Omega: [[0.25  0.103]], bt: 0.6465\n",
      "Best solution found. Point tensor([0.1977, 0.2471], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0004 0.0198], Delta: [-0.0003 -0.0198], Omega: [[0.1974 0.2273]], bt: 0.5752\n",
      "Best solution found. Point tensor([0.5833, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3022 0.    ], Delta: [-0.3022  0.    ], Omega: [[0.2812 0.125 ]], bt: 0.5923\n",
      "Best solution found. Point tensor([0.1009, 0.2839], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1009 0.2839]], bt: 0.6152\n",
      "Best solution found. Point tensor([0.1838, 0.2442], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0068], Delta: [-0.     -0.0068], Omega: [[0.1838 0.2374]], bt: 0.5788\n",
      "Best solution found. Point tensor([0.2500, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0356 0.4111], Delta: [-0.0356 -0.4111], Omega: [[0.2144 0.2139]], bt: 0.5694\n",
      "Best solution found. Point tensor([0.7500, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5357 0.0362], Delta: [-0.5357 -0.0362], Omega: [[0.2143 0.2138]], bt: 0.569\n",
      "Best solution found. Point tensor([0.0655, 0.3096], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.0655 0.3096]], bt: 0.6249\n",
      "Best solution found. Point tensor([0.3400, 0.0495], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0019 0.    ], Delta: [-0.0019  0.    ], Omega: [[0.3381 0.0495]], bt: 0.6124\n",
      "Best solution found. Point tensor([0.0000, 0.2917], dtype=torch.float64), Delta+: [0.0722 0.    ], Delta-: [0. 0.], Delta: [ 0.0722 -0.    ], Omega: [[0.0722 0.2916]], bt: 0.6358\n",
      "Best solution found. Point tensor([0.1667, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4172], Delta: [-0.     -0.4172], Omega: [[0.1667 0.2495]], bt: 0.5818\n",
      "Best solution found. Point tensor([0.2315, 0.2300], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0166 0.0156], Delta: [-0.0166 -0.0156], Omega: [[0.2149 0.2144]], bt: 0.5706\n",
      "Best solution found. Point tensor([0.1250, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3441], Delta: [-0.     -0.3441], Omega: [[0.125  0.2809]], bt: 0.5924\n",
      "Best solution found. Point tensor([0.4583, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2438 0.0776], Delta: [-0.2438 -0.0776], Omega: [[0.2146 0.2141]], bt: 0.5698\n",
      "Best solution found. Point tensor([0.0417, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4068], Delta: [ 0.     -0.4068], Omega: [[0.0417 0.3432]], bt: 0.6131\n",
      "Best solution found. Point tensor([0.2917, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0099 0.    ], Delta: [-0.0099  0.    ], Omega: [[0.2817 0.125 ]], bt: 0.5932\n",
      "Best solution found. Point tensor([0.1250, 0.1250], dtype=torch.float64), Delta+: [0.04   0.0405], Delta-: [0. 0.], Delta: [0.04   0.0405], Omega: [[0.165  0.1655]], bt: 0.6692\n",
      "Best solution found. Point tensor([0.7917, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.48 0.  ], Delta: [-0.48 -0.  ], Omega: [[0.3117 0.0833]], bt: 0.6026\n",
      "Best solution found. Point tensor([0.1602, 0.1710], dtype=torch.float64), Delta+: [0.0007 0.    ], Delta-: [0. 0.], Delta: [0.0007 0.    ], Omega: [[0.1609 0.171 ]], bt: 0.6681\n",
      "Best solution found. Point tensor([0.5833, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2398 0.    ], Delta: [-0.2398  0.    ], Omega: [[0.3435 0.0417]], bt: 0.6136\n",
      "Best solution found. Point tensor([0.0000, 0.3750], dtype=torch.float64), Delta+: [0.0241 0.    ], Delta-: [0.     0.0179], Delta: [ 0.0241 -0.0179], Omega: [[0.0241 0.3571]], bt: 0.6186\n",
      "Best solution found. Point tensor([0.3333, 0.4583], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.119  0.2443], Delta: [-0.1189 -0.2442], Omega: [[0.2144 0.2141]], bt: 0.5696\n",
      "Best solution found. Point tensor([0.2115, 0.1886], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [ 0. -0.], Omega: [[0.2115 0.1886]], bt: 0.5999\n",
      "No optimizer solution found for point tensor([[0.2760, 0.0753]], dtype=torch.float64)!\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 3\n",
      "include consumption: False\n",
      "Step 2a: Approximate NTR\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Optimization failed for start 4: 'float' object has no attribute 'backward'\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "[[0.1651 0.1651]\n",
      " [0.1029 0.25  ]\n",
      " [0.0249 0.3567]\n",
      " [0.0249 0.3562]\n",
      " [0.0249 0.3558]\n",
      " [0.25   0.1027]\n",
      " [0.2142 0.2144]\n",
      " [0.3565 0.0249]\n",
      " [0.2143 0.2144]\n",
      " [0.214  0.2141]\n",
      " [0.356  0.0249]\n",
      " [0.3556 0.0248]]\n",
      "len tilde_omega_t: 12\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point tensor([0.1819, 0.1746], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1819 0.1746]], bt: 0.6435\n",
      "Best solution found. Point tensor([0.3750, 0.5000], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.1606 0.286 ], Delta: [-0.1605 -0.2859], Omega: [[0.2145 0.2141]], bt: 0.5692\n",
      "Best solution found. Point tensor([0.0417, 0.2917], dtype=torch.float64), Delta+: [0.0309 0.    ], Delta-: [0. 0.], Delta: [ 0.0309 -0.    ], Omega: [[0.0726 0.2917]], bt: 0.6356\n",
      "Best solution found. Point tensor([0.5417, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3273 0.2444], Delta: [-0.3273 -0.2444], Omega: [[0.2144 0.2139]], bt: 0.5689\n",
      "Best solution found. Point tensor([0.1848, 0.1877], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1848 0.1877]], bt: 0.6275\n",
      "Best solution found. Point tensor([0.2083, 0.0833], dtype=torch.float64), Delta+: [0.     0.0501], Delta-: [0. 0.], Delta: [0.     0.0501], Omega: [[0.2083 0.1334]], bt: 0.658\n",
      "Best solution found. Point tensor([0.4583, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2438 0.2026], Delta: [-0.2438 -0.2026], Omega: [[0.2145 0.214 ]], bt: 0.5692\n",
      "Best solution found. Point tensor([0.2500, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0356 0.4944], Delta: [-0.0356 -0.4944], Omega: [[0.2144 0.214 ]], bt: 0.569\n",
      "Best solution found. Point tensor([0.1369, 0.2392], dtype=torch.float64), Delta+: [0.0002 0.0001], Delta-: [0.0001 0.0002], Delta: [ 0.0001 -0.0001], Omega: [[0.1371 0.2391]], bt: 0.6238\n",
      "Best solution found. Point tensor([0.0967, 0.2563], dtype=torch.float64), Delta+: [0.0027 0.    ], Delta-: [0. 0.], Delta: [0.0027 0.    ], Omega: [[0.0994 0.2563]], bt: 0.6443\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.3732, 0.0258], dtype=torch.float64), Delta+: [0.     0.0026], Delta-: [0.0192 0.    ], Delta: [-0.0191  0.0026], Omega: [[0.354  0.0283]], bt: 0.6175\n",
      "Best solution found. Point tensor([0.0960, 0.2270], dtype=torch.float64), Delta+: [0.0231 0.    ], Delta-: [0. 0.], Delta: [ 0.0231 -0.    ], Omega: [[0.1191 0.227 ]], bt: 0.6538\n",
      "Best solution found. Point tensor([0.1866, 0.2380], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0024], Delta: [-0.     -0.0024], Omega: [[0.1866 0.2355]], bt: 0.5778\n",
      "Best solution found. Point tensor([0.0998, 0.2814], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.0998 0.2814]], bt: 0.6187\n",
      "Best solution found. Point tensor([0.2580, 0.1296], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0004 0.0002], Delta: [-0.0003  0.0001], Omega: [[0.2577 0.1297]], bt: 0.6127\n",
      "Best solution found. Point tensor([0.1228, 0.2538], dtype=torch.float64), Delta+: [0.0002 0.0001], Delta-: [0.0001 0.0002], Delta: [ 0.0001 -0.0001], Omega: [[0.123  0.2537]], bt: 0.6233\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.5833, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3688 0.0776], Delta: [-0.3688 -0.0776], Omega: [[0.2145 0.214 ]], bt: 0.5692\n",
      "Best solution found. Point tensor([0.2500, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0351 0.0356], Delta: [-0.0351 -0.0356], Omega: [[0.2149 0.2144]], bt: 0.5703\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.0496, 0.3441], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0064], Delta: [-0.     -0.0064], Omega: [[0.0496 0.3377]], bt: 0.6127\n",
      "Best solution found. Point tensor([0.3750, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1556 0.    ], Delta: [-0.1556 -0.    ], Omega: [[0.2194 0.2083]], bt: 0.5715\n",
      "Best solution found. Point tensor([0.0000, 0.0833], dtype=torch.float64), Delta+: [0.1649 0.082 ], Delta-: [0. 0.], Delta: [0.1649 0.082 ], Omega: [[0.1649 0.1653]], bt: 0.6686\n",
      "Best solution found. Point tensor([0.2386, 0.0872], dtype=torch.float64), Delta+: [0.     0.0237], Delta-: [0. 0.], Delta: [0.     0.0237], Omega: [[0.2386 0.1109]], bt: 0.6504\n",
      "Best solution found. Point tensor([0.1250, 0.0833], dtype=torch.float64), Delta+: [0.04   0.0821], Delta-: [0. 0.], Delta: [0.04   0.0821], Omega: [[0.165  0.1654]], bt: 0.669\n",
      "Best solution found. Point tensor([0.5417, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2916 0.    ], Delta: [-0.2916 -0.    ], Omega: [[0.2501 0.1667]], bt: 0.5818\n",
      "Best solution found. Point tensor([0.2917, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0768 0.0357], Delta: [-0.0768 -0.0356], Omega: [[0.2149 0.2144]], bt: 0.5702\n",
      "Best solution found. Point tensor([0.2917, 0.4583], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0773 0.2441], Delta: [-0.0772 -0.244 ], Omega: [[0.2145 0.2144]], bt: 0.5696\n",
      "Best solution found. Point tensor([0.2120, 0.1654], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0002 0.0001], Delta: [-0.      0.0001], Omega: [[0.212  0.1655]], bt: 0.6225\n",
      "No optimizer solution found for point tensor([[0.0000, 0.9583]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2516, 0.1397], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0004 0.0002], Delta: [-0.0003  0.    ], Omega: [[0.2513 0.1398]], bt: 0.609\n",
      "Best solution found. Point tensor([0.4583, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2081 0.    ], Delta: [-0.2081 -0.    ], Omega: [[0.2502 0.1667]], bt: 0.5821\n",
      "Best solution found. Point tensor([0.2083, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0008 0.4892], Delta: [-0.0008 -0.4892], Omega: [[0.2076 0.2191]], bt: 0.5709\n",
      "Best solution found. Point tensor([0.2500, 0.0833], dtype=torch.float64), Delta+: [0.     0.0199], Delta-: [0. 0.], Delta: [0.     0.0199], Omega: [[0.25   0.1032]], bt: 0.6467\n",
      "Best solution found. Point tensor([0.2309, 0.1451], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0002 0.0001], Delta: [-0.      0.0001], Omega: [[0.2308 0.1452]], bt: 0.624\n",
      "Best solution found. Point tensor([0.2500, 0.0000], dtype=torch.float64), Delta+: [0.     0.1031], Delta-: [0. 0.], Delta: [0.     0.1031], Omega: [[0.25   0.1031]], bt: 0.6464\n",
      "Best solution found. Point tensor([0.5833, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3688 0.0359], Delta: [-0.3688 -0.0359], Omega: [[0.2146 0.2141]], bt: 0.5693\n",
      "Best solution found. Point tensor([0.1262, 0.2476], dtype=torch.float64), Delta+: [0.0003 0.0001], Delta-: [0.0001 0.0002], Delta: [ 0.0002 -0.0001], Omega: [[0.1263 0.2475]], bt: 0.6261\n",
      "Best solution found. Point tensor([0.5000, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2854 0.0775], Delta: [-0.2854 -0.0775], Omega: [[0.2146 0.2141]], bt: 0.5694\n",
      "Best solution found. Point tensor([0.2917, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0772 0.3693], Delta: [-0.0772 -0.3693], Omega: [[0.2145 0.214 ]], bt: 0.5692\n",
      "No optimizer solution found for point tensor([[0.0057, 0.3690]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2461, 0.1145], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2461 0.1145]], bt: 0.6394\n",
      "Best solution found. Point tensor([0.2487, 0.1308], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2487 0.1308]], bt: 0.6204\n",
      "Best solution found. Point tensor([0.2178, 0.1749], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2178 0.1749]], bt: 0.6073\n",
      "Best solution found. Point tensor([0.3384, 0.0164], dtype=torch.float64), Delta+: [0.     0.0209], Delta-: [0.0001 0.    ], Delta: [-0.0001  0.0209], Omega: [[0.3383 0.0373]], bt: 0.6243\n",
      "Best solution found. Point tensor([0.6667, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3855 0.    ], Delta: [-0.3855  0.    ], Omega: [[0.2811 0.125 ]], bt: 0.5919\n",
      "Best solution found. Point tensor([0.7917, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5108 0.    ], Delta: [-0.5108  0.    ], Omega: [[0.2809 0.125 ]], bt: 0.5915\n",
      "Best solution found. Point tensor([0.2917, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0772 0.4527], Delta: [-0.0772 -0.4527], Omega: [[0.2144 0.2139]], bt: 0.569\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.7083, 0.0000], dtype=torch.float64), Delta+: [0.     0.0249], Delta-: [0.3522 0.    ], Delta: [-0.3522  0.0249], Omega: [[0.3561 0.0249]], bt: 0.6171\n",
      "Best solution found. Point tensor([0.1631, 0.2268], dtype=torch.float64), Delta+: [0.0002 0.0001], Delta-: [0.0002 0.0003], Delta: [-0.     -0.0002], Omega: [[0.1631 0.2267]], bt: 0.6102\n",
      "Best solution found. Point tensor([0.2083, 0.0417], dtype=torch.float64), Delta+: [0.     0.0917], Delta-: [0. 0.], Delta: [0.     0.0917], Omega: [[0.2083 0.1333]], bt: 0.6579\n",
      "Best solution found. Point tensor([0.2083, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2393], Delta: [-0.     -0.2393], Omega: [[0.2083 0.219 ]], bt: 0.5715\n",
      "Best solution found. Point tensor([0.3580, 0.0053], dtype=torch.float64), Delta+: [0.     0.0196], Delta-: [0.0012 0.    ], Delta: [-0.0012  0.0196], Omega: [[0.3567 0.0249]], bt: 0.6182\n",
      "Best solution found. Point tensor([0.2364, 0.1494], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2364 0.1494]], bt: 0.6143\n",
      "Best solution found. Point tensor([0.5000, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2186 0.    ], Delta: [-0.2186  0.    ], Omega: [[0.2814 0.125 ]], bt: 0.5925\n",
      "Best solution found. Point tensor([0.1250, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.    0.469], Delta: [ 0.    -0.469], Omega: [[0.125 0.281]], bt: 0.5917\n",
      "No optimizer solution found for point tensor([[0.0070, 0.3666]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1926, 0.1842], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1926 0.1842]], bt: 0.6232\n",
      "Best solution found. Point tensor([0.2252, 0.2136], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0095 0.    ], Delta: [-0.0095 -0.    ], Omega: [[0.2157 0.2136]], bt: 0.5707\n",
      "Best solution found. Point tensor([0.0000, 0.8750], dtype=torch.float64), Delta+: [0.0238 0.    ], Delta-: [0.     0.5182], Delta: [ 0.0238 -0.5182], Omega: [[0.0238 0.3568]], bt: 0.6166\n",
      "Best solution found. Point tensor([0.1923, 0.1373], dtype=torch.float64), Delta+: [0.     0.0078], Delta-: [0. 0.], Delta: [0.     0.0078], Omega: [[0.1923 0.1451]], bt: 0.6625\n",
      "Best solution found. Point tensor([0.2473, 0.0770], dtype=torch.float64), Delta+: [0.     0.0281], Delta-: [0. 0.], Delta: [0.     0.0281], Omega: [[0.2473 0.1051]], bt: 0.6474\n",
      "Best solution found. Point tensor([0.2184, 0.1754], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2184 0.1754]], bt: 0.6062\n",
      "Best solution found. Point tensor([0.0000, 0.1250], dtype=torch.float64), Delta+: [0.1649 0.0404], Delta-: [0. 0.], Delta: [0.1649 0.0404], Omega: [[0.1649 0.1654]], bt: 0.6687\n",
      "Best solution found. Point tensor([0.3750, 0.4583], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.1606 0.2443], Delta: [-0.1605 -0.2442], Omega: [[0.2145 0.2141]], bt: 0.5693\n",
      "Best solution found. Point tensor([0.2361, 0.1300], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2361 0.13  ]], bt: 0.6339\n",
      "Best solution found. Point tensor([0.0403, 0.3722], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0267], Delta: [ 0.     -0.0267], Omega: [[0.0403 0.3455]], bt: 0.6141\n",
      "Best solution found. Point tensor([0.5833, 0.0000], dtype=torch.float64), Delta+: [0.     0.0249], Delta-: [0.227 0.   ], Delta: [-0.227   0.0249], Omega: [[0.3563 0.0249]], bt: 0.6175\n",
      "Best solution found. Point tensor([0.3550, 0.0175], dtype=torch.float64), Delta+: [0.     0.0086], Delta-: [0. 0.], Delta: [-0.      0.0086], Omega: [[0.355  0.0262]], bt: 0.6187\n",
      "Best solution found. Point tensor([0.5417, 0.3750], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.3272 0.1611], Delta: [-0.3272 -0.161 ], Omega: [[0.2145 0.214 ]], bt: 0.5691\n",
      "Best solution found. Point tensor([0.0833, 0.9167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.6056], Delta: [ 0.     -0.6056], Omega: [[0.0833 0.3111]], bt: 0.6025\n",
      "Best solution found. Point tensor([0.2339, 0.1912], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0019 0.0001], Delta: [-0.0019 -0.0001], Omega: [[0.232  0.1912]], bt: 0.5769\n",
      "Best solution found. Point tensor([0.5000, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2808 0.    ], Delta: [-0.2808 -0.    ], Omega: [[0.2192 0.2083]], bt: 0.5711\n",
      "Best solution found. Point tensor([0.5000, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2499 0.    ], Delta: [-0.2499 -0.    ], Omega: [[0.2501 0.1667]], bt: 0.5819\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.2134, 0.1613], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2134 0.1613]], bt: 0.6254\n",
      "Best solution found. Point tensor([0.2083, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0009 0.5727], Delta: [-0.0009 -0.5726], Omega: [[0.2075 0.219 ]], bt: 0.5706\n",
      "Best solution found. Point tensor([0.1787, 0.2139], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.1787 0.2138]], bt: 0.6074\n",
      "Best solution found. Point tensor([0.4167, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.202  0.1192], Delta: [-0.202  -0.1192], Omega: [[0.2147 0.2142]], bt: 0.5696\n",
      "Best solution found. Point tensor([0.4167, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1664 0.    ], Delta: [-0.1664  0.    ], Omega: [[0.2503 0.1667]], bt: 0.5822\n",
      "Best solution found. Point tensor([0.1250, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5108], Delta: [-0.     -0.5108], Omega: [[0.125  0.2809]], bt: 0.5915\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.1935, 0.2445], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0004 0.0141], Delta: [-0.0003 -0.014 ], Omega: [[0.1932 0.2305]], bt: 0.5762\n",
      "Best solution found. Point tensor([0.2083, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3228], Delta: [-0.     -0.3228], Omega: [[0.2083 0.2189]], bt: 0.5712\n",
      "Best solution found. Point tensor([0.1250, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.1351], Delta: [-0.     -0.1351], Omega: [[0.125  0.2816]], bt: 0.5927\n",
      "Best solution found. Point tensor([0.2100, 0.1770], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.21  0.177]], bt: 0.6131\n",
      "Best solution found. Point tensor([0.1667, 0.0000], dtype=torch.float64), Delta+: [0.0013 0.1631], Delta-: [0. 0.], Delta: [0.0013 0.1631], Omega: [[0.168  0.1631]], bt: 0.6681\n",
      "Best solution found. Point tensor([0.0920, 0.2901], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.092  0.2901]], bt: 0.6179\n",
      "Best solution found. Point tensor([0.7917, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4484 0.    ], Delta: [-0.4484  0.    ], Omega: [[0.3433 0.0417]], bt: 0.6128\n",
      "Best solution found. Point tensor([0.0000, 0.1667], dtype=torch.float64), Delta+: [0.1634 0.0009], Delta-: [0. 0.], Delta: [0.1634 0.0009], Omega: [[0.1634 0.1676]], bt: 0.6683\n",
      "Best solution found. Point tensor([0.2083, 0.0000], dtype=torch.float64), Delta+: [0.     0.1333], Delta-: [0. 0.], Delta: [0.     0.1333], Omega: [[0.2083 0.1333]], bt: 0.6577\n",
      "Best solution found. Point tensor([0.2405, 0.1272], dtype=torch.float64), Delta+: [0.0001 0.0003], Delta-: [0.0001 0.0001], Delta: [-0.      0.0002], Omega: [[0.2405 0.1274]], bt: 0.6321\n",
      "Best solution found. Point tensor([0.2596, 0.1289], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0004 0.0002], Delta: [-0.0003  0.0001], Omega: [[0.2593 0.129 ]], bt: 0.6117\n",
      "No optimizer solution found for point tensor([[0.0114, 0.3779]], dtype=torch.float64)!\n",
      "No optimizer solution found for point tensor([[0.0000, 0.7917]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1935, 0.2390], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0085], Delta: [-0.     -0.0085], Omega: [[0.1935 0.2306]], bt: 0.5759\n",
      "Best solution found. Point tensor([0.3325, 0.0141], dtype=torch.float64), Delta+: [0.     0.0279], Delta-: [0. 0.], Delta: [-0.      0.0279], Omega: [[0.3325 0.042 ]], bt: 0.6254\n",
      "Best solution found. Point tensor([0.1250, 0.0417], dtype=torch.float64), Delta+: [0.04   0.1237], Delta-: [0. 0.], Delta: [0.04   0.1237], Omega: [[0.165  0.1654]], bt: 0.6688\n",
      "Best solution found. Point tensor([0.1066, 0.2869], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0001], Delta: [ 0.     -0.0001], Omega: [[0.1066 0.2869]], bt: 0.6066\n",
      "Best solution found. Point tensor([0.1865, 0.2457], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.   0.01], Delta: [ 0.   -0.01], Omega: [[0.1865 0.2357]], bt: 0.5778\n",
      "Best solution found. Point tensor([0.1922, 0.1359], dtype=torch.float64), Delta+: [0.     0.0093], Delta-: [0. 0.], Delta: [0.     0.0093], Omega: [[0.1922 0.1452]], bt: 0.6625\n",
      "Best solution found. Point tensor([0.7083, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4586 0.    ], Delta: [-0.4586 -0.    ], Omega: [[0.2498 0.1666]], bt: 0.5813\n",
      "No optimizer solution found for point tensor([[ 0.3656, -0.0029]], dtype=torch.float64)!\n",
      "No optimizer solution found for point tensor([[0.0091, 0.3950]], dtype=torch.float64)!\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 2\n",
      "include consumption: False\n",
      "Step 2a: Approximate NTR\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "[[0.165  0.1652]\n",
      " [0.1028 0.2501]\n",
      " [0.0249 0.3565]\n",
      " [0.0249 0.356 ]\n",
      " [0.0249 0.3555]\n",
      " [0.25   0.1028]\n",
      " [0.2142 0.2145]\n",
      " [0.3567 0.0249]\n",
      " [0.2142 0.2145]\n",
      " [0.2139 0.2142]\n",
      " [0.3563 0.0248]\n",
      " [0.3558 0.0248]]\n",
      "len tilde_omega_t: 12\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point tensor([0.4167, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1663 0.    ], Delta: [-0.1663 -0.    ], Omega: [[0.2504 0.1667]], bt: 0.5821\n",
      "Best solution found. Point tensor([0.6667, 0.0000], dtype=torch.float64), Delta+: [0.     0.0248], Delta-: [0.3102 0.    ], Delta: [-0.3102  0.0248], Omega: [[0.3564 0.0248]], bt: 0.617\n",
      "Best solution found. Point tensor([0.2242, 0.2341], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0095 0.0195], Delta: [-0.0095 -0.0195], Omega: [[0.2148 0.2147]], bt: 0.5704\n",
      "Best solution found. Point tensor([0.1764, 0.1950], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1764 0.195 ]], bt: 0.6286\n",
      "Best solution found. Point tensor([0.3792, 0.0114], dtype=torch.float64), Delta+: [0.     0.0135], Delta-: [0.0222 0.    ], Delta: [-0.0222  0.0135], Omega: [[0.357  0.0249]], bt: 0.618\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.0000, 0.4583], dtype=torch.float64), Delta+: [0.0239 0.    ], Delta-: [0.    0.101], Delta: [ 0.0239 -0.101 ], Omega: [[0.0239 0.3574]], bt: 0.6181\n",
      "Best solution found. Point tensor([0.2500, 0.4167], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.036 0.202], Delta: [-0.0359 -0.2018], Omega: [[0.2141 0.2148]], bt: 0.5698\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.2157, 0.2453], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.002  0.0298], Delta: [-0.002  -0.0298], Omega: [[0.2137 0.2155]], bt: 0.5707\n",
      "Best solution found. Point tensor([0.0174, 0.3896], dtype=torch.float64), Delta+: [0.0065 0.    ], Delta-: [0.    0.032], Delta: [ 0.0065 -0.032 ], Omega: [[0.0239 0.3576]], bt: 0.6183\n",
      "Best solution found. Point tensor([0.2158, 0.1753], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2158 0.1753]], bt: 0.6089\n",
      "Best solution found. Point tensor([0.2672, 0.1185], dtype=torch.float64), Delta+: [0.0001 0.0003], Delta-: [0.0004 0.0002], Delta: [-0.0003  0.0002], Omega: [[0.2669 0.1186]], bt: 0.6145\n",
      "Best solution found. Point tensor([0.2917, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.077  0.3276], Delta: [-0.077  -0.3276], Omega: [[0.2146 0.2141]], bt: 0.5692\n",
      "Best solution found. Point tensor([0.2459, 0.1416], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2459 0.1416]], bt: 0.6125\n",
      "No optimizer solution found for point tensor([[ 0.3992, -0.0120]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1824, 0.1824], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1824 0.1824]], bt: 0.6352\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.6667, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4477 0.    ], Delta: [-0.4477 -0.    ], Omega: [[0.219  0.2083]], bt: 0.5705\n",
      "Best solution found. Point tensor([0.0342, 0.3602], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0104], Delta: [ 0.     -0.0104], Omega: [[0.0342 0.3499]], bt: 0.6159\n",
      "Best solution found. Point tensor([0.1667, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2917], Delta: [-0.     -0.2917], Omega: [[0.1667 0.25  ]], bt: 0.5819\n",
      "Best solution found. Point tensor([0.2010, 0.1753], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.201  0.1753]], bt: 0.6237\n",
      "Best solution found. Point tensor([0.2054, 0.2224], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.0012], Delta: [-0.0001 -0.0012], Omega: [[0.2053 0.2213]], bt: 0.5734\n",
      "Best solution found. Point tensor([0.6250, 0.0000], dtype=torch.float64), Delta+: [0.     0.0248], Delta-: [0.2685 0.    ], Delta: [-0.2685  0.0248], Omega: [[0.3565 0.0248]], bt: 0.6172\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.1063, 0.2684], dtype=torch.float64), Delta+: [0.0003 0.0001], Delta-: [0.0001 0.0002], Delta: [ 0.0003 -0.0001], Omega: [[0.1066 0.2683]], bt: 0.6251\n",
      "Best solution found. Point tensor([0.1250, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2185], Delta: [-0.     -0.2185], Omega: [[0.125  0.2815]], bt: 0.5924\n",
      "Best solution found. Point tensor([0.6667, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3854 0.    ], Delta: [-0.3854  0.    ], Omega: [[0.2813 0.125 ]], bt: 0.5918\n",
      "Best solution found. Point tensor([0.3333, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0828 0.    ], Delta: [-0.0828 -0.    ], Omega: [[0.2505 0.1667]], bt: 0.5824\n",
      "Best solution found. Point tensor([0.2500, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0352 0.0772], Delta: [-0.0351 -0.0772], Omega: [[0.2149 0.2145]], bt: 0.5701\n",
      "Best solution found. Point tensor([0.2424, 0.1050], dtype=torch.float64), Delta+: [0.     0.0034], Delta-: [0. 0.], Delta: [0.     0.0034], Omega: [[0.2424 0.1084]], bt: 0.6491\n",
      "Best solution found. Point tensor([0.0826, 0.2940], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.0826 0.294 ]], bt: 0.6233\n",
      "No optimizer solution found for point tensor([[ 0.3802, -0.0078]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.0833, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.1464], Delta: [ 0.     -0.1464], Omega: [[0.0833 0.3119]], bt: 0.604\n",
      "Best solution found. Point tensor([0.1828, 0.1986], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1828 0.1986]], bt: 0.6186\n",
      "Best solution found. Point tensor([0.1667, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.1247], Delta: [-0.     -0.1247], Omega: [[0.1666 0.2503]], bt: 0.5824\n",
      "Best solution found. Point tensor([0.2083, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.2809], Delta: [-0.0001 -0.2809], Omega: [[0.2082 0.2191]], bt: 0.5713\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.0833, 0.2500], dtype=torch.float64), Delta+: [0.0194 0.    ], Delta-: [0. 0.], Delta: [0.0194 0.    ], Omega: [[0.1027 0.25  ]], bt: 0.6472\n",
      "Best solution found. Point tensor([0.2231, 0.1550], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0002 0.0001], Delta: [-0.0001  0.0001], Omega: [[0.2231 0.1551]], bt: 0.6218\n",
      "Best solution found. Point tensor([0.6250, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.406 0.   ], Delta: [-0.406 -0.   ], Omega: [[0.219  0.2083]], bt: 0.5706\n",
      "Best solution found. Point tensor([0.1828, 0.1969], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.1828 0.1969]], bt: 0.6204\n",
      "Best solution found. Point tensor([0.1850, 0.2060], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.185 0.206]], bt: 0.609\n",
      "Best solution found. Point tensor([0.1778, 0.2118], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1778 0.2118]], bt: 0.6104\n",
      "Best solution found. Point tensor([0.1464, 0.1664], dtype=torch.float64), Delta+: [0.0179 0.0001], Delta-: [0. 0.], Delta: [0.0179 0.0001], Omega: [[0.1643 0.1665]], bt: 0.6691\n",
      "Best solution found. Point tensor([0.0057, 0.3518], dtype=torch.float64), Delta+: [0.0229 0.    ], Delta-: [0. 0.], Delta: [ 0.0229 -0.    ], Omega: [[0.0286 0.3518]], bt: 0.6195\n",
      "Best solution found. Point tensor([0.3333, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.119  0.4109], Delta: [-0.119  -0.4109], Omega: [[0.2143 0.2141]], bt: 0.5689\n",
      "Best solution found. Point tensor([0.5417, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2915 0.    ], Delta: [-0.2915 -0.    ], Omega: [[0.2502 0.1667]], bt: 0.5817\n",
      "Best solution found. Point tensor([0.4583, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.239 0.   ], Delta: [-0.239 -0.   ], Omega: [[0.2193 0.2083]], bt: 0.5711\n",
      "Best solution found. Point tensor([0.8333, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5837 0.    ], Delta: [-0.5837  0.    ], Omega: [[0.2496 0.1667]], bt: 0.5808\n",
      "Best solution found. Point tensor([0.0833, 0.8333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5221], Delta: [ 0.     -0.5221], Omega: [[0.0834 0.3112]], bt: 0.6028\n",
      "Best solution found. Point tensor([0.0965, 0.2142], dtype=torch.float64), Delta+: [0.032 0.   ], Delta-: [0. 0.], Delta: [0.032 0.   ], Omega: [[0.1285 0.2142]], bt: 0.6571\n",
      "Best solution found. Point tensor([0.3333, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1189 0.4527], Delta: [-0.1189 -0.4527], Omega: [[0.2144 0.214 ]], bt: 0.5688\n",
      "Best solution found. Point tensor([0.2404, 0.0898], dtype=torch.float64), Delta+: [0.     0.0197], Delta-: [0. 0.], Delta: [0.     0.0197], Omega: [[0.2404 0.1095]], bt: 0.65\n",
      "Best solution found. Point tensor([0.2917, 0.0417], dtype=torch.float64), Delta+: [0.     0.0308], Delta-: [0. 0.], Delta: [0.     0.0308], Omega: [[0.2917 0.0724]], bt: 0.6358\n",
      "Best solution found. Point tensor([0.1250, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3855], Delta: [-0.     -0.3855], Omega: [[0.125  0.2812]], bt: 0.5919\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.0018, 0.3614], dtype=torch.float64), Delta+: [0.0221 0.    ], Delta-: [0.     0.0039], Delta: [ 0.0221 -0.0039], Omega: [[0.0239 0.3576]], bt: 0.6184\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.1190, 0.2626], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0001], Delta: [ 0. -0.], Omega: [[0.119  0.2626]], bt: 0.6184\n",
      "Best solution found. Point tensor([0.1250, 0.1667], dtype=torch.float64), Delta+: [0.0385 0.001 ], Delta-: [0. 0.], Delta: [0.0385 0.001 ], Omega: [[0.1635 0.1677]], bt: 0.6687\n",
      "Best solution found. Point tensor([0.0833, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0629], Delta: [-0.     -0.0629], Omega: [[0.0833 0.3121]], bt: 0.6043\n",
      "Best solution found. Point tensor([0.1996, 0.1780], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1996 0.178 ]], bt: 0.6224\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.1250, 0.0833], dtype=torch.float64), Delta+: [0.0399 0.0822], Delta-: [0. 0.], Delta: [0.0399 0.0822], Omega: [[0.1649 0.1655]], bt: 0.669\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.2917, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.077 0.119], Delta: [-0.0769 -0.1189], Omega: [[0.2148 0.2144]], bt: 0.5699\n",
      "Best solution found. Point tensor([0.1667, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3752], Delta: [ 0.     -0.3752], Omega: [[0.1667 0.2498]], bt: 0.5816\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.2126, 0.2536], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0039 0.0349], Delta: [-0.0038 -0.0347], Omega: [[0.2088 0.2189]], bt: 0.5721\n",
      "Best solution found. Point tensor([0.2365, 0.1503], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2365 0.1503]], bt: 0.6132\n",
      "Best solution found. Point tensor([0.2083, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0008 0.1552], Delta: [-0.0008 -0.1552], Omega: [[0.2076 0.2198]], bt: 0.5718\n",
      "Best solution found. Point tensor([0.2803, 0.0986], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.2803 0.0986]], bt: 0.6211\n",
      "Best solution found. Point tensor([0.2917, 0.2500], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0767 0.0359], Delta: [-0.0766 -0.0358], Omega: [[0.2151 0.2142]], bt: 0.5702\n",
      "Best solution found. Point tensor([0.2175, 0.1491], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2175 0.1491]], bt: 0.6335\n",
      "Best solution found. Point tensor([0.1250, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.1351], Delta: [-0.     -0.1351], Omega: [[0.125  0.2816]], bt: 0.5927\n",
      "Best solution found. Point tensor([0.0000, 0.9583], dtype=torch.float64), Delta+: [0.0239 0.    ], Delta-: [0.     0.6019], Delta: [ 0.0239 -0.6019], Omega: [[0.0239 0.3565]], bt: 0.6165\n",
      "Best solution found. Point tensor([0.1667, 0.2197], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1667 0.2197]], bt: 0.6135\n",
      "Best solution found. Point tensor([0.8750, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5632 0.    ], Delta: [-0.5632  0.    ], Omega: [[0.3118 0.0833]], bt: 0.602\n",
      "Best solution found. Point tensor([0.6250, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4106 0.161 ], Delta: [-0.4106 -0.161 ], Omega: [[0.2144 0.214 ]], bt: 0.5688\n",
      "Best solution found. Point tensor([0.3750, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0623 0.    ], Delta: [-0.0623  0.    ], Omega: [[0.3127 0.0833]], bt: 0.6036\n",
      "Best solution found. Point tensor([0.1250, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.1768], Delta: [ 0.     -0.1768], Omega: [[0.125  0.2815]], bt: 0.5926\n",
      "Best solution found. Point tensor([0.1216, 0.2481], dtype=torch.float64), Delta+: [0.0003 0.0001], Delta-: [0.0001 0.0002], Delta: [ 0.0002 -0.    ], Omega: [[0.1218 0.2481]], bt: 0.6301\n",
      "Best solution found. Point tensor([0.1250, 0.5417], dtype=torch.float64), Delta+: [0.0002 0.0001], Delta-: [0.0002 0.2604], Delta: [-0.     -0.2602], Omega: [[0.125  0.2814]], bt: 0.5923\n",
      "Best solution found. Point tensor([0.3750, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1605 0.3276], Delta: [-0.1605 -0.3276], Omega: [[0.2145 0.2141]], bt: 0.569\n",
      "Best solution found. Point tensor([0.2322, 0.2183], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0172 0.0037], Delta: [-0.0172 -0.0037], Omega: [[0.215  0.2146]], bt: 0.5703\n",
      "Best solution found. Point tensor([0.0833, 0.0417], dtype=torch.float64), Delta+: [0.0815 0.1238], Delta-: [0. 0.], Delta: [0.0815 0.1238], Omega: [[0.1649 0.1654]], bt: 0.6687\n",
      "Best solution found. Point tensor([0.3333, 0.0000], dtype=torch.float64), Delta+: [0.     0.0414], Delta-: [0. 0.], Delta: [-0.      0.0414], Omega: [[0.3333 0.0414]], bt: 0.6251\n",
      "Best solution found. Point tensor([0.3760, 0.0047], dtype=torch.float64), Delta+: [0.     0.0202], Delta-: [0.019 0.   ], Delta: [-0.019   0.0202], Omega: [[0.357  0.0249]], bt: 0.618\n",
      "Best solution found. Point tensor([0.4583, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1142 0.    ], Delta: [-0.1142  0.    ], Omega: [[0.3441 0.0417]], bt: 0.6136\n",
      "Best solution found. Point tensor([0.1567, 0.1567], dtype=torch.float64), Delta+: [0.0084 0.009 ], Delta-: [0. 0.], Delta: [0.0084 0.009 ], Omega: [[0.1651 0.1656]], bt: 0.6691\n",
      "Best solution found. Point tensor([0.8333, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5215 0.    ], Delta: [-0.5215  0.    ], Omega: [[0.3119 0.0833]], bt: 0.6022\n",
      "Best solution found. Point tensor([0.1707, 0.2120], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1707 0.212 ]], bt: 0.6173\n",
      "No optimizer solution found for point tensor([[ 0.3854, -0.0224]], dtype=torch.float64)!\n",
      "No optimizer solution found for point tensor([[ 0.3709, -0.0053]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1911, 0.2368], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0044], Delta: [-0.     -0.0044], Omega: [[0.1911 0.2324]], bt: 0.5765\n",
      "Best solution found. Point tensor([0.1667, 0.0833], dtype=torch.float64), Delta+: [0.0008 0.0804], Delta-: [0. 0.], Delta: [0.0008 0.0804], Omega: [[0.1675 0.1637]], bt: 0.6684\n",
      "Best solution found. Point tensor([0.0929, 0.2595], dtype=torch.float64), Delta+: [0.004 0.   ], Delta-: [0. 0.], Delta: [0.004 0.   ], Omega: [[0.0969 0.2595]], bt: 0.6435\n",
      "Best solution found. Point tensor([0.4583, 0.3750], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.2438 0.161 ], Delta: [-0.2437 -0.1609], Omega: [[0.2146 0.2141]], bt: 0.5692\n",
      "Best solution found. Point tensor([0.0000, 0.0833], dtype=torch.float64), Delta+: [0.1648 0.0821], Delta-: [0. 0.], Delta: [0.1648 0.0821], Omega: [[0.1648 0.1654]], bt: 0.6685\n",
      "Best solution found. Point tensor([0.1723, 0.2164], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1723 0.2164]], bt: 0.6113\n",
      "Best solution found. Point tensor([0.2350, 0.1427], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0002 0.0001], Delta: [-0.0001  0.0001], Omega: [[0.2349 0.1428]], bt: 0.6223\n",
      "Best solution found. Point tensor([0.1250, 0.8750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5942], Delta: [-0.     -0.5942], Omega: [[0.125  0.2808]], bt: 0.5913\n",
      "Best solution found. Point tensor([0.4583, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2436 0.0358], Delta: [-0.2436 -0.0357], Omega: [[0.2147 0.2143]], bt: 0.5696\n",
      "Best solution found. Point tensor([0.4167, 0.4583], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.2023 0.2443], Delta: [-0.2021 -0.2442], Omega: [[0.2145 0.2141]], bt: 0.5691\n",
      "Best solution found. Point tensor([0.1391, 0.2491], dtype=torch.float64), Delta+: [0.0002 0.0001], Delta-: [0.0002 0.0004], Delta: [ 0.0001 -0.0003], Omega: [[0.1391 0.2489]], bt: 0.612\n",
      "Best solution found. Point tensor([0.1228, 0.2657], dtype=torch.float64), Delta+: [0.0003 0.0001], Delta-: [0.0002 0.0005], Delta: [ 0.0001 -0.0004], Omega: [[0.1229 0.2653]], bt: 0.6118\n",
      "Best solution found. Point tensor([0.0286, 0.3384], dtype=torch.float64), Delta+: [0.0093 0.    ], Delta-: [0.     0.0001], Delta: [ 0.0093 -0.0001], Omega: [[0.0379 0.3383]], bt: 0.6238\n",
      "Best solution found. Point tensor([0.0216, 0.3348], dtype=torch.float64), Delta+: [0.0181 0.    ], Delta-: [0. 0.], Delta: [ 0.0181 -0.    ], Omega: [[0.0397 0.3348]], bt: 0.6254\n",
      "Best solution found. Point tensor([0.5833, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2394 0.    ], Delta: [-0.2394  0.    ], Omega: [[0.3439 0.0417]], bt: 0.6132\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 1\n",
      "include consumption: False\n",
      "Step 2a: Approximate NTR\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "[[0.1651 0.1651]\n",
      " [0.1029 0.25  ]\n",
      " [0.025  0.3568]\n",
      " [0.0249 0.3563]\n",
      " [0.0249 0.3559]\n",
      " [0.25   0.1027]\n",
      " [0.2142 0.2144]\n",
      " [0.3566 0.0249]\n",
      " [0.2144 0.2143]\n",
      " [0.214  0.2142]\n",
      " [0.3561 0.0248]\n",
      " [0.3557 0.0248]]\n",
      "len tilde_omega_t: 12\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point tensor([0.2500, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0353 0.4527], Delta: [-0.0353 -0.4527], Omega: [[0.2147 0.214 ]], bt: 0.5689\n",
      "Best solution found. Point tensor([0.0417, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3644], Delta: [-0.     -0.3644], Omega: [[0.0417 0.3439]], bt: 0.6126\n",
      "Best solution found. Point tensor([0.2324, 0.1492], dtype=torch.float64), Delta+: [0.0002 0.0003], Delta-: [0.0003 0.0002], Delta: [-0.0001  0.0001], Omega: [[0.2323 0.1493]], bt: 0.6184\n",
      "Best solution found. Point tensor([0.1183, 0.2658], dtype=torch.float64), Delta+: [0.0003 0.0001], Delta-: [0.0001 0.0004], Delta: [ 0.0001 -0.0002], Omega: [[0.1184 0.2656]], bt: 0.616\n",
      "Best solution found. Point tensor([0.1862, 0.2000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1862 0.2   ]], bt: 0.6138\n",
      "Best solution found. Point tensor([0.3656, 0.0384], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.019 0.   ], Delta: [-0.019  0.   ], Omega: [[0.3467 0.0384]], bt: 0.6149\n",
      "Best solution found. Point tensor([0.6667, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3231 0.    ], Delta: [-0.3231  0.    ], Omega: [[0.3436 0.0417]], bt: 0.6131\n",
      "Best solution found. Point tensor([0.3923, 0.0129], dtype=torch.float64), Delta+: [0.     0.0119], Delta-: [0.0355 0.    ], Delta: [-0.0355  0.0119], Omega: [[0.3568 0.0249]], bt: 0.6181\n",
      "Best solution found. Point tensor([0.1910, 0.1980], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [ 0. -0.], Omega: [[0.191 0.198]], bt: 0.611\n",
      "Best solution found. Point tensor([0.1600, 0.1573], dtype=torch.float64), Delta+: [0.0049 0.0084], Delta-: [0. 0.], Delta: [0.0049 0.0084], Omega: [[0.1649 0.1657]], bt: 0.6694\n",
      "Best solution found. Point tensor([0.3731, 0.0080], dtype=torch.float64), Delta+: [0.     0.0169], Delta-: [0.0162 0.    ], Delta: [-0.0162  0.0169], Omega: [[0.3569 0.0248]], bt: 0.6181\n",
      "Best solution found. Point tensor([0.1900, 0.1375], dtype=torch.float64), Delta+: [0.     0.0092], Delta-: [0. 0.], Delta: [0.     0.0092], Omega: [[0.19   0.1467]], bt: 0.6632\n",
      "Best solution found. Point tensor([0.3654, 0.0243], dtype=torch.float64), Delta+: [0.     0.0009], Delta-: [0.0088 0.    ], Delta: [-0.0088  0.0009], Omega: [[0.3566 0.0252]], bt: 0.6181\n",
      "Best solution found. Point tensor([0.5000, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2855 0.2861], Delta: [-0.2854 -0.2861], Omega: [[0.2146 0.2139]], bt: 0.5686\n",
      "Best solution found. Point tensor([0.2000, 0.1887], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.2    0.1887]], bt: 0.6113\n",
      "Best solution found. Point tensor([0.2917, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.077  0.3693], Delta: [-0.077  -0.3692], Omega: [[0.2147 0.2141]], bt: 0.569\n",
      "Best solution found. Point tensor([0.1250, 0.1250], dtype=torch.float64), Delta+: [0.0399 0.0407], Delta-: [0. 0.], Delta: [0.0399 0.0406], Omega: [[0.1649 0.1656]], bt: 0.6691\n",
      "Best solution found. Point tensor([0.7083, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3959 0.    ], Delta: [-0.3959  0.    ], Omega: [[0.3124 0.0833]], bt: 0.6023\n",
      "Best solution found. Point tensor([0.2265, 0.1726], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.    ], Delta: [-0. -0.], Omega: [[0.2265 0.1726]], bt: 0.6009\n",
      "Best solution found. Point tensor([0.2500, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0353 0.2858], Delta: [-0.0352 -0.2857], Omega: [[0.2148 0.2143]], bt: 0.5694\n",
      "Best solution found. Point tensor([0.2917, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0718 0.    ], Delta: [-0.0718 -0.    ], Omega: [[0.2198 0.2083]], bt: 0.5715\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.3333, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1187 0.411 ], Delta: [-0.1187 -0.411 ], Omega: [[0.2146 0.214 ]], bt: 0.5688\n",
      "Best solution found. Point tensor([0.2047, 0.2394], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0002 0.0171], Delta: [-0.0002 -0.0171], Omega: [[0.2045 0.2223]], bt: 0.5731\n",
      "Best solution found. Point tensor([0.0000, 0.0833], dtype=torch.float64), Delta+: [0.1647 0.0821], Delta-: [0. 0.], Delta: [0.1647 0.0821], Omega: [[0.1647 0.1655]], bt: 0.6686\n",
      "Best solution found. Point tensor([0.1667, 0.0417], dtype=torch.float64), Delta+: [0.0047 0.1196], Delta-: [0.0002 0.0002], Delta: [0.0045 0.1194], Omega: [[0.1712 0.1611]], bt: 0.6672\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.2194, 0.2449], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0044 0.0303], Delta: [-0.0044 -0.0303], Omega: [[0.215  0.2146]], bt: 0.5702\n",
      "Best solution found. Point tensor([0.1764, 0.2103], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0002 0.0002], Delta: [-0.     -0.0001], Omega: [[0.1764 0.2102]], bt: 0.6134\n",
      "Best solution found. Point tensor([0.1989, 0.2348], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0007 0.0084], Delta: [-0.0006 -0.0083], Omega: [[0.1983 0.2265]], bt: 0.5752\n",
      "No optimizer solution found for point tensor([[0.0000, 0.8333]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.5417, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.327  0.1193], Delta: [-0.327  -0.1193], Omega: [[0.2147 0.214 ]], bt: 0.569\n",
      "Best solution found. Point tensor([0.7500, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4066 0.    ], Delta: [-0.4066  0.    ], Omega: [[0.3434 0.0417]], bt: 0.6129\n",
      "Best solution found. Point tensor([0.1139, 0.2687], dtype=torch.float64), Delta+: [0.0003 0.0001], Delta-: [0.0001 0.0003], Delta: [ 0.0002 -0.0002], Omega: [[0.1141 0.2685]], bt: 0.6174\n",
      "No optimizer solution found for point tensor([[0.0000, 0.7917]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.4583, 0.4583], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.2438 0.2444], Delta: [-0.2437 -0.2443], Omega: [[0.2147 0.214 ]], bt: 0.5688\n",
      "Best solution found. Point tensor([0.2917, 0.3750], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.077  0.1607], Delta: [-0.0769 -0.1606], Omega: [[0.2148 0.2144]], bt: 0.5696\n",
      "Best solution found. Point tensor([0.7083, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3648 0.    ], Delta: [-0.3648  0.    ], Omega: [[0.3435 0.0417]], bt: 0.613\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.0276, 0.3742], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0191], Delta: [ 0.     -0.0191], Omega: [[0.0276 0.3551]], bt: 0.6172\n",
      "Best solution found. Point tensor([0.1674, 0.2102], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0001 0.0002], Delta: [ 0.0001 -0.    ], Omega: [[0.1675 0.2102]], bt: 0.6223\n",
      "Best solution found. Point tensor([0.7083, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4585 0.    ], Delta: [-0.4585  0.    ], Omega: [[0.2499 0.1667]], bt: 0.5812\n",
      "Best solution found. Point tensor([0.2527, 0.1280], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0003 0.0001], Delta: [-0.0002  0.0001], Omega: [[0.2525 0.1281]], bt: 0.6194\n",
      "Best solution found. Point tensor([0.5000, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2806 0.    ], Delta: [-0.2806 -0.    ], Omega: [[0.2194 0.2083]], bt: 0.5708\n",
      "Best solution found. Point tensor([0.6250, 0.0000], dtype=torch.float64), Delta+: [0.     0.0248], Delta-: [0.2686 0.    ], Delta: [-0.2686  0.0248], Omega: [[0.3564 0.0248]], bt: 0.6173\n",
      "Best solution found. Point tensor([0.2500, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0354 0.5361], Delta: [-0.0354 -0.5361], Omega: [[0.2146 0.2139]], bt: 0.5687\n",
      "Best solution found. Point tensor([0.6667, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.452 0.036], Delta: [-0.452 -0.036], Omega: [[0.2147 0.214 ]], bt: 0.5689\n",
      "Best solution found. Point tensor([0.2479, 0.0673], dtype=torch.float64), Delta+: [0.0001 0.0377], Delta-: [0.0001 0.    ], Delta: [0.     0.0376], Omega: [[0.2479 0.1049]], bt: 0.647\n",
      "Best solution found. Point tensor([0.2252, 0.1539], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.2252 0.1539]], bt: 0.6209\n",
      "No optimizer solution found for point tensor([[0.5000, 0.1667]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.0988, 0.2169], dtype=torch.float64), Delta+: [0.0275 0.    ], Delta-: [0. 0.], Delta: [0.0275 0.    ], Omega: [[0.1263 0.2169]], bt: 0.6566\n",
      "Best solution found. Point tensor([0.2040, 0.1868], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.204  0.1868]], bt: 0.6091\n",
      "Best solution found. Point tensor([0.2053, 0.1778], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0002 0.0002], Delta: [-0.0001  0.    ], Omega: [[0.2053 0.1779]], bt: 0.6169\n",
      "Best solution found. Point tensor([0.3333, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1189 0.4527], Delta: [-0.1188 -0.4527], Omega: [[0.2145 0.214 ]], bt: 0.5686\n",
      "No optimizer solution found for point tensor([[0.0013, 0.3655]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2356, 0.1447], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0002 0.0001], Delta: [-0.0001  0.0001], Omega: [[0.2355 0.1448]], bt: 0.6197\n",
      "Best solution found. Point tensor([0.0417, 0.8333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4897], Delta: [ 0.     -0.4897], Omega: [[0.0417 0.3436]], bt: 0.6123\n",
      "Best solution found. Point tensor([0.5417, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2601 0.    ], Delta: [-0.2601  0.    ], Omega: [[0.2816 0.125 ]], bt: 0.5921\n",
      "Best solution found. Point tensor([0.2328, 0.1565], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2328 0.1565]], bt: 0.6106\n",
      "Best solution found. Point tensor([0.7500, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4381 0.    ], Delta: [-0.4381  0.    ], Omega: [[0.3119 0.0833]], bt: 0.6026\n",
      "Best solution found. Point tensor([0.9583, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.6153 0.    ], Delta: [-0.6153  0.    ], Omega: [[0.3431 0.0417]], bt: 0.6122\n",
      "No optimizer solution found for point tensor([[0.0170, 0.3591]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2093, 0.1895], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2093 0.1895]], bt: 0.6012\n",
      "Best solution found. Point tensor([0.2454, 0.1366], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0003 0.0001], Delta: [-0.0001  0.0001], Omega: [[0.2453 0.1367]], bt: 0.618\n",
      "Best solution found. Point tensor([0.2500, 0.0000], dtype=torch.float64), Delta+: [0.     0.1032], Delta-: [0. 0.], Delta: [0.     0.1032], Omega: [[0.25   0.1032]], bt: 0.6463\n",
      "Best solution found. Point tensor([0.5833, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2396 0.    ], Delta: [-0.2396 -0.    ], Omega: [[0.3438 0.0417]], bt: 0.6134\n",
      "Best solution found. Point tensor([0.6250, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3435 0.    ], Delta: [-0.3435  0.    ], Omega: [[0.2815 0.125 ]], bt: 0.5918\n",
      "Best solution found. Point tensor([0.3750, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1601 0.0775], Delta: [-0.16   -0.0774], Omega: [[0.215  0.2142]], bt: 0.5696\n",
      "Best solution found. Point tensor([0.1250, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4688], Delta: [ 0.     -0.4688], Omega: [[0.125  0.2812]], bt: 0.5915\n",
      "Best solution found. Point tensor([0.2345, 0.1403], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0002 0.0001], Delta: [-0.0001  0.0001], Omega: [[0.2344 0.1404]], bt: 0.6251\n",
      "Best solution found. Point tensor([0.2098, 0.1833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2098 0.1833]], bt: 0.6069\n",
      "Best solution found. Point tensor([0.2776, 0.1077], dtype=torch.float64), Delta+: [0.0001 0.0003], Delta-: [0.0004 0.0001], Delta: [-0.0003  0.0002], Omega: [[0.2772 0.1079]], bt: 0.6149\n",
      "No optimizer solution found for point tensor([[     0.3958,     -0.0001]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.0000, 0.1250], dtype=torch.float64), Delta+: [0.1647 0.0405], Delta-: [0. 0.], Delta: [0.1647 0.0405], Omega: [[0.1647 0.1655]], bt: 0.6688\n",
      "Best solution found. Point tensor([0.1667, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5004], Delta: [ 0.     -0.5004], Omega: [[0.1667 0.2496]], bt: 0.5812\n",
      "Best solution found. Point tensor([0.3333, 0.4583], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.1188 0.2442], Delta: [-0.1186 -0.2441], Omega: [[0.2147 0.2143]], bt: 0.5692\n",
      "Best solution found. Point tensor([0.2917, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0096 0.    ], Delta: [-0.0096  0.    ], Omega: [[0.2821 0.125 ]], bt: 0.5929\n",
      "Best solution found. Point tensor([0.0833, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0629], Delta: [ 0.     -0.0629], Omega: [[0.0833 0.3121]], bt: 0.6042\n",
      "Best solution found. Point tensor([0.2330, 0.2060], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0112 0.    ], Delta: [-0.0112 -0.    ], Omega: [[0.2218 0.206 ]], bt: 0.5722\n",
      "Best solution found. Point tensor([0.1795, 0.2112], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0003 0.0003], Delta: [-0.0001 -0.0001], Omega: [[0.1795 0.2111]], bt: 0.6094\n",
      "Best solution found. Point tensor([0.2190, 0.2142], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0032 0.0006], Delta: [-0.0032 -0.0006], Omega: [[0.2158 0.2135]], bt: 0.5706\n",
      "Best solution found. Point tensor([0.3642, 0.0030], dtype=torch.float64), Delta+: [0.     0.0218], Delta-: [0.0074 0.    ], Delta: [-0.0074  0.0218], Omega: [[0.3569 0.0248]], bt: 0.6181\n",
      "Best solution found. Point tensor([0.1667, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2916], Delta: [ 0.     -0.2916], Omega: [[0.1667 0.25  ]], bt: 0.5818\n",
      "Best solution found. Point tensor([0.2374, 0.2269], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0222 0.0125], Delta: [-0.0222 -0.0124], Omega: [[0.2152 0.2144]], bt: 0.5702\n",
      "Best solution found. Point tensor([0.2917, 0.3333], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.077  0.1191], Delta: [-0.0768 -0.1189], Omega: [[0.2148 0.2144]], bt: 0.5698\n",
      "Best solution found. Point tensor([0.4583, 0.4167], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.2437 0.2027], Delta: [-0.2436 -0.2026], Omega: [[0.2147 0.2141]], bt: 0.569\n",
      "Best solution found. Point tensor([0.0269, 0.3583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0026], Delta: [ 0.     -0.0026], Omega: [[0.0269 0.3556]], bt: 0.6174\n",
      "Best solution found. Point tensor([0.3750, 0.5417], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.1605 0.3277], Delta: [-0.1604 -0.3276], Omega: [[0.2146 0.2141]], bt: 0.5688\n",
      "Best solution found. Point tensor([0.1250, 0.5833], dtype=torch.float64), Delta+: [0.0003 0.0002], Delta-: [0.0003 0.302 ], Delta: [-0.     -0.3018], Omega: [[0.125  0.2815]], bt: 0.592\n",
      "Best solution found. Point tensor([0.1993, 0.2008], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0004 0.0004], Delta: [-0.0002 -0.0002], Omega: [[0.1991 0.2005]], bt: 0.6004\n",
      "Best solution found. Point tensor([0.1667, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.2082], Delta: [-0.     -0.2082], Omega: [[0.1666 0.2501]], bt: 0.5822\n",
      "Best solution found. Point tensor([0.1904, 0.1974], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1904 0.1974]], bt: 0.6121\n",
      "Best solution found. Point tensor([0.0974, 0.2848], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.0974 0.2848]], bt: 0.6178\n",
      "No optimizer solution found for point tensor([[-0.0131,  0.3744]], dtype=torch.float64)!\n",
      "No optimizer solution found for point tensor([[0.0000, 0.4167]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.1250, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4271], Delta: [ 0.     -0.4271], Omega: [[0.125  0.2812]], bt: 0.5916\n",
      "Best solution found. Point tensor([0.2486, 0.0802], dtype=torch.float64), Delta+: [0.     0.0242], Delta-: [0. 0.], Delta: [0.     0.0242], Omega: [[0.2486 0.1044]], bt: 0.6469\n",
      "Best solution found. Point tensor([0.0933, 0.2570], dtype=torch.float64), Delta+: [0.0057 0.    ], Delta-: [0. 0.], Delta: [0.0057 0.    ], Omega: [[0.099 0.257]], bt: 0.644\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.6667, 0.0000], dtype=torch.float64), Delta+: [0.     0.0248], Delta-: [0.3104 0.    ], Delta: [-0.3104  0.0248], Omega: [[0.3563 0.0248]], bt: 0.6172\n",
      "Best solution found. Point tensor([0.1553, 0.2427], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0. -0.], Omega: [[0.1553 0.2427]], bt: 0.602\n",
      "Best solution found. Point tensor([0.9167, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5735 0.    ], Delta: [-0.5735  0.    ], Omega: [[0.3431 0.0417]], bt: 0.6123\n",
      "Best solution found. Point tensor([0.0417, 0.1667], dtype=torch.float64), Delta+: [0.1215 0.001 ], Delta-: [0. 0.], Delta: [0.1215 0.001 ], Omega: [[0.1632 0.1677]], bt: 0.6685\n",
      "No optimizer solution found for point tensor([[0.0046, 0.3657]], dtype=torch.float64)!\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 0\n",
      "include consumption: False\n",
      "Step 2a: Approximate NTR\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Optimization failed for start 2: 'float' object has no attribute 'backward'\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "[[0.1651 0.1652]\n",
      " [0.1031 0.25  ]\n",
      " [0.025  0.3566]\n",
      " [0.025  0.3561]\n",
      " [0.0249 0.3557]\n",
      " [0.25   0.1026]\n",
      " [0.2141 0.2146]\n",
      " [0.3565 0.0248]\n",
      " [0.2142 0.2146]\n",
      " [0.2139 0.2143]\n",
      " [0.356  0.0248]\n",
      " [0.3556 0.0248]]\n",
      "len tilde_omega_t: 12\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point tensor([0.4583, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2387 0.    ], Delta: [-0.2387 -0.    ], Omega: [[0.2197 0.2083]], bt: 0.5708\n",
      "Best solution found. Point tensor([0.1250, 0.1250], dtype=torch.float64), Delta+: [0.0398 0.0408], Delta-: [0. 0.], Delta: [0.0398 0.0408], Omega: [[0.1648 0.1658]], bt: 0.6691\n",
      "Best solution found. Point tensor([0.2059, 0.1904], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2059 0.1904]], bt: 0.6037\n",
      "Best solution found. Point tensor([0.9167, 0.0833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.6052 0.    ], Delta: [-0.6052  0.    ], Omega: [[0.3115 0.0833]], bt: 0.6022\n",
      "Best solution found. Point tensor([0.3333, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1184 0.119 ], Delta: [-0.1184 -0.119 ], Omega: [[0.215  0.2144]], bt: 0.5695\n",
      "Best solution found. Point tensor([0.0000, 0.2500], dtype=torch.float64), Delta+: [0.1031 0.    ], Delta-: [0. 0.], Delta: [0.1031 0.    ], Omega: [[0.1031 0.25  ]], bt: 0.6463\n",
      "Best solution found. Point tensor([0.2940, 0.0942], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.    ], Delta: [-0.0001  0.    ], Omega: [[0.2939 0.0942]], bt: 0.6118\n",
      "Best solution found. Point tensor([0.1908, 0.2463], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.0134], Delta: [-0.0001 -0.0134], Omega: [[0.1907 0.2329]], bt: 0.5764\n",
      "Best solution found. Point tensor([0.2500, 0.3750], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0356 0.1603], Delta: [-0.0355 -0.1602], Omega: [[0.2145 0.2148]], bt: 0.5697\n",
      "Best solution found. Point tensor([0.1483, 0.1341], dtype=torch.float64), Delta+: [0.0166 0.0317], Delta-: [0. 0.], Delta: [0.0166 0.0317], Omega: [[0.1649 0.1657]], bt: 0.6692\n",
      "Best solution found. Point tensor([0.4167, 0.5417], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.2022 0.3277], Delta: [-0.202  -0.3275], Omega: [[0.2146 0.2141]], bt: 0.5686\n",
      "Best solution found. Point tensor([0.8333, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5837 0.    ], Delta: [-0.5837  0.    ], Omega: [[0.2496 0.1667]], bt: 0.5808\n",
      "Best solution found. Point tensor([0.0319, 0.3406], dtype=torch.float64), Delta+: [0.0044 0.    ], Delta-: [0. 0.], Delta: [ 0.0044 -0.    ], Omega: [[0.0363 0.3406]], bt: 0.6231\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.3568, 0.0254], dtype=torch.float64), Delta+: [0.     0.0011], Delta-: [0.0016 0.    ], Delta: [-0.0016  0.0011], Omega: [[0.3552 0.0265]], bt: 0.6183\n",
      "Best solution found. Point tensor([0.1250, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5103], Delta: [ 0.     -0.5103], Omega: [[0.125  0.2814]], bt: 0.5911\n",
      "Best solution found. Point tensor([0.3825, 0.0189], dtype=torch.float64), Delta+: [0.    0.006], Delta-: [0.0258 0.    ], Delta: [-0.0258  0.006 ], Omega: [[0.3567 0.0249]], bt: 0.6182\n",
      "No optimizer solution found for point tensor([[0.0000, 0.7500]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2500, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0298 0.0003], Delta: [-0.0298 -0.0002], Omega: [[0.2202 0.2081]], bt: 0.5716\n",
      "No optimizer solution found for point tensor([[0.0096, 0.3907]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.6250, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3436 0.    ], Delta: [-0.3436  0.    ], Omega: [[0.2814 0.125 ]], bt: 0.5919\n",
      "Best solution found. Point tensor([0.4167, 0.4583], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.202  0.2443], Delta: [-0.2019 -0.2442], Omega: [[0.2148 0.2142]], bt: 0.5688\n",
      "Best solution found. Point tensor([0.2042, 0.1623], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2042 0.1623]], bt: 0.6336\n",
      "Best solution found. Point tensor([0.5000, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2184 0.    ], Delta: [-0.2184  0.    ], Omega: [[0.2816 0.125 ]], bt: 0.5923\n",
      "Best solution found. Point tensor([0.1630, 0.1481], dtype=torch.float64), Delta+: [0.0028 0.017 ], Delta-: [0. 0.], Delta: [0.0028 0.017 ], Omega: [[0.1658 0.1651]], bt: 0.669\n",
      "Best solution found. Point tensor([0.0455, 0.3610], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0201], Delta: [ 0.     -0.0201], Omega: [[0.0455 0.3409]], bt: 0.6135\n",
      "Best solution found. Point tensor([0.2184, 0.1828], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0006 0.0004], Delta: [-0.0004 -0.0002], Omega: [[0.218  0.1826]], bt: 0.5994\n",
      "Best solution found. Point tensor([0.2247, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2247 0.1667]], bt: 0.6086\n",
      "Best solution found. Point tensor([0.3750, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.031 0.   ], Delta: [-0.031 -0.   ], Omega: [[0.344  0.0417]], bt: 0.6142\n",
      "Best solution found. Point tensor([0.3194, 0.0664], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.3194 0.0664]], bt: 0.6142\n",
      "Best solution found. Point tensor([0.2591, 0.1335], dtype=torch.float64), Delta+: [0.0002 0.0003], Delta-: [0.0007 0.0002], Delta: [-0.0005  0.0001], Omega: [[0.2586 0.1336]], bt: 0.6078\n",
      "Best solution found. Point tensor([0.0417, 0.2917], dtype=torch.float64), Delta+: [0.031 0.   ], Delta-: [0. 0.], Delta: [ 0.031 -0.   ], Omega: [[0.0726 0.2917]], bt: 0.6355\n",
      "Best solution found. Point tensor([0.5000, 0.3333], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.2852 0.1194], Delta: [-0.2851 -0.1192], Omega: [[0.2149 0.2141]], bt: 0.5689\n",
      "Best solution found. Point tensor([0.7917, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.542 0.   ], Delta: [-0.542  0.   ], Omega: [[0.2497 0.1667]], bt: 0.581\n",
      "Best solution found. Point tensor([0.2500, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0353 0.2439], Delta: [-0.0352 -0.2439], Omega: [[0.2148 0.2144]], bt: 0.5694\n",
      "Best solution found. Point tensor([0.1830, 0.2137], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0003 0.0004], Delta: [-0.0001 -0.0002], Omega: [[0.1829 0.2135]], bt: 0.6037\n",
      "Best solution found. Point tensor([0.2182, 0.2224], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0032 0.0077], Delta: [-0.0032 -0.0077], Omega: [[0.215  0.2147]], bt: 0.5702\n",
      "Best solution found. Point tensor([0.2400, 0.1410], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.24  0.141]], bt: 0.6189\n",
      "Best solution found. Point tensor([0.0417, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.1558], Delta: [ 0.     -0.1558], Omega: [[0.0417 0.3442]], bt: 0.6133\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.3721, 0.0332], dtype=torch.float64), Delta+: [0.     0.0003], Delta-: [0.0219 0.    ], Delta: [-0.0219  0.0003], Omega: [[0.3502 0.0334]], bt: 0.6162\n",
      "Best solution found. Point tensor([0.2070, 0.1699], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.207  0.1699]], bt: 0.6232\n",
      "Best solution found. Point tensor([0.2083, 0.3750], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0031 0.1535], Delta: [-0.0029 -0.1533], Omega: [[0.2054 0.2217]], bt: 0.5721\n",
      "Best solution found. Point tensor([0.2500, 0.5833], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0361 0.3687], Delta: [-0.0359 -0.3685], Omega: [[0.2141 0.2148]], bt: 0.5691\n",
      "Best solution found. Point tensor([0.4583, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2438 0.3277], Delta: [-0.2437 -0.3276], Omega: [[0.2146 0.214 ]], bt: 0.5685\n",
      "No optimizer solution found for point tensor([[ 0.3906, -0.0043]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2083, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.4894], Delta: [-0.0001 -0.4894], Omega: [[0.2082 0.2189]], bt: 0.5704\n",
      "Best solution found. Point tensor([0.1747, 0.2500], dtype=torch.float64), Delta+: [0.0001 0.    ], Delta-: [0.0002 0.0061], Delta: [-0.0002 -0.006 ], Omega: [[0.1746 0.2439]], bt: 0.5815\n",
      "Best solution found. Point tensor([0.2500, 0.4167], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0358 0.2019], Delta: [-0.0357 -0.2018], Omega: [[0.2143 0.2149]], bt: 0.5696\n",
      "Best solution found. Point tensor([0.5833, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3639 0.    ], Delta: [-0.3639 -0.    ], Omega: [[0.2194 0.2083]], bt: 0.5704\n",
      "No optimizer solution found for point tensor([[0.0000, 0.4167]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2500, 0.0417], dtype=torch.float64), Delta+: [0.     0.0616], Delta-: [0. 0.], Delta: [0.     0.0616], Omega: [[0.25   0.1032]], bt: 0.6465\n",
      "No optimizer solution found for point tensor([[0.3427, 0.0294]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.0000, 0.2083], dtype=torch.float64), Delta+: [0.1324 0.    ], Delta-: [0. 0.], Delta: [0.1324 0.    ], Omega: [[0.1324 0.2083]], bt: 0.6586\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "No optimizer solution found for point tensor([[0.1851, 0.2368]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2083, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.001  0.3218], Delta: [-0.0009 -0.3218], Omega: [[0.2074 0.2199]], bt: 0.5711\n",
      "Best solution found. Point tensor([0.2083, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5312], Delta: [-0.     -0.5312], Omega: [[0.2083 0.2188]], bt: 0.5703\n",
      "Best solution found. Point tensor([0.1992, 0.1916], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.1992 0.1916]], bt: 0.6092\n",
      "Best solution found. Point tensor([0.2016, 0.1601], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2016 0.1601]], bt: 0.6383\n",
      "Best solution found. Point tensor([0.2406, 0.0766], dtype=torch.float64), Delta+: [0.     0.0325], Delta-: [0. 0.], Delta: [0.     0.0325], Omega: [[0.2406 0.1092]], bt: 0.6501\n",
      "Best solution found. Point tensor([0.6667, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.452  0.0776], Delta: [-0.452  -0.0776], Omega: [[0.2147 0.214 ]], bt: 0.5686\n",
      "Best solution found. Point tensor([0.2072, 0.1945], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0001 0.0001], Delta: [-0. -0.], Omega: [[0.2072 0.1945]], bt: 0.5983\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.0417, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.    0.448], Delta: [ 0.    -0.448], Omega: [[0.0417 0.3437]], bt: 0.6124\n",
      "Best solution found. Point tensor([0.2432, 0.1239], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2432 0.1239]], bt: 0.6329\n",
      "No optimizer solution found for point tensor([[0.2917, 0.0000]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.6667, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.452  0.1193], Delta: [-0.452  -0.1193], Omega: [[0.2146 0.214 ]], bt: 0.5685\n",
      "Best solution found. Point tensor([0.8333, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5523 0.    ], Delta: [-0.5523  0.    ], Omega: [[0.281 0.125]], bt: 0.5912\n",
      "Best solution found. Point tensor([0.0996, 0.2306], dtype=torch.float64), Delta+: [0.0163 0.    ], Delta-: [0. 0.], Delta: [0.0163 0.    ], Omega: [[0.1159 0.2306]], bt: 0.6534\n",
      "Best solution found. Point tensor([0.2140, 0.1965], dtype=torch.float64), Delta+: [0.     0.0001], Delta-: [0.0002 0.0002], Delta: [-0.0002 -0.0001], Omega: [[0.2138 0.1964]], bt: 0.5898\n",
      "No optimizer solution found for point tensor([[0.0174, 0.3805]], dtype=torch.float64)!\n",
      "No optimizer solution found for point tensor([[0.0850, 0.2675]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2206, 0.2241], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0055 0.0095], Delta: [-0.0055 -0.0095], Omega: [[0.2151 0.2146]], bt: 0.5702\n",
      "Best solution found. Point tensor([0.2083, 0.3333], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0027 0.112 ], Delta: [-0.0026 -0.1118], Omega: [[0.2057 0.2215]], bt: 0.5722\n",
      "Best solution found. Point tensor([0.2691, 0.1118], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2691 0.1118]], bt: 0.6191\n",
      "Best solution found. Point tensor([0.8333, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4902 0.    ], Delta: [-0.4902 -0.    ], Omega: [[0.3431 0.0417]], bt: 0.6127\n",
      "Best solution found. Point tensor([0.0833, 0.5833], dtype=torch.float64), Delta+: [0.0001 0.    ], Delta-: [0.     0.2719], Delta: [ 0.     -0.2718], Omega: [[0.0834 0.3115]], bt: 0.6038\n",
      "Best solution found. Point tensor([0.5833, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3687 0.1192], Delta: [-0.3687 -0.1192], Omega: [[0.2147 0.2142]], bt: 0.5687\n",
      "Best solution found. Point tensor([0.0244, 0.3685], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0111], Delta: [ 0.     -0.0111], Omega: [[0.0244 0.3574]], bt: 0.6182\n",
      "Best solution found. Point tensor([0.1866, 0.1919], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1866 0.1919]], bt: 0.6215\n",
      "Best solution found. Point tensor([0.5833, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3685 0.0358], Delta: [-0.3685 -0.0358], Omega: [[0.2148 0.2142]], bt: 0.569\n",
      "Best solution found. Point tensor([0.1667, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5419], Delta: [ 0.     -0.5419], Omega: [[0.1667 0.2497]], bt: 0.5809\n",
      "Best solution found. Point tensor([0.5000, 0.0000], dtype=torch.float64), Delta+: [0.     0.0248], Delta-: [0.1435 0.    ], Delta: [-0.1435  0.0248], Omega: [[0.3565 0.0248]], bt: 0.6178\n",
      "Best solution found. Point tensor([0.2329, 0.1650], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0006 0.0003], Delta: [-0.0004 -0.0001], Omega: [[0.2325 0.1649]], bt: 0.6026\n",
      "Best solution found. Point tensor([0.5833, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3333 0.    ], Delta: [-0.3333  0.    ], Omega: [[0.2501 0.1667]], bt: 0.5816\n",
      "No optimizer solution found for point tensor([[-0.0050,  0.3681]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2045, 0.2334], dtype=torch.float64), Delta+: [0.0001 0.0001], Delta-: [0.0012 0.0108], Delta: [-0.0012 -0.0107], Omega: [[0.2034 0.2227]], bt: 0.5738\n",
      "No optimizer solution found for point tensor([[0.0000, 0.6667]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2170, 0.1572], dtype=torch.float64), Delta+: [0.0001 0.0002], Delta-: [0.0002 0.0001], Delta: [-0.      0.0001], Omega: [[0.217  0.1573]], bt: 0.6257\n",
      "Best solution found. Point tensor([0.2083, 0.4167], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0035 0.195 ], Delta: [-0.0033 -0.1948], Omega: [[0.2051 0.2219]], bt: 0.5721\n",
      "No optimizer solution found for point tensor([[0.0000, 0.7083]], dtype=torch.float64)!\n",
      "Best solution found. Point tensor([0.2190, 0.1686], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.219  0.1686]], bt: 0.6124\n",
      "Best solution found. Point tensor([0.2917, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0769 0.3275], Delta: [-0.0769 -0.3275], Omega: [[0.2148 0.2142]], bt: 0.569\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.4583, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2434 0.0774], Delta: [-0.2434 -0.0774], Omega: [[0.2149 0.2143]], bt: 0.5692\n",
      "Best solution found. Point tensor([0.1907, 0.1933], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1907 0.1933]], bt: 0.616\n",
      "Best solution found. Point tensor([0.1937, 0.1990], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1937 0.199 ]], bt: 0.6073\n",
      "Best solution found. Point tensor([0.4583, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2434 0.0357], Delta: [-0.2434 -0.0357], Omega: [[0.2149 0.2143]], bt: 0.5694\n",
      "Best solution found. Point tensor([0.2545, 0.0654], dtype=torch.float64), Delta+: [0.     0.0342], Delta-: [0. 0.], Delta: [0.     0.0342], Omega: [[0.2545 0.0996]], bt: 0.6458\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.1656, 0.2214], dtype=torch.float64), Delta+: [0.0002 0.0002], Delta-: [0.0002 0.0003], Delta: [ 0.     -0.0001], Omega: [[0.1656 0.2213]], bt: 0.6132\n",
      "Best solution found. Point tensor([0.2303, 0.1521], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.2303 0.1521]], bt: 0.6176\n",
      "Cannot call restoration phase at point that is almost feasible (violation 0.000000e+00).\n",
      "Abort in line search due to no other fall back.\n",
      "Best solution found. Point tensor([0.8750, 0.0417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5319 0.    ], Delta: [-0.5319 -0.    ], Omega: [[0.3431 0.0417]], bt: 0.6126\n",
      "Best solution found. Point tensor([0.3166, 0.0694], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [-0.  0.], Omega: [[0.3166 0.0694]], bt: 0.614\n",
      "Best solution found. Point tensor([0.3668, 0.0091], dtype=torch.float64), Delta+: [0.     0.0158], Delta-: [0.01 0.  ], Delta: [-0.01    0.0158], Omega: [[0.3568 0.0248]], bt: 0.6183\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n",
    "\n",
    "# Set print options\n",
    "torch.set_printoptions(sci_mode=False, precision=4)\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Limit PyTorch and NumPy to use a single thread per worker\n",
    "torch.set_num_threads(1)\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "def TasmanianSGLogQuadNorm(n, mu=None, cov=None):\n",
    "    \"\"\"\n",
    "    Computes nodes and weights for a multivariate normal distribution\n",
    "    using Tasmanian's Gauss-Hermite quadrature. (Same as Schober 2022 uses)\n",
    "\n",
    "    Args:\n",
    "        n (list or array-like): 1 by d array of number of refinements (nodes) per dimension.\n",
    "        mu (array-like): 1 by d mean vector. Defaults to zeros.\n",
    "        cov (array-like): d by d covariance matrix. Defaults to identity.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - x (np.ndarray): Matrix of evaluation nodes (num_nodes x d). Exponential transformed.\n",
    "            - w (np.ndarray): Array of quadrature weights (num_nodes,).\n",
    "    \"\"\"\n",
    "    n = np.asarray(n)\n",
    "    dim = n.size\n",
    "\n",
    "    # Default covariance matrix\n",
    "    if cov is None:\n",
    "        cov = np.eye(dim)\n",
    "    else:\n",
    "        cov = np.asarray(cov)\n",
    "        if cov.shape != (dim, dim):\n",
    "            raise ValueError(\"Covariance matrix must be of shape (d, d).\")\n",
    "\n",
    "    # Default mean vector\n",
    "    if mu is None:\n",
    "        mu = np.zeros(dim)\n",
    "    else:\n",
    "        mu = np.asarray(mu)\n",
    "        if mu.size != dim:\n",
    "            raise ValueError(\"Mean vector must be of length d.\")\n",
    "\n",
    "    # Calculate anisotropic refinements\n",
    "    if dim == 1:\n",
    "        refine = []\n",
    "    else:\n",
    "        refine = (1.0 / np.array(n) * np.prod(n)).tolist()\n",
    "\n",
    "    # Determine the maximum level\n",
    "    level = int(np.max(n))\n",
    "\n",
    "    # Create Tasmanian grid using positional arguments\n",
    "    grid = Tasmanian.makeGlobalGrid(\n",
    "        int(dim),              # iDimension\n",
    "        1,                     # iOutputs\n",
    "        level,                 # iDepth\n",
    "        'level',               # sType\n",
    "        'gauss-hermite',       # sRule\n",
    "        refine,                # liAnisotropicWeights \n",
    "        0.0,                   # fAlpha #No alpha for Gauss-Hermite\n",
    "        0.0,                   # fBeta #No beta for Gauss-Hermite\n",
    "        \"\",                    # sCustomFilename\n",
    "        []                     # liLevelLimits\n",
    "    )\n",
    "\n",
    "    # Retrieve nodes and weights\n",
    "    nodes = grid.getPoints()    # Shape: (dim, num_nodes)\n",
    "    weights = grid.getQuadratureWeights() # Shape: (num_nodes,)\n",
    "    \n",
    "    # Transpose nodes to shape (num_nodes, dim)\n",
    "    # nodes = nodes.              # Now nodes.shape = (num_nodes, dim)\n",
    "    # nodes *= np.sqrt(2) # Correct scaling by sqrt(2)\n",
    "\n",
    "    L = scipy.linalg.cholesky(cov, lower=True).T  # Shape: (dim, dim)\n",
    "    transformed_nodes = mu*Delta_t + np.sqrt(2) * np.sqrt(Delta_t) * (nodes @ L)  # Shape: (num_nodes, dim)\n",
    "    transformed_nodes = np.exp(transformed_nodes-0.5*np.diag(cov)*Delta_t)  # Transform to positive domain\n",
    "    scaled_weights = (np.pi ** (-dim / 2)) * weights  # Shape: (num_nodes,)\n",
    "\n",
    "    return transformed_nodes, scaled_weights,L\n",
    "\n",
    "# def gauss_hermite_quadrature(n,mu,Sigma,Delta_t):\n",
    "#     D = len(mu)\n",
    "#     #scipy.special.roots_hermite\n",
    "#     x_1d, w_1d = roots_hermite(n)\n",
    "#     x_1d, w_1d = roots_hermitenorm(n)\n",
    "\n",
    "#     nodes = np.array(list(product(x_1d, repeat=D)))  # Shape: [n^D, D]\n",
    "#     weights = np.prod(np.array(list(product(w_1d, repeat=D))), axis=1)  # Shape: [n^D]\n",
    "    \n",
    "#     L = scipy.linalg.cholesky(Sigma, lower=True)    \n",
    "#     nodes = mu * Delta_t + np.sqrt(2) * (nodes @ L)  # Correct scaling by sqrt(2)\n",
    "#     weights = np.pi**(-D/2)*weights\n",
    "#     return nodes, weights, L\n",
    "\n",
    "# def gauss_hermite_log_normal_quadrature(n, mu, Sigma, Delta_t):\n",
    "#     nodes, weights, L = gauss_hermite_quadrature(n, mu, Sigma, Delta_t)\n",
    "#     # nodes = np.exp(nodes)  # Apply exp column-wise\n",
    "#     # Apply exponential column-wise on nodes\n",
    "#     for i in range(nodes.shape[1]):\n",
    "#         nodes[:, i] = np.exp(nodes[:, i])\n",
    "#     return nodes, weights, L\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            # gpytorch.kernels.MaternKernel(nu=0.5, ard_num_dims=train_x.shape[1])\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=train_x.shape[1])\n",
    "            # gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=train_x.shape[1])\n",
    "            # ,jitter=1e-8  # Adding jitter for numerical stability\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def train_gp_model(train_x, train_y, patience=100, min_delta=1e-8, max_iterations=300):\n",
    "    \"\"\"\n",
    "    Trains a Gaussian Process Regression model with early stopping.\n",
    "\n",
    "    Args:\n",
    "        train_x (torch.Tensor): Training inputs. Shape: [num_samples, D]\n",
    "        train_y (torch.Tensor): Training targets. Shape: [num_samples]\n",
    "        patience (int): Number of iterations to wait for improvement before stopping.\n",
    "        min_delta (float): Minimum change in the loss to qualify as an improvement.\n",
    "        max_iterations (int): Maximum number of iterations to run.\n",
    "\n",
    "    Returns:\n",
    "        model (GPRegressionModel): Trained GP model.\n",
    "        likelihood (gpytorch.likelihoods.GaussianLikelihood): Associated likelihood.\n",
    "    \"\"\"\n",
    "    if train_y.dim() > 1:\n",
    "        train_y = train_y.squeeze(-1)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "        # This is an assumption of noise in training data. See Murphy(2023) 18.3.1\n",
    "        noise_constraint=gpytorch.constraints.GreaterThan(1e-7)\n",
    "    )\n",
    "    model = GPRegressionModel(train_x, train_y, likelihood)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "\n",
    "        # Check for improvement\n",
    "        if current_loss < best_loss - min_delta:\n",
    "            best_loss = current_loss\n",
    "            no_improvement_count = 0  # Reset the counter if we see improvement\n",
    "        else:\n",
    "            no_improvement_count += 1  # Increment if no improvement\n",
    "\n",
    "        # Early stopping condition\n",
    "        if no_improvement_count >= patience:\n",
    "            print(f\"Early stopping at iteration {i+1}\")\n",
    "            break\n",
    "    return model, likelihood\n",
    "\n",
    "def utility(var, gamma):\n",
    "    # var = torch.clamp(var, min=1e-4)\n",
    "    if gamma == 1:\n",
    "        return torch.log(var)  # Log utility for gamma = 1\n",
    "    else:\n",
    "        return (var ** (1.0 - gamma)) / (1.0 - gamma)  # CRRA utility      #Which is correct?\n",
    "\n",
    "def V_terminal(xT, tau, gamma, Rf, Delta_t):\n",
    "    r = np.log(Rf)\n",
    "    # Ensure xT requires grad\n",
    "    holdings = 1.0 - tau * torch.sum(xT, dim=-1)\n",
    "    terminal_utility = ((holdings ** (1.0 - gamma)) * Delta_t) / (1.0 - gamma)\n",
    "    # return terminal_utility #(if using vt as value function)\n",
    "    return terminal_utility # (if using jt as value function)\n",
    "\n",
    "def normalized_bond_holdings(xt, delta_plus, delta_minus, tau, Delta_t, ct=None, include_consumption=False):\n",
    "    # This function is more similar to Schober 2022\n",
    "    if not include_consumption:\n",
    "        ct = torch.tensor([0.0], dtype=torch.float64)\n",
    "    if ct is None:\n",
    "        ct = torch.tensor([0.0], dtype=torch.float64)\n",
    "\n",
    "    # Ensure ct is a scalar tensor\n",
    "    if ct.dim() == 0:\n",
    "        ct = ct  # Already scalar\n",
    "    else:\n",
    "        ct = ct.squeeze()  # Convert [1] to scalar tensor []\n",
    "\n",
    "    # Available cash before transactions\n",
    "    available_cash = 1.0 - torch.sum(xt)\n",
    "\n",
    "    # Buying and selling costs\n",
    "    buying_cost = (1 + tau) * torch.sum(delta_plus)\n",
    "    selling_proceeds = (1 - tau) * torch.sum(delta_minus)\n",
    "\n",
    "    # Calculate bond holdings (bt)\n",
    "    bt = 0.0 + available_cash - buying_cost + selling_proceeds - ct * Delta_t \n",
    "    # bt = 1.0 - torch.sum(xt) - torch.sum(delta_plus) + torch.sum(delta_minus) - torch.sum(delta_plus)*tau - torch.sum(delta_minus)*tau - torch.sum(ct) * Delta_t\n",
    "\n",
    "    # Calculate bond holdings (bt)\n",
    "    # bt = 1.0 - torch.sum(xt + delta_plus - delta_minus) - \\\n",
    "    #      (torch.sum(tau * delta_plus) + torch.sum(tau * delta_minus)) - \\\n",
    "    #      torch.sum(ct) * Delta_t\n",
    "\n",
    "    return bt\n",
    "\n",
    "def normalized_state_dynamics(xt, delta_plus, delta_minus, Rt, bt, Rf, tau):\n",
    "    \"\"\"\n",
    "    Handles both single and batched Rt inputs.\n",
    "    \n",
    "    Args:\n",
    "        xt (torch.Tensor): Current state allocations. Shape: [1, D]\n",
    "        delta_plus (torch.Tensor): Adjustments (increases). Shape: [1, D]\n",
    "        delta_minus (torch.Tensor): Adjustments (decreases). Shape: [1, D]\n",
    "        Rt (torch.Tensor): Returns. Shape: [D] or [n_samples, D]\n",
    "        bt (float): Bond holdings.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        tau (float): Transaction cost rate.\n",
    "    \n",
    "    Returns:\n",
    "        pi_t1 (torch.Tensor): Next period's portfolio value. Shape: [1] or [n_samples]\n",
    "        xt1 (torch.Tensor): Next period's state allocation proportions. Shape: [D] or [n_samples, D]\n",
    "        Wt1 (torch.Tensor): Wealth factor (scalar or [n_samples])\n",
    "    \"\"\"\n",
    "    # Squeeze the first dimension if necessary\n",
    "    xt = xt.squeeze(0)          # Shape: [D]\n",
    "    delta_plus = delta_plus.squeeze(0)    # Shape: [D]\n",
    "    delta_minus = delta_minus.squeeze(0)  # Shape: [D]\n",
    "    \n",
    "    # Calculate asset adjustments\n",
    "    asset_adjustment = xt + delta_plus - delta_minus  # Shape: [D]\n",
    "    \n",
    "    # Check if Rt is batched\n",
    "    if Rt.dim() == 1:\n",
    "        # Single Rt\n",
    "        portfolio_returns = asset_adjustment * Rt  # Shape: [D]\n",
    "        pi_t1 = torch.sum(bt * Rf) + torch.sum(portfolio_returns)  # Scalar\n",
    "        xt1 = portfolio_returns / pi_t1  # Shape: [D]\n",
    "        Wt1 = pi_t1  # Scalar\n",
    "    else:\n",
    "        # Batched Rt\n",
    "        # Rt: [n_samples, D]\n",
    "        # asset_adjustment: [D] -> [1, D] -> broadcast to [n_samples, D]\n",
    "        portfolio_returns = asset_adjustment.unsqueeze(0) * Rt  # Shape: [n_samples, D]\n",
    "        pi_t1 = torch.sum(portfolio_returns, dim=1) + torch.sum(bt * Rf)   # Shape: [n_samples]\n",
    "        xt1 = portfolio_returns / pi_t1.unsqueeze(1)  # Shape: [n_samples, D]\n",
    "        Wt1 = pi_t1  # Shape: [n_samples]\n",
    "\n",
    "    return pi_t1, xt1\n",
    "\n",
    "# my Bellman. Which includes the certainty equivalent transformation\n",
    "def bellman_equation(\n",
    "    vt_next_in,\n",
    "    vt_next_out,\n",
    "    xt,\n",
    "    delta_plus,\n",
    "    delta_minus,\n",
    "    beta,\n",
    "    gamma,\n",
    "    Delta_t,\n",
    "    tau,\n",
    "    Rf,\n",
    "    ct=None,\n",
    "    include_consumption=False,\n",
    "    convex_hull=None,\n",
    "    t=None,\n",
    "    mu=None,\n",
    "    Sigma=None,\n",
    "    quadrature_nodes_weights=None,\n",
    "    integration_method='quadrature',\n",
    "    num_mc_samples=1000  # Number of Monte Carlo samples if using MC integration\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the value function vt using the Bellman equation with specified integration method.\n",
    "\n",
    "    Args:\n",
    "        vt_next_in (gpytorch.models.ExactGP or callable): Value function for inside NTR.\n",
    "        vt_next_out (gpytorch.models.ExactGP or callable): Value function for outside NTR.\n",
    "        xt (torch.Tensor): Current state. Shape: [1, D]\n",
    "        delta_plus (torch.Tensor): Adjustments (increases). Shape: [1, D]\n",
    "        delta_minus (torch.Tensor): Adjustments (decreases). Shape: [1, D]\n",
    "        beta (float): Discount factor.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "        Delta_t (float): Time step size.\n",
    "        tau (float): Transaction cost rate.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        ct (torch.Tensor or None): Consumption at time t.\n",
    "        include_consumption (bool): Flag to include consumption.\n",
    "        convex_hull (ConvexHull or None): Convex hull defining the NTR.\n",
    "        t (int): Current time step.\n",
    "        mu (np.array): Mean vector for asset returns.\n",
    "        Sigma (np.array): Covariance matrix for asset returns.\n",
    "        quadrature_nodes_weights (tuple or None): Quadrature nodes and weights.\n",
    "        integration_method (str): 'quadrature' or 'monte_carlo'\n",
    "        num_mc_samples (int): Number of Monte Carlo samples (used if integration_method='monte_carlo')\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Value function. Shape: [1]\n",
    "    \"\"\"\n",
    "    D = len(mu)\n",
    "    assert xt.dim() == 2 and xt.size(0) == 1, f\"xt must be [1, D], got {xt.shape}\"\n",
    "    assert delta_plus.dim() == 2 and delta_plus.size(0) == 1, f\"delta_plus must be [1, D], got {delta_plus.shape}\"\n",
    "    assert delta_minus.dim() == 2 and delta_minus.size(0) == 1, f\"delta_minus must be [1, D], got {delta_minus.shape}\"\n",
    "    if not include_consumption:\n",
    "        ct = torch.tensor([0.0], dtype=torch.float64)  # Shape: [1]\n",
    "\n",
    "    # if include consumption make sure it is a tensor and make sure it is 0 dimensional\n",
    "    if include_consumption:\n",
    "        if not torch.is_tensor(ct):\n",
    "            ct = torch.tensor(ct, dtype=torch.float64)\n",
    "        if ct.dim() == 1:\n",
    "            ct = ct.squeeze(0)\n",
    "\n",
    "    # Compute bond holdings\n",
    "    bt = normalized_bond_holdings(xt, delta_plus, delta_minus, tau, Delta_t, ct, include_consumption)\n",
    "        # # # if bt is negative but less than 1e-3, set it to 0\n",
    "    # if bt < 0 and bt > -1e-3:\n",
    "    #     bt = torch.tensor([0.0], dtype = torch.float64)\n",
    "    #     # if bt <0 raise error and display xt delta_plus delta_minus\n",
    "\n",
    "    if bt < 0:\n",
    "        return -np.inf\n",
    "\n",
    "    if bt < 0:\n",
    "        raise ValueError(f\"bond holdings are negative. bt: {bt}\")\n",
    "\n",
    "    if integration_method == 'quadrature':\n",
    "        # Quadrature integration\n",
    "        # Check if quadrature nodes and weights are provided; if not, compute them\n",
    "        if quadrature_nodes_weights is None:\n",
    "            raise ValueError(\"No quadrature nodes and weights provided.\")\n",
    "        # else:\n",
    "        transformed_nodes, weights, L = quadrature_nodes_weights\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        log_nodes = torch.tensor(transformed_nodes, dtype=torch.float64)  # Shape: [n_q^D, D]\n",
    "        weights = torch.tensor(weights, dtype=torch.float64)          # Shape: [n_q^D]\n",
    "\n",
    "        pi_t1, xt1 = normalized_state_dynamics(xt, delta_plus, delta_minus, log_nodes, bt, Rf, tau)\n",
    "\n",
    "    elif integration_method == 'monte_carlo':\n",
    "        random_seed = 20011210\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        # Monte Carlo integration\n",
    "        adjusted_mu = mu* Delta_t  - 0.5 * np.diag(Sigma) * Delta_t #See Cai Judd Xu 2013\n",
    "        distribution = cp.MvNormal(adjusted_mu, Sigma * Delta_t)\n",
    "        samples = distribution.sample(num_mc_samples, rule='random')\n",
    "        log_Rt_samples = torch.tensor(samples.T, dtype=torch.float64)  # Shape: [num_mc_samples, D]\n",
    "        Rt = torch.exp(log_Rt_samples)\n",
    "        pi_t1, xt1, Wt1 = normalized_state_dynamics(xt, delta_plus, delta_minus, Rt, bt, Rf, tau)\n",
    "        pi_t1, xt1, Wt1 = [], [], []\n",
    "        for node in Rt:\n",
    "            pi, x, W = normalized_state_dynamics(xt, delta_plus, delta_minus, node, bt, Rf, tau)\n",
    "            pi_t1.append(pi)\n",
    "            xt1.append(x)\n",
    "            Wt1.append(W)\n",
    "        pi_t1 = torch.stack(pi_t1)  # Shape: [n_q^D]\n",
    "        xt1 = torch.stack(xt1)      # Shape: [n_q^D, D]\n",
    "        Wt1 = torch.stack(Wt1)      # Shape: [n_q^D]\n",
    "\n",
    "    elif integration_method == 'quasi_monte_carlo':\n",
    "        random_seed = 20011210\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        # Quasi-Monte Carlo integration using Sobol sequences\n",
    "        adjusted_mu = mu * Delta_t - 0.5 * np.diag(Sigma) * Delta_t #See Cai Judd Xu 2013\n",
    "        distribution = cp.MvNormal(adjusted_mu, Sigma * Delta_t)\n",
    "        samples = distribution.sample(num_mc_samples, rule='sobol')  # 'sobol' or 'halton'\n",
    "        log_Rt_samples = torch.tensor(samples.T, dtype=torch.float64)  # Shape: [num_mc_samples, D]\n",
    "        Rt = torch.exp(log_Rt_samples)\n",
    "\n",
    "        pi_t1, xt1, Wt1 = normalized_state_dynamics(xt, delta_plus, delta_minus, Rt, bt, Rf, tau)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid integration method. Choose 'quadrature', 'monte_carlo', or 'quasi_monte_carlo'.\")\n",
    "\n",
    "    # Raise error if NaN or Inf values are encountered\n",
    "    # if torch.isnan(pi_t1).any() or torch.isnan(xt1).any():\n",
    "    if torch.isnan(pi_t1).any() or torch.isnan(xt1).any():\n",
    "        raise ValueError(\"NaN values encountered in pi_t1, xt1.\")\n",
    "\n",
    "    # if any xt is very slightly negative, set it to 0\n",
    "    if ((xt1 < 0) & (xt1 > -1e-4)).any():\n",
    "        xt1[(xt1 < -0.0) & (xt1 > -1e-5)] = 0.0\n",
    "\n",
    "    # Correctly expand delta_plus and delta_minus to match xt1's shape\n",
    "    delta_plus_expanded = delta_plus.repeat(xt1.size(0), 1)    # Shape: [n_samples, D]\n",
    "    delta_minus_expanded = delta_minus.repeat(xt1.size(0), 1)  # Shape: [n_samples, D]\n",
    "\n",
    "    # Determine if next state is inside NTR\n",
    "    with torch.no_grad():\n",
    "        in_ntr = is_in_ntr(xt1, convex_hull, delta_plus_expanded, delta_minus_expanded,epsilon_ntr=1e-6, t=t)  # [n_samples]\n",
    "        # in_ntr = is_in_ntr(xt1, convex_hull)  # [n_samples]\n",
    "\n",
    "    # Evaluate the next period's value function\n",
    "    vt_next_vals = torch.zeros(xt1.size(0), dtype=torch.float64)\n",
    "\n",
    "    #Now. We select correct value function.\n",
    "    if in_ntr.any():\n",
    "        xt1_in = xt1[in_ntr]  # [n_in, D]\n",
    "        if isinstance(vt_next_in, gpytorch.models.ExactGP) or isinstance(vt_next_out, gpytorch.models.ExactGP):\n",
    "            vt_next_in.eval()\n",
    "            with gpytorch.settings.fast_computations(), \\\n",
    "                gpytorch.settings.fast_pred_samples(True), \\\n",
    "                gpytorch.settings.fast_pred_var(True), \\\n",
    "                torch.no_grad():\n",
    "                vt_next_val_in = vt_next_in(xt1_in).mean.detach().squeeze()  # [n_in]\n",
    "        else:\n",
    "            vt_next_val_in = V_terminal(xt1_in, tau, gamma, Rf, Delta_t).squeeze()  # [n_in]\n",
    "        vt_next_vals[in_ntr] = vt_next_val_in\n",
    "\n",
    "    if (~in_ntr).any():\n",
    "        xt1_out = xt1[~in_ntr]  # [n_out, D]\n",
    "        if isinstance(vt_next_out, gpytorch.models.ExactGP) or isinstance(vt_next_in, gpytorch.models.ExactGP):\n",
    "            vt_next_out.eval()\n",
    "            # with torch.no_grad():\n",
    "            with gpytorch.settings.fast_computations(), \\\n",
    "                gpytorch.settings.fast_pred_samples(True), \\\n",
    "                gpytorch.settings.fast_pred_var(True), \\\n",
    "                torch.no_grad():\n",
    "                vt_next_val_out = vt_next_out(xt1_out).mean.detach().squeeze()  # [n_in]\n",
    "        else:\n",
    "            vt_next_val_out = V_terminal(xt1_out, tau, gamma, Rf, Delta_t).squeeze()  # [n_out]\n",
    "        vt_next_vals[~in_ntr] = vt_next_val_out\n",
    "\n",
    "    # if any negative elements in vt_next_vals, set them them positive\n",
    "    # if (vt_next_vals > 0).any():\n",
    "    #     vt_next_vals[vt_next_vals > 0] = vt_next_vals[vt_next_vals > 0]*(-1)\n",
    "\n",
    "    if integration_method == 'quadrature':\n",
    "        # expected_vt = torch.sum( (((pi_t1) ** (1.0 - gamma)) * vt_next_vals) * weights )\n",
    "        # expected_vt = torch.sum(((pi_t1) ** (1.0 - gamma))*weights)*torch.sum(vt_next_vals*weights)\n",
    "\n",
    "        expected_vt = torch.sum( (((pi_t1) ** (1.0 - gamma)) * vt_next_vals) * weights )\n",
    "        # expected_vt = torch.sum(((pi_t1) ** (1.0 - gamma))*weights)*torch.sum(vt_next_vals*weights)\n",
    "\n",
    "        expected_vt_weighted = expected_vt #NOTE Scaling weights. See Hoerneff 2016\n",
    "    elif integration_method == 'monte_carlo':\n",
    "        vt_i = (pi_t1 ** (1.0 - gamma)) * vt_next_vals\n",
    "        expected_vt = torch.sum(vt_i / num_mc_samples)\n",
    "\n",
    "    elif integration_method == 'quasi_monte_carlo':\n",
    "        vt_i = (pi_t1 ** (1.0 - gamma)) * vt_next_vals\n",
    "        expected_vt = torch.sum(vt_i / num_mc_samples)\n",
    "\n",
    "    vt = beta * expected_vt_weighted  # Shape: [1]\n",
    "    if include_consumption:\n",
    "        # vt = vt.view(-1)  # Ensure vt is a 1D tensor\n",
    "        vt += utility(ct, gamma) * Delta_t # Shape: [1]\n",
    "        # vt = vt.unsqueeze(0)\n",
    "    # # NOTE Certainty equivalent transformation from Shober 2022 (Same result actually) (see exponents which cancel...)\n",
    "    # Compute valueFunctionExpectation = E[(valueFunction)^(1 - gamma)]\n",
    "    valueFunction = pi_t1 * vt_next_vals  # Wealth times next period's value\n",
    "    valueFunctionPower = valueFunction ** (1.0 - gamma)\n",
    "    expected_jt = torch.sum(valueFunctionPower * weights)\n",
    "    expected_jt *= (1 / (np.pi ** (D / 2)))  # Scaling weights if necessary\n",
    "\n",
    "    jt = beta * expected_jt #**(1.0/(1.0-gamma))\n",
    "\n",
    "    # if include_consumption:\n",
    "    #     jt += ct**(1-gamma) # Shape: [1]\n",
    "\n",
    "    jt = jt**(1.0/(1.0-gamma))\n",
    "    return vt\n",
    "\n",
    "# Sample points in step 2.a (NTR Approximation) \n",
    "def sample_state_points(D, add_closest_points=True):\n",
    "    # Generate all combinations of 0.0 and 1.0 for D dimensions (vertices)\n",
    "    vertices = list(product([0.0, 1.0], repeat=D))\n",
    "\n",
    "    # Add midpoints between each combination of vertices\n",
    "    midpoints = []\n",
    "    for i, j in combinations(range(len(vertices)), 2):\n",
    "        midpoint = [(vertices[i][k] + vertices[j][k]) / 2.0 for k in range(D)]\n",
    "        midpoints.append(midpoint)\n",
    "\n",
    "    # Add the interior point [1/D, 1/D, ..., 1/D]\n",
    "    interior_point = [1.0 / D] * D\n",
    "\n",
    "    # Combine all points: vertices, midpoints, and interior point\n",
    "    points = vertices + midpoints + [interior_point]\n",
    "\n",
    "    # Convert the points into a tensor\n",
    "    all_points = torch.tensor(points, dtype=torch.float64)\n",
    "\n",
    "    # Filter points where the sum exceeds 1.0 to stay within the simplex\n",
    "    valid_points = all_points[torch.sum(all_points, dim=1) <= 1.0]\n",
    "\n",
    "    # Add points at closest distances if requested\n",
    "    if add_closest_points:\n",
    "        # Compute pairwise distances between all points\n",
    "        pairwise_distances = pdist(valid_points.numpy())  # Calculate pairwise distances\n",
    "        dist_matrix = squareform(pairwise_distances)      # Convert to distance matrix\n",
    "\n",
    "        # Find the minimum non-zero distance\n",
    "        min_dist = np.min(dist_matrix[dist_matrix > 0])\n",
    "\n",
    "        # Add new points by averaging points at the minimum distance\n",
    "        closest_distance_points = []\n",
    "        for i in range(len(valid_points)):\n",
    "            for j in range(i + 1, len(valid_points)):\n",
    "                if np.isclose(dist_matrix[i, j], min_dist):\n",
    "                    # Add the midpoint between the closest points\n",
    "                    closest_point = (valid_points[i] + valid_points[j]) / 2.0\n",
    "                    closest_distance_points.append(closest_point)\n",
    "\n",
    "        if closest_distance_points:\n",
    "            closest_distance_points = torch.stack(closest_distance_points)\n",
    "            # Combine original points with closest distance points\n",
    "            valid_points = torch.cat([valid_points, closest_distance_points], dim=0)\n",
    "\n",
    "    # Remove duplicate points\n",
    "    valid_points = torch.unique(valid_points, dim=0)\n",
    "\n",
    "    return valid_points\n",
    "\n",
    "# Functions for Sampling points in step 2.b (Solutions over the designed space)\n",
    "def point_in_convex_hull(hull, point):\n",
    "    \"\"\"\n",
    "    Check if a point is inside the convex hull.\n",
    "    \n",
    "    Args:\n",
    "        hull (scipy.spatial.ConvexHull): Convex hull object defining the NTR.\n",
    "        point (ndarray): Point to check, shape [D].\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the point is inside the convex hull, False otherwise.\n",
    "    \"\"\"\n",
    "    return np.all(np.dot(hull.equations[:, :-1], point) + hull.equations[:, -1] <= 0)\n",
    "\n",
    "def create_grid(ntr_vertices, grid_density=100):\n",
    "    \"\"\"\n",
    "    Creates a grid of points in the simplex (sum(x_i) <= 1), excluding those inside a convex hull defined by NTR vertices.\n",
    "    \n",
    "    Args:\n",
    "        ntr_vertices (ndarray): Vertices defining the convex hull (NTR), shape [n_vertices, D].\n",
    "        grid_density (int): Number of points along each dimension.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Grid of points excluding the points inside the convex hull.\n",
    "    \"\"\"\n",
    "    # Get the dimension of the problem from the NTR vertices\n",
    "    D = ntr_vertices.shape[1]\n",
    "    \n",
    "    # Create a grid in D dimensions, each dimension ranging from 0 to 1\n",
    "    grid_ranges = [np.linspace(0, 1, int(grid_density)) for _ in range(D)]\n",
    "    \n",
    "    # Create a meshgrid for all D dimensions and flatten it into a list of points\n",
    "    grid = np.array(np.meshgrid(*grid_ranges)).T.reshape(-1, D)\n",
    "\n",
    "    # Filter out points where the sum exceeds 1 (outside the simplex)\n",
    "    simplex_mask = np.sum(grid, axis=1) <= 1\n",
    "\n",
    "    # Keep only points inside the simplex\n",
    "    points = grid[simplex_mask]\n",
    "\n",
    "    return points\n",
    "\n",
    "def create_grid_excluding_ntr(ntr_vertices, grid_density=100):\n",
    "    \"\"\"\n",
    "    Creates a grid of points in the simplex (sum(x_i) <= 1), excluding those inside a convex hull defined by NTR vertices.\n",
    "    \n",
    "    Args:\n",
    "        ntr_vertices (ndarray): Vertices defining the convex hull (NTR), shape [n_vertices, D].\n",
    "        grid_density (int): Number of points along each dimension.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Grid of points excluding the points inside the convex hull.\n",
    "    \"\"\"\n",
    "    # Create the convex hull from the NTR vertices\n",
    "    hull = ConvexHull(ntr_vertices)\n",
    "\n",
    "    # Create a grid of points in the simplex\n",
    "    grid_points = create_grid(ntr_vertices, grid_density)\n",
    "\n",
    "    # Filter out points inside the NTR (convex hull)\n",
    "    mask = np.array([not point_in_convex_hull(hull, point) for point in grid_points])\n",
    "    outside_points = grid_points[mask]\n",
    "\n",
    "    return outside_points\n",
    "\n",
    "def sample_points_around_ntr_separated(ntr_vertices, num_samples, kink_ratio=0.25, inside_ratio=0.25, grid_density=25,seed=None):\n",
    "    \"\"\"\n",
    "    Samples points around kinks, inside the NTR, and in the general state space excluding NTR.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    hull = ConvexHull(ntr_vertices)\n",
    "    delaunay = Delaunay(ntr_vertices[hull.vertices])  # Create a Delaunay triangulation for point-in-hull testing\n",
    "\n",
    "    # Sample points inside the NTR\n",
    "    num_inside = int(num_samples * inside_ratio)\n",
    "    inside_points = np.array([\n",
    "        np.dot(np.random.dirichlet(np.ones(len(hull.vertices)), size=1), ntr_vertices[hull.vertices]).squeeze(0)\n",
    "        for _ in range(num_inside)\n",
    "    ])\n",
    "\n",
    "    # Sample points around the kinks using linear interpolation with noise\n",
    "    num_kinks = int(num_samples * kink_ratio)\n",
    "    kink_points = []\n",
    "    for i in range(len(ntr_vertices)):\n",
    "        for _ in range(num_kinks // len(ntr_vertices)):\n",
    "            while True:\n",
    "                alpha = np.random.uniform(1.05, 1.15)  # Interpolation factor to ensure point is outside\n",
    "                beta = 1 - alpha\n",
    "                point = alpha * ntr_vertices[i] + beta * ntr_vertices[(i + 1) % len(ntr_vertices)]\n",
    "                point += np.random.uniform(-0.025, 0.025, size=len(ntr_vertices[0]))  # Small noise\n",
    "                if not delaunay.find_simplex(point) >= 0:  # Check if point is outside the hull\n",
    "                    kink_points.append(point)\n",
    "                    break  # Exit loop once we have a valid point outside\n",
    "\n",
    "    kink_points = np.array(kink_points)\n",
    "\n",
    "    # Create a grid and exclude points inside the NTR\n",
    "    general_points = create_grid_excluding_ntr(ntr_vertices, grid_density)\n",
    "    num_general = num_samples - len(inside_points) - len(kink_points)\n",
    "    if num_general > 0:\n",
    "        general_points = general_points[np.random.choice(len(general_points), size=num_general, replace=False)]\n",
    "\n",
    "    return inside_points, kink_points, general_points\n",
    "\n",
    "# Function whether a point is in the NTR for the Bellman\n",
    "def is_in_ntr(x, convex_hull, delta_plus=None, delta_minus=None, epsilon_ntr=1e-7, t=None):\n",
    "    \"\"\"\n",
    "    Determines whether each point in x is inside the NTR.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Points to check. Shape: [n_points, D]\n",
    "        convex_hull (ConvexHull or None): Convex hull defining the NTR.\n",
    "        delta_plus (torch.Tensor or None): Adjustments (increases). Shape: [n_points, D]\n",
    "        delta_minus (torch.Tensor or None): Adjustments (decreases). Shape: [n_points, D]\n",
    "        epsilon_ntr (float): Tolerance for delta policy.\n",
    "        t (int): Current time step.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Boolean tensor indicating NTR membership. Shape: [n_points]\n",
    "    \"\"\"\n",
    "    if convex_hull is None:\n",
    "        return torch.zeros(x.size(0), dtype=torch.bool, device=x.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract convex hull equations and perform tensor operations\n",
    "        equations_A = torch.tensor(convex_hull.equations[:, :-1], dtype=torch.float64)\n",
    "        equations_b = torch.tensor(convex_hull.equations[:, -1], dtype=torch.float64)\n",
    "        inequalities = torch.matmul(x, equations_A.T) + equations_b.unsqueeze(0)  # Shape: [n_points, num_constraints]\n",
    "        epsilon = epsilon_ntr\n",
    "        in_convex_hull = torch.all(inequalities <= epsilon, dim=1)\n",
    "        if delta_plus is not None and delta_minus is not None:\n",
    "            delta = delta_plus - delta_minus\n",
    "            delta_policy = torch.all(torch.abs(delta) < epsilon_ntr, dim=-1)  # Shape: [n_points]\n",
    "            return torch.logical_or(in_convex_hull, delta_policy)  # Shape: [n_points]\n",
    "        return in_convex_hull  # Shape: [n_points]\n",
    "\n",
    "# Function for projecting a point towards the NTR for initial guess\n",
    "def project_onto_convex_hull(x, convex_hull):\n",
    "    \"\"\"\n",
    "    Projects point x onto the convex hull defined by convex_hull.\n",
    "    This is used in order to generate direction of optimization.\n",
    "    When we already have an idea of the NTR\n",
    "\n",
    "    Args:\n",
    "        x (np.array): Current position. Shape: [D]\n",
    "        convex_hull (scipy.spatial.ConvexHull): Convex hull of the NTR.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Projected point within the convex hull.\n",
    "    \"\"\"\n",
    "    D = x.shape[0]\n",
    "    hull_eq = convex_hull.equations  # Shape: [num_facets, D+1]\n",
    "    A = hull_eq[:, :-1]  # Coefficients of inequalities\n",
    "    b = -hull_eq[:, -1]  # Constants of inequalities\n",
    "\n",
    "    # Objective function (squared distance) (euclidian norm)\n",
    "    def objective(x_proj):\n",
    "        return np.sum((x_proj - x) ** 2)\n",
    "\n",
    "    # Define the constraints (x_proj inside convex hull)\n",
    "    constraints = [{'type': 'ineq', 'fun': lambda x_proj, A_row=A[i], b_val=b[i]: b_val - np.dot(A_row, x_proj)} for i in range(len(b))]\n",
    "\n",
    "    # Variable bounds (e.g., x_proj between 0 and 1)\n",
    "    bounds = [(0, 1) for _ in range(D)]\n",
    "\n",
    "    # Initial guess for x_proj (could be current x)\n",
    "    x0 = np.copy(x)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    result = minimize(objective, x0, bounds=bounds, constraints=constraints, tol=1e-6)\n",
    "\n",
    "    if result.success:\n",
    "        x_proj = result.x\n",
    "        return x_proj\n",
    "    else:\n",
    "        # If projection fails, fall back to current x\n",
    "        return None\n",
    "\n",
    "# Function for the Merton point (No costs solution)\n",
    "def MertonPoint(mu, Sigma, r, gamma):\n",
    "    \"\"\"\n",
    "    Computes the Merton portfolio weights.\n",
    "\n",
    "    Args:\n",
    "        mu (np.array): Expected returns vector of risky assets.\n",
    "        Sigma (np.array): Covariance matrix of asset returns.\n",
    "        r (float): Risk-free rate.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Optimal portfolio weights in risky assets.\n",
    "    \"\"\"\n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "    mu_r = mu - r\n",
    "    pi_star = (1.0 / gamma) * Sigma_inv.dot(mu_r)\n",
    "    return pi_star\n",
    "\n",
    "# Problem class for the optimization\n",
    "class PortfolioOptimization(cyipopt.Problem):\n",
    "    def __init__(\n",
    "        self,\n",
    "        D,\n",
    "        xt,\n",
    "        vt_next_in,\n",
    "        vt_next_out,\n",
    "        t,\n",
    "        T,\n",
    "        beta,\n",
    "        gamma,\n",
    "        Delta_t,\n",
    "        tau,\n",
    "        Rf,\n",
    "        mu,\n",
    "        Sigma,\n",
    "        c_min,\n",
    "        include_consumption=False,\n",
    "        convex_hull=None,\n",
    "        quadrature_nodes_weights=None,  # Added parameter\n",
    "        integration_method='quadrature',\n",
    "        num_mc_samples=1000\n",
    "    ):\n",
    "        self.D = D\n",
    "        self.xt = xt.detach().clone()  # Shape: [1, D]\n",
    "        self.vt_next_in = vt_next_in\n",
    "        self.vt_next_out = vt_next_out\n",
    "        self.t = t\n",
    "        self.T = T\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.Delta_t = Delta_t\n",
    "        self.tau = tau\n",
    "        self.Rf = Rf\n",
    "        self.mu = mu\n",
    "        self.Sigma = Sigma\n",
    "        self.c_min = c_min\n",
    "        self.include_consumption = include_consumption\n",
    "        self.convex_hull = convex_hull\n",
    "        self.quadrature_nodes_weights = quadrature_nodes_weights  # Store quadrature data\n",
    "        self.integration_method = integration_method\n",
    "        self.num_mc_samples = num_mc_samples\n",
    "\n",
    "        if not isinstance(xt, torch.Tensor):\n",
    "            raise TypeError(f\"xt must be a torch.Tensor, but got {type(xt)}\")\n",
    "\n",
    "        # **Define the number of variables (self.n)**\n",
    "        self.n = 2 * D + (1 if self.include_consumption else 0)\n",
    "\n",
    "        # **Define Constraint Count**\n",
    "        # Constraints:\n",
    "        # - 2 * D Asset Allocation Constraints (lower and upper bounds per asset)\n",
    "        # - 2 Sum(x + delta) Constraints (sum >=0 and sum <=1)\n",
    "        # - 1 Bond Holdings Constraint (bt >=0)\n",
    "        # - 1 Consumption Constraint (c_t >= c_min) if included\n",
    "        if self.include_consumption:\n",
    "            self.m = 2 * D + 4  # 2D asset constraints + 2 sum constraints + bt + c_t >= c_min\n",
    "        else:\n",
    "            self.m = 2 * D + 3  # 2D asset constraints + 2 sum constraints + bt\n",
    "\n",
    "        # **Variable Bounds**\n",
    "        lb = np.zeros(self.n)\n",
    "        ub = np.ones(self.n)\n",
    "\n",
    "        # **Set Lower Bound for c_t to c_min**\n",
    "        if self.include_consumption:\n",
    "            lb[2 * D] = self.c_min  # Assuming c_t is the last variable\n",
    "\n",
    "        # **Set Upper Bounds for delta_plus and delta_minus based on xt**\n",
    "        # delta_plus <= 1 - xt\n",
    "        ub[:D] = (1.0 - self.xt.cpu().numpy()).flatten()\n",
    "        # delta_minus <= xt\n",
    "        ub[D:2 * D] = self.xt.cpu().numpy().flatten()\n",
    "\n",
    "        # **Constraint Bounds**\n",
    "        cl = np.zeros(self.m)\n",
    "        cu = np.full(self.m, np.inf)  # All constraints are inequalities (>= 0)\n",
    "\n",
    "        super().__init__(n=self.n, m=self.m, problem_obj=self, lb=lb, ub=ub, cl=cl, cu=cu)\n",
    "\n",
    "    def objective(self, params):\n",
    "        \"\"\"\n",
    "        Objective function for the optimization problem.\n",
    "        \"\"\"\n",
    "        # Convert params to a tensor\n",
    "        params_tensor = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "        delta_plus = params_tensor[:self.D].unsqueeze(0)    # Shape: [1, D]\n",
    "        delta_minus = params_tensor[self.D:2 * self.D].unsqueeze(0)  # Shape: [1, D]\n",
    "        if self.include_consumption:\n",
    "            ct = params_tensor[2 * self.D].unsqueeze(0)  # Shape: [1]\n",
    "        else:\n",
    "            ct = None\n",
    "\n",
    "        vt = bellman_equation(\n",
    "            self.vt_next_in,\n",
    "            self.vt_next_out,\n",
    "            self.xt,\n",
    "            delta_plus,\n",
    "            delta_minus,\n",
    "            self.beta,\n",
    "            self.gamma,\n",
    "            self.Delta_t,\n",
    "            self.tau,\n",
    "            self.Rf,\n",
    "            ct,\n",
    "            self.include_consumption,\n",
    "            self.convex_hull,\n",
    "            self.t,\n",
    "            self.mu,\n",
    "            self.Sigma,\n",
    "            self.quadrature_nodes_weights,\n",
    "            self.integration_method,  # 'monte_carlo' or 'quadrature'\n",
    "            self.num_mc_samples\n",
    "        )\n",
    "\n",
    "        if torch.isnan(vt).any() or torch.isinf(vt).any():\n",
    "            raise ValueError(\"NaN or Inf detected in objective function!\")\n",
    "\n",
    "        vt_scalar = vt.squeeze(0)\n",
    "        obj_value = -vt_scalar.item()  # Only convert to scalar at the return statement\n",
    "        return obj_value\n",
    "\n",
    "    def gradient(self, params):\n",
    "        \"\"\"\n",
    "        Gradient of the objective function.\n",
    "        \"\"\"\n",
    "        # Use automatic differentiation\n",
    "        params_tensor = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "        delta_plus = params_tensor[:self.D].unsqueeze(0)    # Shape: [1, D]\n",
    "        delta_minus = params_tensor[self.D:2 * self.D].unsqueeze(0)  # Shape: [1, D]\n",
    "        if self.include_consumption:\n",
    "            ct = params_tensor[2 * self.D].unsqueeze(0)  # Shape: [1]\n",
    "        else:\n",
    "            ct = None\n",
    "\n",
    "\n",
    "        vt = bellman_equation(\n",
    "            self.vt_next_in,\n",
    "            self.vt_next_out,\n",
    "            self.xt,\n",
    "            delta_plus,\n",
    "            delta_minus,\n",
    "            self.beta,\n",
    "            self.gamma,\n",
    "            self.Delta_t,\n",
    "            self.tau,\n",
    "            self.Rf,\n",
    "            ct,\n",
    "            self.include_consumption,\n",
    "            self.convex_hull,\n",
    "            self.t,\n",
    "            self.mu,\n",
    "            self.Sigma,\n",
    "            self.quadrature_nodes_weights,\n",
    "            self.integration_method,  # 'monte_carlo' or 'quadrature'\n",
    "            self.num_mc_samples\n",
    "        )\n",
    "\n",
    "        # Compute gradients\n",
    "        vt.backward()\n",
    "\n",
    "        # Extract gradients\n",
    "        grads = params_tensor.grad.detach().cpu().numpy()\n",
    "        return -grads  # Return negative of the gradients\n",
    "\n",
    "    def constraints_method(self, params):\n",
    "        \"\"\"\n",
    "        Computes the constraints for the optimization problem.\n",
    "        \"\"\"\n",
    "        # Convert NumPy array to PyTorch tensor\n",
    "        params_tensor = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "        constraints_tensor = self.compute_constraints(params_tensor)\n",
    "        constraints_array = constraints_tensor.detach().cpu().numpy()\n",
    "        return constraints_array\n",
    "\n",
    "    def compute_constraints(self, params_tensor):\n",
    "        D = self.D\n",
    "        tau = self.tau\n",
    "        xt = self.xt\n",
    "        Delta_t = self.Delta_t\n",
    "        c_min = self.c_min  # Use the passed c_min\n",
    "\n",
    "        if self.include_consumption:\n",
    "            delta_plus = params_tensor[:D].unsqueeze(0)             # Shape: [1, D]\n",
    "            delta_minus = params_tensor[D:2 * D].unsqueeze(0)       # Shape: [1, D]\n",
    "            c_t = params_tensor[2 * D].unsqueeze(0)                 # Shape: [1]\n",
    "        else:\n",
    "            delta_plus = params_tensor[:D].unsqueeze(0)             # Shape: [1, D]\n",
    "            delta_minus = params_tensor[D:2 * D].unsqueeze(0)       # Shape: [1, D]\n",
    "            c_t = torch.tensor([0.0], dtype=torch.float64)          # Shape: [1]\n",
    "\n",
    "        delta = delta_plus - delta_minus                            # Shape: [1, D]\n",
    "\n",
    "        # Constraint 1: Asset Allocation Constraints (xt + delta >= 0)\n",
    "        constraints_xt_delta_lower = (xt + delta).squeeze(0)        # Shape: [D]\n",
    "\n",
    "        # Constraint 2: Asset Allocation Constraints (xt + delta <= 1)\n",
    "        constraints_xt_delta_upper = 1.0 - (xt + delta).squeeze(0)  # Shape: [D]\n",
    "\n",
    "        # Constraint 3: Sum(x + delta) >= 0\n",
    "        sum_x_plus_delta = torch.sum(xt + delta)                    # Scalar\n",
    "        constraint_sum_geq_zero = sum_x_plus_delta                # >=0\n",
    "\n",
    "        # Constraint 4: Sum(x + delta) <= 1\n",
    "        constraint_sum_leq_one = 1.0 - sum_x_plus_delta          # >=0  (since 1 - sum(x + delta) >=0)\n",
    "\n",
    "        # Constraint 5: Bond Holdings Constraint (bt >= 0). Added small epsilon to prevent numerical issues\n",
    "        bt = normalized_bond_holdings(xt, delta_plus, delta_minus, tau, Delta_t, c_t, self.include_consumption)\n",
    "        constraint_bt = bt.squeeze(0)  # Shape: []\n",
    "\n",
    "        # Constraint 6: Consumption Constraint (c_t >= c_min)\n",
    "        if self.include_consumption:\n",
    "            constraint_ct_geq_cmin = c_t.squeeze(0) - c_min  # Shape: []\n",
    "        else:\n",
    "            constraint_ct_geq_cmin = torch.tensor(0.0, dtype=torch.float64)  # No constraint\n",
    "\n",
    "        # Concatenate all constraints in the desired order:\n",
    "        # Asset Allocation Lower Bounds, Asset Allocation Upper Bounds,\n",
    "        # Sum(x + delta) >=0, Sum(x + delta) <=1, Bond Holdings, Consumption\n",
    "        if self.include_consumption:\n",
    "            constraints_tensor = torch.cat([\n",
    "                constraints_xt_delta_lower,               # D constraints: xt + delta >= 0\n",
    "                constraints_xt_delta_upper,               # D constraints: xt + delta <= 1\n",
    "                constraint_sum_geq_zero.unsqueeze(0),    # Sum(x + delta) >= 0\n",
    "                constraint_sum_leq_one.unsqueeze(0),     # Sum(x + delta) <= 1\n",
    "                constraint_bt.unsqueeze(0),               # bt >= 0\n",
    "                constraint_ct_geq_cmin.unsqueeze(0)       # c_t >= c_min\n",
    "            ])\n",
    "        else:\n",
    "            constraints_tensor = torch.cat([\n",
    "                constraints_xt_delta_lower,               # D constraints: xt + delta >= 0\n",
    "                constraints_xt_delta_upper,               # D constraints: xt + delta <= 1\n",
    "                constraint_sum_geq_zero.unsqueeze(0),    # Sum(x + delta) >= 0\n",
    "                constraint_sum_leq_one.unsqueeze(0),     # Sum(x + delta) <= 1\n",
    "                constraint_bt.unsqueeze(0)                # bt >= 0\n",
    "            ])\n",
    "\n",
    "        return constraints_tensor\n",
    "\n",
    "    # Assign the constraints method to comply with cyipopt's requirements\n",
    "    constraints = constraints_method\n",
    "\n",
    "    def jacobianstructure(self):\n",
    "        D = self.D\n",
    "        rows = []\n",
    "        cols = []\n",
    "        seen = set()\n",
    "\n",
    "        # **1. Asset Allocation Constraints (Lower Bounds)**\n",
    "        for i in range(D):\n",
    "            # dC_i_lower/d(delta_plus_i) = 1\n",
    "            if (i, i) not in seen:\n",
    "                rows.append(i)\n",
    "                cols.append(i)\n",
    "                seen.add((i, i))\n",
    "            # dC_i_lower/d(delta_minus_i) = -1\n",
    "            if (i, D + i) not in seen:\n",
    "                rows.append(i)\n",
    "                cols.append(D + i)\n",
    "                seen.add((i, D + i))\n",
    "\n",
    "        # **2. Asset Allocation Constraints (Upper Bounds)**\n",
    "        for i in range(D):\n",
    "            # dC_i_upper/d(delta_plus_i) = -1\n",
    "            if (D + i, i) not in seen:\n",
    "                rows.append(D + i)\n",
    "                cols.append(i)\n",
    "                seen.add((D + i, i))\n",
    "            # dC_i_upper/d(delta_minus_i) = 1\n",
    "            if (D + i, D + i) not in seen:\n",
    "                rows.append(D + i)\n",
    "                cols.append(D + i)\n",
    "                seen.add((D + i, D + i))\n",
    "\n",
    "        # **3. Sum(x + delta) >= 0 Constraint**\n",
    "        sum_geq_zero_row = 2 * D\n",
    "        for j in range(D):\n",
    "            # dC_sum_geq_zero/d(delta_plus_j) = 1\n",
    "            if (sum_geq_zero_row, j) not in seen:\n",
    "                rows.append(sum_geq_zero_row)\n",
    "                cols.append(j)\n",
    "                seen.add((sum_geq_zero_row, j))\n",
    "        for j in range(D):\n",
    "            # dC_sum_geq_zero/d(delta_minus_j) = -1\n",
    "            if (sum_geq_zero_row, D + j) not in seen:\n",
    "                rows.append(sum_geq_zero_row)\n",
    "                cols.append(D + j)\n",
    "                seen.add((sum_geq_zero_row, D + j))\n",
    "\n",
    "        # **4. Sum(x + delta) <=1 Constraint**\n",
    "        sum_leq_one_row = 2 * D + 1\n",
    "        for j in range(D):\n",
    "            # dC_sum_leq_one/d(delta_plus_j) = -1\n",
    "            if (sum_leq_one_row, j) not in seen:\n",
    "                rows.append(sum_leq_one_row)\n",
    "                cols.append(j)\n",
    "                seen.add((sum_leq_one_row, j))\n",
    "        for j in range(D):\n",
    "            # dC_sum_leq_one/d(delta_minus_j) = 1\n",
    "            if (sum_leq_one_row, D + j) not in seen:\n",
    "                rows.append(sum_leq_one_row)\n",
    "                cols.append(D + j)\n",
    "                seen.add((sum_leq_one_row, D + j))\n",
    "\n",
    "        # **5. Bond Holdings Constraint (bt >= 0)**\n",
    "        bond_constraint_row = 2 * D + 2 if self.include_consumption else 2 * D + 1\n",
    "        for j in range(D):\n",
    "            # dC_bt/d(delta_plus_j) = -1 - tau\n",
    "            if (bond_constraint_row, j) not in seen:\n",
    "                rows.append(bond_constraint_row)\n",
    "                cols.append(j)\n",
    "                seen.add((bond_constraint_row, j))\n",
    "        for j in range(D):\n",
    "            # dC_bt/d(delta_minus_j) = 1 - tau\n",
    "            if (bond_constraint_row, D + j) not in seen:\n",
    "                rows.append(bond_constraint_row)\n",
    "                cols.append(D + j)\n",
    "                seen.add((bond_constraint_row, D + j))\n",
    "        if self.include_consumption:\n",
    "            # dC_bt/d(c_t) = -Delta_t\n",
    "            if (bond_constraint_row, 2 * D) not in seen:\n",
    "                rows.append(bond_constraint_row)\n",
    "                cols.append(2 * D)\n",
    "                seen.add((bond_constraint_row, 2 * D))\n",
    "\n",
    "        # **6. Consumption Constraint (if included)**\n",
    "        if self.include_consumption:\n",
    "            consumption_constraint_row = 2 * D + 3\n",
    "            # dC_consumption/d(c_t) =1\n",
    "            if (consumption_constraint_row, 2 * D) not in seen:\n",
    "                rows.append(consumption_constraint_row)\n",
    "                cols.append(2 * D)\n",
    "                seen.add((consumption_constraint_row, 2 * D))\n",
    "\n",
    "        return np.array(rows, dtype=int), np.array(cols, dtype=int)\n",
    "\n",
    "    def jacobian(self, params):\n",
    "        \"\"\"\n",
    "        Computes the Jacobian of the constraints using AutoDiff.\n",
    "        \"\"\"\n",
    "        params_tensor = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "        delta_plus = params_tensor[:self.D].unsqueeze(0)    # Shape: [1, D]\n",
    "        delta_minus = params_tensor[self.D:2 * self.D].unsqueeze(0)  # Shape: [1, D]\n",
    "        if self.include_consumption:\n",
    "            ct = params_tensor[2 * self.D].unsqueeze(0)  # Shape: [1]\n",
    "        else:\n",
    "            ct = torch.tensor([0.0], dtype=torch.float64, device=params_tensor.device)  # Shape: [1]\n",
    "\n",
    "        # Compute all constraints as a single tensor\n",
    "        constraints = self.compute_constraints(params_tensor)\n",
    "\n",
    "        # Compute gradients of constraints w.r.t params\n",
    "        jacobian = []\n",
    "        for constraint in constraints:\n",
    "            constraint.backward(retain_graph=True)\n",
    "            jacobian.append(params_tensor.grad.clone().detach().cpu().numpy())\n",
    "            params_tensor.grad.zero_()\n",
    "\n",
    "        # Flatten the Jacobian based on sparsity structure\n",
    "        rows, cols = self.jacobianstructure()\n",
    "        jacobian_values = [jacobian[r][c] for r, c in zip(rows, cols)]\n",
    "\n",
    "        return np.array(jacobian_values, dtype=float)\n",
    "\n",
    "# Parallel processing of steps 2.a and 2.b and 2.c\n",
    "def solve_bellman_with_ipopt(\n",
    "    D, xt, vt_next_in, vt_next_out, t, T, beta, gamma, Delta_t,tau, Rf, mu, Sigma,c_min,\n",
    "    convex_hull=None, quadrature_nodes_weights=None, include_consumption=False,\n",
    "    integration_method = 'quadrature', num_mc_samples = 1000,\n",
    "    num_starts=6, drop_tolerance=0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Solves the Bellman equation using IPOPT optimization.\n",
    "\n",
    "    Args:\n",
    "        D (int): Number of assets.\n",
    "        xt (torch.Tensor): Current state. Shape: [1, D]\n",
    "        vt_next_in (gpytorch.models.ExactGP or callable): Value function for inside NTR.\n",
    "        vt_next_out (gpytorch.models.ExactGP or callable): Value function for outside NTR.\n",
    "        t (int): Current time step.\n",
    "        T (int): Total number of time periods.\n",
    "        beta (float): Discount factor.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "        tau (float): Transaction cost rate.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        mu (np.array): Mean vector for asset returns.\n",
    "        Sigma (np.array): Covariance matrix for asset returns.\n",
    "        convex_hull (ConvexHull or None): Convex hull defining the NTR.\n",
    "        quadrature_nodes_weights (tuple or None): Quadrature nodes and weights.\n",
    "        include_consumption (bool): Flag to include consumption.\n",
    "        num_starts (int): Number of optimization starts. We tackle the problem by multiple starts.\n",
    "        drop_tolerance (float): Tolerance for dropping starts. (NOT USED)\n",
    "\n",
    "    Returns:\n",
    "        tuple or None: (delta_plus_opt, delta_minus_opt, delta_opt, omega_i_t, bt) if successful, else None.\n",
    "    \"\"\"\n",
    "    best_solution = None\n",
    "    best_info = None\n",
    "    best_obj_val = float('-inf')\n",
    "    failed_attempts = 0\n",
    "    successful_attempts = 0\n",
    "    max_successful_attempts = 6  # Set the threshold for early stopping\n",
    "    max_failed_attempts = int(num_starts)\n",
    "    max_failed_attempts = int(num_starts)\n",
    "\n",
    "    # logging.info(f\"Solving Bellman equation for xt: {xt}\")\n",
    "    # Ensure xt has a batch dimension\n",
    "    if xt.dim() == 1:\n",
    "        xt = xt.unsqueeze(0)  # Shape: [1, D]\n",
    "\n",
    "    def check_portfolio_constraints(xt, delta_plus, delta_minus, tau, Delta_t, ct=None):\n",
    "        \"\"\"\n",
    "        Directly checks all portfolio constraints.\n",
    "\n",
    "        Args:\n",
    "            xt (torch.Tensor): Current portfolio weights [D]\n",
    "            delta_plus (torch.Tensor): Buy amounts [D]\n",
    "            delta_minus (torch.Tensor): Sell amounts [D]\n",
    "            tau (float): Transaction cost rate\n",
    "            Delta_t (float): Time step\n",
    "            ct (torch.Tensor, optional): Consumption [1]\n",
    "\n",
    "        Returns:\n",
    "            bool: Whether all constraints are satisfied\n",
    "            dict: Dictionary of which constraints failed\n",
    "        \"\"\"\n",
    "        # Initialize failed constraints dictionary\n",
    "        failed = {}\n",
    "\n",
    "        # 1. Check if all variables are in [0,1]\n",
    "        if torch.any((delta_plus < 0) | (delta_plus > 1)):\n",
    "            failed['delta_plus_bounds'] = 'delta_plus must be in [0,1]'\n",
    "        if torch.any((delta_minus < 0) | (delta_minus > 1)):\n",
    "            failed['delta_minus_bounds'] = 'delta_minus must be in [0,1]'\n",
    "\n",
    "        # 2. Check delta_minus <= xt constraint\n",
    "        if torch.any(delta_minus > xt):\n",
    "            failed['delta_minus_xt'] = 'delta_minus cannot be larger than xt'\n",
    "\n",
    "        # 3. Check delta_plus <= 1-xt constraint\n",
    "        if torch.any(delta_plus > (1 - xt)):\n",
    "            failed['delta_plus_xt'] = 'delta_plus cannot be larger than 1-xt'\n",
    "\n",
    "        # 4. Check xt + delta_plus - delta_minus is in [0,1] and sums to ≤ 1\n",
    "        new_portfolio = xt + delta_plus - delta_minus\n",
    "        if torch.any((new_portfolio < 0) | (new_portfolio > 1)):\n",
    "            failed['new_portfolio_bounds'] = 'new portfolio weights must be in [0,1]'\n",
    "        if torch.sum(new_portfolio) > 1:\n",
    "            failed['portfolio_sum'] = 'portfolio weights must sum to at most 1'\n",
    "\n",
    "        # 5. Check bond holdings (bt) is in [0,1]\n",
    "        ct_value = 0.0 if ct is None else ct.item()\n",
    "        bt = normalized_bond_holdings(xt, delta_plus, delta_minus, tau, Delta_t, ct_value)\n",
    "        if bt < 0 or bt > 1:\n",
    "            failed['bond_holdings'] = f'bond holdings {bt:.4f} must be in [0,1]. xt: {xt}, delta_plus: {delta_plus}, delta_minus: {delta_minus})'\n",
    "\n",
    "        # 6. If consumption is included, check it's non-negative\n",
    "        if ct is not None and ct < 0:\n",
    "            failed['consumption'] = 'consumption must be non-negative'\n",
    "\n",
    "        return len(failed) == 0, failed\n",
    "\n",
    "    # usage function\n",
    "    def test_constraints(xt, delta_plus, delta_minus, tau, Delta_t, ct=None):\n",
    "        \"\"\"Prints a readable report of constraint satisfaction\"\"\"\n",
    "        satisfied, failed = check_portfolio_constraints(xt, delta_plus, delta_minus, tau, Delta_t, ct)\n",
    "\n",
    "        # print(\"Portfolio Constraint Check Results:\")\n",
    "        # if satisfied:\n",
    "        #     print(\"✓ All constraints satisfied!\")\n",
    "        # else:\n",
    "        #     print(\"✗ Some constraints failed:\")\n",
    "        #     for constraint, message in failed.items():\n",
    "        #         print(f\"  - {message}\")\n",
    "\n",
    "        return satisfied\n",
    "\n",
    "    def generate_feasible_initial_guess(\n",
    "        xt,\n",
    "        D,\n",
    "        tau,\n",
    "        c_min,\n",
    "        include_consumption=False,\n",
    "        convex_hull=None,\n",
    "        quadrature_nodes_weights=None,\n",
    "        t=None,\n",
    "        T=None,\n",
    "        beta=None,\n",
    "        gamma=None,\n",
    "        Delta_t=None,\n",
    "        Rf=None,\n",
    "        mu=None,\n",
    "        Sigma=None,\n",
    "        max_attempts=1500,\n",
    "        epsilon=1e-8  # Tolerance for determining if xt is inside NTR\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generates a feasible initial guess for the optimizer.\n",
    "        If convex_hull is provided, projects xt onto the convex hull and computes delta_plus and delta_minus accordingly.\n",
    "        If xt is inside the NTR, sets no change (delta_plus = delta_minus = 0).\n",
    "        Falls back to random generation (within constraints) if projection fails or constraints are not satisfied.\n",
    "\n",
    "        Args:\n",
    "            xt (torch.Tensor): Current state. Shape: [1, D]\n",
    "            D (int): Number of assets.\n",
    "            tau (float): Transaction cost rate.\n",
    "            c_min (float): Minimum consumption.\n",
    "            include_consumption (bool): Flag to include consumption.\n",
    "            convex_hull (scipy.spatial.ConvexHull or None): Convex hull defining the NTR.\n",
    "            quadrature_nodes_weights (tuple or None): Quadrature nodes and weights.\n",
    "            t (int): Current time step.\n",
    "            T (int): Total number of time periods.\n",
    "            beta (float): Discount factor.\n",
    "            gamma (float): Coefficient of relative risk aversion.\n",
    "            Delta_t (float): Time step size.\n",
    "            Rf (float): Risk-free rate factor.\n",
    "            mu (np.array): Mean vector for asset returns.\n",
    "            Sigma (np.array): Covariance matrix for asset returns.\n",
    "            max_attempts (int, optional): Maximum number of attempts to generate a feasible guess.\n",
    "            epsilon (float, optional): Tolerance for determining if xt is inside NTR.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Feasible initial guess vector.\n",
    "        \"\"\"\n",
    "        # Attempt projection onto convex hull if provided\n",
    "\n",
    "        #Clamp xt to avoid numerical issues\n",
    "        xt = torch.clamp(xt, 0.0, 1.0)\n",
    "\n",
    "        if convex_hull is not None:\n",
    "            xt_np = xt.cpu().numpy().flatten()\n",
    "            x_proj = project_onto_convex_hull(xt_np, convex_hull)\n",
    "            if x_proj is not None:\n",
    "                # Use a scaling factor to move towards the convex hull\n",
    "                scaling_factor = random.uniform(0.9, 1.0)  # Random scaling factor between 0.9 and 1.0\n",
    "                \n",
    "                # Apply scaling to projection\n",
    "                x_proj_scaled = xt_np + scaling_factor * (x_proj - xt_np)\n",
    "                \n",
    "                # Ensure scaled point is within bounds\n",
    "                x_proj_scaled = np.clip(x_proj_scaled, 0, 1)\n",
    "                \n",
    "                distance = np.linalg.norm(x_proj_scaled - xt_np)\n",
    "\n",
    "                if distance < epsilon:\n",
    "                    # xt is inside NTR; no change\n",
    "                    delta_plus = torch.zeros(D, dtype=torch.float64)  # Shape: [D]\n",
    "                    delta_minus = torch.zeros(D, dtype=torch.float64)  # Shape: [D]\n",
    "                else:\n",
    "                    # xt is outside NTR; compute delta based on projection\n",
    "                    delta_np = x_proj_scaled - xt_np  # Compute delta in numpy\n",
    "                    delta_plus_np = np.maximum(delta_np, 0)\n",
    "                    delta_minus_np = np.maximum(-delta_np, 0)\n",
    "\n",
    "                    delta_plus = torch.tensor(delta_plus_np, dtype=torch.float64)  # Shape: [D]\n",
    "                    delta_minus = torch.tensor(delta_minus_np, dtype=torch.float64)  # Shape: [D]\n",
    "\n",
    "                # Compute available cash after transactions (before consumption)\n",
    "                available_cash = 1.0 - torch.sum(xt) - (1 + tau) * torch.sum(delta_plus) + (1 - tau) * torch.sum(delta_minus)\n",
    "\n",
    "                if include_consumption:\n",
    "                    # Ensure there's enough cash for minimum consumption\n",
    "                    max_consumption = available_cash / Delta_t\n",
    "\n",
    "                    # Allocate a portion of available cash to consumption\n",
    "                    c_t_value = torch.rand(1).item() * (max_consumption - c_min) + c_min\n",
    "                    c_t = torch.tensor(c_t_value, dtype=torch.float64)  # Scalar tensor\n",
    "                else:\n",
    "                    c_t = torch.tensor(0.0, dtype=torch.float64)  # Scalar tensor\n",
    "\n",
    "                # Compute bond holdings after consumption\n",
    "                bt = available_cash - c_t * Delta_t\n",
    "\n",
    "                # Form the initial guess vector\n",
    "                deltas_concatenated = torch.cat([delta_plus, delta_minus])  # Shape: [2D]\n",
    "                if include_consumption:\n",
    "                    initial_guess = torch.cat([deltas_concatenated, c_t.unsqueeze(0)])  # Shape: [2D + 1]\n",
    "                else:\n",
    "                    initial_guess = deltas_concatenated  # Shape: [2D]\n",
    "\n",
    "                # Verify constraints\n",
    "                if test_constraints(xt, delta_plus, delta_minus, tau, Delta_t, c_t):\n",
    "                    return initial_guess\n",
    "\n",
    "            else:\n",
    "                # Projection failed, fall back to random generation\n",
    "                pass  # Proceed to random generation\n",
    "\n",
    "        # Fallback to random generation if projection fails or not provided\n",
    "        for attempt in range(max_attempts):\n",
    "            # Generate random delta_plus and delta_minus within feasible bounds\n",
    "            delta_plus = torch.clamp(torch.rand(D, dtype=torch.float64)* (1.0 - xt.squeeze(0)), 0., 1.) + 0.0  # Shape: [D]\n",
    "            delta_minus = torch.clamp(torch.rand(D, dtype=torch.float64)* xt.squeeze(0), 0., 1.) + 0.0    # Shape: [D]\n",
    "\n",
    "            # Ensure no simultaneous buying and selling\n",
    "            delta_diff = torch.min(delta_plus, delta_minus)\n",
    "            delta_plus -= delta_diff\n",
    "            delta_minus -= delta_diff\n",
    "\n",
    "            delta = delta_plus - delta_minus  # Shape: [D]\n",
    "            # Compute transaction costs\n",
    "            transaction_costs = tau * torch.sum(delta_plus) + tau * torch.sum(delta_minus)  # Scalar\n",
    "            # Compute available cash after transactions (before consumption)\n",
    "            available_cash = 1.0 - torch.sum(xt) - (1 + tau) * torch.sum(delta_plus) + (1 - tau) * torch.sum(delta_minus)\n",
    "\n",
    "            # Ensure available cash is non-negative\n",
    "            if available_cash < 0:\n",
    "                continue  # Invalid initial guess, try again\n",
    "\n",
    "            if include_consumption:\n",
    "                # Ensure there's enough cash for minimum consumption\n",
    "                max_consumption = available_cash / Delta_t\n",
    "                if max_consumption < c_min:\n",
    "                    continue  # Not enough wealth for minimum consumption\n",
    "\n",
    "                # Allocate a portion of available cash to consumption\n",
    "                c_t_value = torch.rand(1).item()* 0.95 * (max_consumption - c_min) + c_min\n",
    "                c_t = torch.tensor(c_t_value, dtype=torch.float64)  # Scalar tensor\n",
    "            else:\n",
    "                c_t = torch.tensor(0.0, dtype=torch.float64)  # Scalar tensor\n",
    "\n",
    "            # Compute bond holdings after consumption\n",
    "            bt = available_cash - c_t * Delta_t\n",
    "\n",
    "            # Ensure bond holdings are non-negative\n",
    "            if bt < 0:\n",
    "                continue  # Invalid initial guess, try again\n",
    "\n",
    "            # Form the initial guess vector\n",
    "            deltas_concatenated = torch.cat([delta_plus, delta_minus])  # Shape: [2D]\n",
    "            if include_consumption:\n",
    "                initial_guess = torch.cat([deltas_concatenated, c_t.unsqueeze(0)])  # Shape: [2D + 1]\n",
    "            else:\n",
    "                initial_guess = deltas_concatenated  # Shape: [2D]\n",
    "\n",
    "            # Verify constraints\n",
    "            if test_constraints(xt, delta_plus, delta_minus, tau, Delta_t, c_t):\n",
    "                return initial_guess\n",
    "\n",
    "        # If all attempts failed, raise an error\n",
    "        raise ValueError(f\"Failed to generate a feasible initial guess after max attempts. xt = {xt}\")\n",
    "\n",
    "\n",
    "    # Loop through multiple starting points #NOTE OPEN HERE IF WE NEED TO CHANGE SETTINGS\n",
    "    for start_idx in range(num_starts):\n",
    "        initial_guess = generate_feasible_initial_guess(xt, D, tau, c_min, include_consumption, convex_hull, quadrature_nodes_weights, t, T, beta, gamma, Delta_t, Rf, mu, Sigma)\n",
    "        # logging.debug(f\"Start {start_idx}: Initial guess generated.\")\n",
    "\n",
    "        try:\n",
    "            # Create the optimization problem\n",
    "            prob = PortfolioOptimization(\n",
    "                D,\n",
    "                xt,\n",
    "                vt_next_in,\n",
    "                vt_next_out,\n",
    "                t,\n",
    "                T,\n",
    "                beta,\n",
    "                gamma,\n",
    "                Delta_t,\n",
    "                tau,\n",
    "                Rf,\n",
    "                mu=mu,\n",
    "                Sigma=Sigma,\n",
    "                c_min=c_min,\n",
    "                include_consumption=include_consumption,\n",
    "                convex_hull=convex_hull,\n",
    "                quadrature_nodes_weights=quadrature_nodes_weights,  # Pass quadrature data\n",
    "                integration_method=integration_method,\n",
    "                num_mc_samples=num_mc_samples\n",
    "            )\n",
    "\n",
    "            # Set IPOPT options\n",
    "            prob.add_option(\"tol\", 1e-6)\n",
    "            prob.add_option(\"acceptable_tol\", 1e-5)\n",
    "            prob.add_option(\"max_iter\", 600)\n",
    "            prob.add_option(\"linear_solver\", \"mumps\")  # Use an efficient sparse solver\n",
    "            prob.add_option(\"print_level\", 2)\n",
    "            prob.add_option(\"honor_original_bounds\", \"yes\") #yes is default\n",
    "            prob.add_option(\"mu_strategy\", \"adaptive\")        # adaptive, monotone\n",
    "            prob.add_option(\"mu_oracle\", \"quality-function\")  # Control step quality. 'probing', 'quality-function', 'loqo', 'monotone', 'mixed'.\n",
    "            prob.add_option(\"line_search_method\", \"filter\")        # filter, cg-penalty , penalty (note only filter officially suported!?)\n",
    "            prob.add_option('jacobian_approximation', 'exact') #exact, finite-difference-values\n",
    "            prob.add_option(\"hessian_approximation\", 'limited-memory')  # limited-memory, exact\n",
    "            # prob.add_option(\"max_resto_iter\", 750)\n",
    "            prob.add_option(\"max_resto_iter\", 0) #No restoration phase might increase performance\n",
    "            prob.add_option(\"sb\", \"yes\") #Omit annoying header\n",
    "            # prob.add_option(\"warm_start_init_point\", \"yes\")\n",
    "            prob.add_option(\"nlp_scaling_method\", \"gradient-based\") #gradient-based, none\n",
    "            # prob.add_option(\"constr_viol_tol\", 1e-6)  # Tighten constraint violation tolerance\n",
    "            # prob.add_option(\"dual_inf_tol\", 1e-6)  # Tighten dual infeasibility tolerance\n",
    "            # prob.add_option(\"compl_inf_tol\", 1e-6)  # Tighten complementarity tolerance\n",
    "\n",
    "            solution, info = prob.solve(initial_guess.cpu().numpy())\n",
    "\n",
    "            # Check if the solution is not valid\n",
    "            if solution is None:\n",
    "                logging.warning(f\"Start {start_idx}: Solver returned None solution.\")\n",
    "                failed_attempts += 1\n",
    "                if failed_attempts > max_failed_attempts:\n",
    "                    logging.error(f\"Exceeded maximum allowed failed attempts: {max_failed_attempts}\")\n",
    "                    if include_consumption:\n",
    "                        return None, None, None, None, None, None\n",
    "                    else:\n",
    "                        return None, None, None, None, None\n",
    "                continue\n",
    "\n",
    "            # Check if the solution is valid\n",
    "            if solution is not None and info['status'] == 0:  # Success condition\n",
    "                successful_attempts += 1\n",
    "                logging.info(f\"Start {start_idx}: Successful solution found. Successful attempts: {successful_attempts}\")\n",
    "\n",
    "            # Check if this solution is better than the current best\n",
    "            if info['status'] == 0 and (best_solution is None or info['obj_val'] > best_obj_val):\n",
    "                best_solution = solution\n",
    "                best_obj_val = info['obj_val']\n",
    "                logging.info(f\"Start {start_idx}: New best solution found with obj_val: {best_obj_val}\")\n",
    "\n",
    "                # Check if the number of successful attempts has reached the threshold\n",
    "                if successful_attempts >= max_successful_attempts:\n",
    "                    logging.info(f\"Early stopping after {successful_attempts} successful attempts.\")\n",
    "                    break  # Exit the loop early\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Optimization failed for start {start_idx}: {e}\")\n",
    "            logging.error(f\"Optimization failed for start {start_idx}: {e}\", exc_info=True)\n",
    "            failed_attempts += 1\n",
    "            if failed_attempts > max_failed_attempts:\n",
    "                print(f\"Exceeded maximum allowed failed attempts: {max_failed_attempts}\")\n",
    "                logging.error(f\"Exceeded maximum allowed failed attempts: {max_failed_attempts}\")\n",
    "                if include_consumption:\n",
    "                    return None, None, None, None, None, None\n",
    "                else:\n",
    "                    return None, None, None, None, None\n",
    "            continue\n",
    "\n",
    "    if best_solution is None:\n",
    "        print(f\"No optimizer solution found for point {xt}!\")\n",
    "        # logging.error(f\"No optimizer solution found for point {xt}!\")\n",
    "        if include_consumption:\n",
    "            return None, None, None, None, None, None\n",
    "        else:\n",
    "            return None, None, None, None, None\n",
    "    try:\n",
    "        # After finding the best solution, extract the variables\n",
    "        idx = 0\n",
    "        delta_plus_opt = best_solution[idx : idx + D]          # Shape: [D]\n",
    "        delta_minus_opt = best_solution[idx + D : idx + 2 * D]  # Shape: [D]\n",
    "        if include_consumption:\n",
    "            ct_opt = best_solution[idx + 2 * D]                    # Scalar\n",
    "        delta_opt = delta_plus_opt - delta_minus_opt          # Shape: [D]\n",
    "\n",
    "        # Convert delta_plus_opt and delta_minus_opt to tensors and reshape to [1, D]\n",
    "        delta_plus_tensor = torch.tensor(delta_plus_opt, dtype=torch.float64).unsqueeze(0)   # [1, D]\n",
    "        delta_minus_tensor = torch.tensor(delta_minus_opt, dtype=torch.float64).unsqueeze(0) # [1, D]\n",
    "\n",
    "        if include_consumption:\n",
    "            c_t_tensor = torch.tensor(ct_opt, dtype=torch.float64).unsqueeze(0)  # Shape: [1]\n",
    "        else:\n",
    "            c_t_tensor = torch.tensor([0.0], dtype=torch.float64)  # Shape: [1]\n",
    "\n",
    "        # Compute omega_i_t and bond holdings (bt)\n",
    "        omega_i_t = xt.cpu().numpy() + delta_opt                                            # [1, D] + [D] -> [1, D]\n",
    "        bt = normalized_bond_holdings(\n",
    "            xt, delta_plus_tensor, delta_minus_tensor, tau, c_t_tensor, include_consumption\n",
    "        ).item()\n",
    "\n",
    "        torch.set_printoptions(sci_mode=False, precision=4)\n",
    "        np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "        del prob\n",
    "\n",
    "        torch.cuda.empty_cache()  # If using CUDA\n",
    "\n",
    "        if include_consumption:\n",
    "            ct_opt = np.round(ct_opt, 4)\n",
    "            return delta_plus_opt, delta_minus_opt, delta_opt, omega_i_t, bt, ct_opt\n",
    "        else:\n",
    "            return delta_plus_opt, delta_minus_opt, delta_opt, omega_i_t, bt\n",
    "    except Exception as e:\n",
    "        # logging.error(f\"Error processing best solution: {e}\", exc_info=True)\n",
    "        if include_consumption:\n",
    "            return None, None, None, None, None, None\n",
    "        else:\n",
    "            return None, None, None, None, None\n",
    "\n",
    "def approximate_ntr(vt_next_in, vt_next_out, D, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min,include_consumption=False, quadrature_nodes_weights=None,integration_method = 'quadrature', num_mc_samples = 1000,):\n",
    "    \"\"\"\n",
    "    Approximates the Non-Trading Region (NTR) at time t.\n",
    "\n",
    "    Args:\n",
    "        vt_next_in (gpytorch.models.ExactGP or callable): Value function for inside NTR.\n",
    "        vt_next_out (gpytorch.models.ExactGP or callable): Value function for outside NTR.\n",
    "        D (int): Number of assets.\n",
    "        t (int): Current time step.\n",
    "        T (int): Total number of time periods.\n",
    "        beta (float): Discount factor.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "        tau (float): Transaction cost rate.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        mu (np.array): Mean vector for asset returns.\n",
    "        Sigma (np.array): Covariance matrix for asset returns.\n",
    "        include_consumption (bool): Flag to include consumption.\n",
    "        quadrature_nodes_weights (tuple): Quadrature nodes and weights.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (tilde_omega_t, convex_hull)\n",
    "    \"\"\"\n",
    "    # Step 1: Sample state points at vertices and midpoints\n",
    "    tilde_X_t = sample_state_points(D)  # Shape: [num_points, D]\n",
    "    N = tilde_X_t.size(0)\n",
    "    tilde_omega_t = []\n",
    "    convex_hull = None  # Initialize convex_hull\n",
    "\n",
    "    for i in range(N):\n",
    "        tilde_x_i_t = tilde_X_t[i:i+1]  # Shape: [1, D]\n",
    "        solution = solve_bellman_with_ipopt(\n",
    "            D, tilde_x_i_t.squeeze(0), vt_next_in, vt_next_out, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma,\n",
    "            c_min,convex_hull=None,\n",
    "            quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "            include_consumption=include_consumption,\n",
    "            integration_method = integration_method, num_mc_samples = num_mc_samples,\n",
    "        )\n",
    "        if include_consumption:\n",
    "            delta_plus, delta_minus, delta_opt, omega_i_t, bt, ct_opt = solution\n",
    "        else:\n",
    "            delta_plus, delta_minus, delta_opt, omega_i_t, bt = solution\n",
    "\n",
    "        if delta_plus is None:\n",
    "            print(f\"Delta is None for point {tilde_x_i_t}\")\n",
    "            continue\n",
    "\n",
    "        tilde_omega_i_t = (tilde_x_i_t + delta_plus - delta_minus).numpy()\n",
    "        tilde_omega_t.append(tilde_omega_i_t.squeeze(0))\n",
    "\n",
    "    # Construct convex hull\n",
    "    if len(tilde_omega_t) >= D + 1:\n",
    "        tilde_omega_t = np.vstack(tilde_omega_t)  # Shape: [num_points, D]\n",
    "        convex_hull = ConvexHull(tilde_omega_t)\n",
    "    else:\n",
    "        convex_hull = None\n",
    "\n",
    "    return tilde_omega_t, convex_hull\n",
    "\n",
    "def process_ntr_point(tilde_x_i_t, vt_next_in, vt_next_out, D, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min, include_consumption, quadrature_nodes_weights, integration_method, num_mc_samples):\n",
    "    \"\"\"\n",
    "    Processes a single NTR point by solving the optimization problem.\n",
    "\n",
    "    Args:\n",
    "        tilde_x_i_t (torch.Tensor): Current NTR state vector. Shape: [D]\n",
    "\n",
    "    Returns:\n",
    "        np.array: Processed NTR point.\n",
    "    \"\"\"\n",
    "    solution = solve_bellman_with_ipopt(\n",
    "        D, tilde_x_i_t, vt_next_in, vt_next_out, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min,\n",
    "        include_consumption=include_consumption,\n",
    "        quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "        integration_method=integration_method, num_mc_samples=num_mc_samples\n",
    "    )\n",
    "\n",
    "    if solution[0] is None:\n",
    "        return None  # Indicate failure\n",
    "    if include_consumption:\n",
    "        delta_plus, delta_minus, delta_opt, omega_i_t, bt, ct_opt = solution\n",
    "    else:\n",
    "        delta_plus, delta_minus, delta_opt, omega_i_t, bt = solution\n",
    "    # delta_plus, delta_minus, *_ = solution\n",
    "    return (tilde_x_i_t + delta_plus - delta_minus).numpy()  # Return transformed point\n",
    "\n",
    "def approximate_ntr_parallel(vt_next_in, vt_next_out, D, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min, include_consumption, quadrature_nodes_weights, integration_method, num_mc_samples,backendtype):\n",
    "    \"\"\"\n",
    "    Approximates the NTR with parallel processing.\n",
    "    \"\"\"\n",
    "    tilde_X_t = sample_state_points(D)  # Shape: [num_points, D]\n",
    "    num_jobs = 3  # Limit to available cores\n",
    "\n",
    "    # Parallel processing of NTR points\n",
    "    tilde_omega_t = Parallel(n_jobs=num_jobs, backend=backendtype)(\n",
    "        delayed(process_ntr_point)(\n",
    "            tilde_x_i_t, vt_next_in, vt_next_out, D, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min,\n",
    "            include_consumption, quadrature_nodes_weights, integration_method, num_mc_samples\n",
    "        ) for tilde_x_i_t in tilde_X_t\n",
    "    )\n",
    "\n",
    "    # Filter out failed solutions and form convex hull\n",
    "    tilde_omega_t = [pt for pt in tilde_omega_t if pt is not None]\n",
    "    if len(tilde_omega_t) >= D + 1:\n",
    "        tilde_omega_t = np.vstack(tilde_omega_t)\n",
    "        convex_hull = ConvexHull(tilde_omega_t)\n",
    "    else:\n",
    "        convex_hull = None\n",
    "\n",
    "    return tilde_omega_t, convex_hull\n",
    "\n",
    "def process_point(\n",
    "    x_i_t,\n",
    "    quadrature_nodes_weights,\n",
    "    V_t_plus1_in,\n",
    "    V_t_plus1_out,\n",
    "    t,\n",
    "    T,\n",
    "    beta,\n",
    "    gamma,\n",
    "    Delta_t,\n",
    "    tau,\n",
    "    Rf,\n",
    "    mu,\n",
    "    Sigma,\n",
    "    c_min,\n",
    "    NTR_t,\n",
    "    D,\n",
    "    include_consumption=False,\n",
    "    integration_method = 'quadrature', num_mc_samples = 1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a single state point by solving the optimization problem.\n",
    "\n",
    "    Args:\n",
    "        x_i_t (torch.Tensor): Current state vector. Shape: [D]\n",
    "        quadrature_nodes_weights (tuple): Quadrature nodes and weights.\n",
    "        V_t_plus1_in (gpytorch.models.ExactGP or callable): Value function for inside NTR.\n",
    "        V_t_plus1_out (gpytorch.models.ExactGP or callable): Value function for outside NTR.\n",
    "        t (int): Current time step.\n",
    "        T (int): Total number of time periods.\n",
    "        beta (float): Discount factor.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "        tau (float): Transaction cost rate.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        mu (np.array): Mean vector for asset returns.\n",
    "        Sigma (np.array): Covariance matrix for asset returns.\n",
    "        NTR_t (ConvexHull or None): Convex hull defining the NTR.\n",
    "        D (int): Number of assets.\n",
    "        include_consumption (bool): Flag to include consumption.\n",
    "\n",
    "    Returns:\n",
    "        tuple or None:\n",
    "            If include_consumption=True: (x_i_t, v_i_t_value, in_ntr_value, c_t)\n",
    "            Else: (x_i_t, v_i_t_value, in_ntr_value)\n",
    "            If unsuccessful, returns None.\n",
    "    \"\"\"\n",
    "    # logging.info(f\"Step 2c: Solve optimization problem for point {x_i_t}\")\n",
    "    torch.set_printoptions(sci_mode=False, precision=4)\n",
    "    np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    solution = solve_bellman_with_ipopt(\n",
    "        D, x_i_t, V_t_plus1_in, V_t_plus1_out, t, T, beta, gamma,Delta_t, tau,Rf, mu, Sigma,c_min,\n",
    "        convex_hull=NTR_t,\n",
    "        quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "        include_consumption=include_consumption,\n",
    "        integration_method = integration_method, num_mc_samples = num_mc_samples\n",
    "    )\n",
    "\n",
    "    if include_consumption:\n",
    "        delta_plus, delta_minus, delta_opt, omega_i_t, bt, ct_opt = solution\n",
    "    else:\n",
    "        delta_plus, delta_minus, delta_opt, omega_i_t, bt = solution\n",
    "\n",
    "    if delta_plus is None:\n",
    "        # logging.warning(f\"Step 2c: Optimization failed for point {x_i_t}. Skipping.\")\n",
    "        return None  # Indicate failure\n",
    "\n",
    "    if include_consumption:\n",
    "        print(f\"Best solution found. Point {x_i_t}, Delta+: {delta_plus}, Delta-: {delta_minus}, \"\n",
    "              f\"Delta: {delta_opt}, Omega: {omega_i_t}, bt: {np.round(bt, 4)}, Consumption: {ct_opt}\")\n",
    "        # logging.info(f\"Time: {t}, Point: {x_i_t}, Delta+: {delta_plus}, Delta-: {delta_minus}, \"\n",
    "                    #  f\"Delta: {delta_opt}, Omega: {omega_i_t}, bt: {bt}, Consumption: {ct_opt}\")\n",
    "    else:\n",
    "        print(f\"Best solution found. Point {x_i_t}, Delta+: {delta_plus}, Delta-: {delta_minus}, \"\n",
    "              f\"Delta: {delta_opt}, Omega: {omega_i_t}, bt: {np.round(bt, 4)}\")\n",
    "        # logging.info(f\"Time: {t}, Point: {x_i_t}, Delta+: {delta_plus}, Delta-: {delta_minus}, \"\n",
    "                    #  f\"Delta: {delta_opt}, Omega: {omega_i_t}, bt: {bt}\")\n",
    "\n",
    "    # Compute value using the Bellman equation\n",
    "    x_i_t_tensor = x_i_t.unsqueeze(0)  # [1, D]\n",
    "    delta_plus_tensor = torch.tensor(delta_plus, dtype=torch.float64).unsqueeze(0)    # [1, D]\n",
    "    delta_minus_tensor = torch.tensor(delta_minus, dtype=torch.float64).unsqueeze(0)  # [1, D]\n",
    "\n",
    "    if include_consumption:\n",
    "        ct_tensor = torch.tensor(ct_opt, dtype=torch.float64).unsqueeze(0)  # Shape: [1]\n",
    "    else:\n",
    "        ct_tensor = torch.tensor([0.0], dtype=torch.float64)  # Shape: [1]\n",
    "\n",
    "    v_i_t = bellman_equation(\n",
    "        V_t_plus1_in, V_t_plus1_out, x_i_t_tensor, delta_plus_tensor, delta_minus_tensor,\n",
    "        beta, gamma,Delta_t, tau, Rf, ct=ct_tensor, include_consumption=include_consumption,\n",
    "        convex_hull=NTR_t, t=t, mu=mu, Sigma=Sigma,\n",
    "        quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "        integration_method = integration_method, num_mc_samples = num_mc_samples\n",
    "    )\n",
    "\n",
    "    # Determine if the point is inside the NTR\n",
    "    with torch.no_grad():\n",
    "        in_ntr = is_in_ntr(\n",
    "            x_i_t_tensor, NTR_t, delta_plus_tensor, delta_minus_tensor, t=t\n",
    "        )\n",
    "\n",
    "    # Prepare the result\n",
    "    if include_consumption:\n",
    "        result = (x_i_t, v_i_t.item(), in_ntr.item(), ct_opt)\n",
    "    else:\n",
    "        result = (x_i_t, v_i_t.item(), in_ntr.item())\n",
    "\n",
    "    # Clean up\n",
    "    del delta_plus_tensor, delta_minus_tensor, v_i_t\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "\n",
    "    T = 6       # Number of time period (years)\n",
    "    Delta_t = 1.0 # time step (in years). Delta_t = T/M <=> M = T/Delta_t\n",
    "    M = int(T/Delta_t) # needs to be integer for the range function\n",
    "    # rho = 0.1 # Utility discount rate, see Cai Judd Xu.\n",
    "    # beta = np.exp(-rho*Delta_t)\n",
    "    beta = 0.97\n",
    "    tau = 0.005\n",
    "\n",
    "    Schober_Parameters = False #Parameters of Schober 2020 \n",
    "    Cai_Judd_Identical = False #Assumes a correlation coefficent of 0\n",
    "    Cai_Judd_High_Correlation = True #Assumes a correlation coefficient of 0.75\n",
    "\n",
    "    if Schober_Parameters:\n",
    "        gamma = 3.5\n",
    "        r = np.log(1.0408)\n",
    "        mu = np.array([0.0572, 0.0638, 0.07, 0.0764, 0.0828])\n",
    "        Sigma = np.array([\n",
    "                        [0.0256, 0.00576, 0.00288, 0.00176, 0.00096], \n",
    "                        [0.00576, 0.0324, 0.0090432, 0.010692, 0.01296],\n",
    "                        [0.00288, 0.0090432, 0.04, 0.0132, 0.0168],\n",
    "                        [0.00176, 0.010692, 0.0132, 0.0484, 0.02112],\n",
    "                        [0.00096, 0.01296, 0.0168, 0.02112, 0.0576]\n",
    "                        ])\n",
    "    if Cai_Judd_Identical:\n",
    "        gamma = 3.0\n",
    "        r = np.log(np.round(np.exp(0.03),4))\n",
    "        mu = np.array([0.07, 0.07, 0.07, 0.07,0.07])\n",
    "        Sigma = np.array([\n",
    "                        [0.04, 0.00, 0.00, 0.00, 0.00], \n",
    "                        [0.00, 0.04, 0.00, 0.00, 0.00],\n",
    "                        [0.00, 0.00, 0.04, 0.00, 0.00],\n",
    "                        [0.00, 0.00, 0.00, 0.04, 0.00],\n",
    "                        [0.00, 0.00, 0.00, 0.00, 0.04]\n",
    "                        ])\n",
    "    if Cai_Judd_High_Correlation:\n",
    "        gamma = 3.0\n",
    "        r = np.log(np.round(np.exp(0.03),4))\n",
    "        mu = np.array([0.07, 0.07, 0.07, 0.07,0.07])\n",
    "        Sigma = np.array([\n",
    "                        [0.04, 0.03, 0.03, 0.03, 0.03], \n",
    "                        [0.03, 0.04, 0.03, 0.03, 0.03],\n",
    "                        [0.03, 0.03, 0.04, 0.03, 0.03],\n",
    "                        [0.03, 0.03, 0.03, 0.04, 0.03],\n",
    "                        [0.03, 0.03, 0.03, 0.03, 0.04]\n",
    "                        ])\n",
    "    Rf = np.exp(r*Delta_t)\n",
    "\n",
    "\n",
    "    def select_mu_sigma(mu, Sigma, D):\n",
    "        \"\"\"\n",
    "        Selects the first D elements from mu and the corresponding D x D submatrix from Sigma.\n",
    "        \"\"\"\n",
    "        selected_mu = mu[:D]\n",
    "        selected_Sigma = Sigma[:D, :D]\n",
    "        return selected_mu, selected_Sigma\n",
    "\n",
    "    D = 2\n",
    "    mu, Sigma = select_mu_sigma(mu, Sigma, D)\n",
    "    refinement = np.array([3 * D] * D)\n",
    "\n",
    "    N = 50 * D  # Number of state points to sample\n",
    "\n",
    "    include_consumption = False  # Set to False if consumption is not included\n",
    "    c_min = 1e-6  # Minimum consumption for numerical stability\n",
    "    if not include_consumption:\n",
    "        c_min = 0.0\n",
    "\n",
    "    integration_method = 'quadrature' # 'quadrature' or 'monte_carlo' 'quasi_monte_carlo'\n",
    "    num_mc_samples = 1000\n",
    "\n",
    "    # number_of_quadrature_points = 5 # In each dimension #Only for old quad\n",
    "    merton_p = MertonPoint(mu, Sigma, r, gamma)\n",
    "\n",
    "    # Print all parameters when running the script\n",
    "    do_print = True\n",
    "    if do_print:\n",
    "        print(\"===== Dynamic Portfolio Optimization Parameters =====\")\n",
    "        print(f\"Number of Assets (D): {D}\")\n",
    "        print(f\"Total Years (T): {T}\")\n",
    "        print(f\"Time Step Size (Delta_t): {Delta_t}\")\n",
    "        print(f\"Number of Time Steps (step size * T): {M}\")\n",
    "        print(f\"Discount Factor (beta): {beta}\")\n",
    "        print(f\"Relative Risk Aversion (gamma): {gamma}\")\n",
    "        print(f\"Transaction Cost Rate (tau): {tau}\")\n",
    "        print(f\"Yearly Net Risk-Free Rate (r): {r}\")\n",
    "        print(f\"Expected Yearly Net Returns (mu): {mu}\")\n",
    "        print(f\"Covariance Matrix (Sigma):\\n{Sigma}\")\n",
    "        print(f\"Include Consumption: {include_consumption}\")\n",
    "        print(f\"Minimum Consumption (c_min): {c_min}\")\n",
    "        print(f\"Number of State Points (N): {N}\")\n",
    "        print(f\"merton_p: {merton_p}\")\n",
    "        print(f\"Integration Method: {integration_method}\")\n",
    "        print(\"==============================================\\n\")\n",
    "\n",
    "    # Initialize value function V\n",
    "    V = [[None, None] for _ in range(M + 1)]\n",
    "\n",
    "    # Set terminal value function\n",
    "    V[M][0] = lambda x: V_terminal(x, tau, gamma,r,Delta_t)  # For inside NTR\n",
    "    V[M][1] = lambda x: V_terminal(x, tau, gamma,r,Delta_t)  # For outside NTR\n",
    "\n",
    "    NTR = [None for _ in range(M)]  # Store NTR for each period\n",
    "\n",
    "    # Generate quadrature nodes and weights using helper functions\n",
    "    # n_q = number_of_quadrature_points  # Number of quadrature points per dimension (adjust as needed)\n",
    "    sparse = False\n",
    "\n",
    "    # nodes, weights, L = gauss_hermite_quadrature(n_q, mu, Sigma, Delta_t)\n",
    "    # expnodes, weights, L = gauss_hermite_log_normal_quadrature(n_q, mu, Sigma, Delta_t)\n",
    "    expnodes, weights, L = TasmanianSGLogQuadNorm(refinement, mu, Sigma)\n",
    "    quadrature_nodes_weights = (expnodes, weights, L)  # Include L for scaling\n",
    "    backendtype = 'threading' # Type of parallelization 'threading' or 'loky'\n",
    "    for t in reversed(range(M)):\n",
    "        print(f\"Time step {t}\")\n",
    "\n",
    "        include_consumption = include_consumption\n",
    "        print(f\"include consumption: {include_consumption}\")\n",
    "        # Step 2a: Approximate NTR\n",
    "        print(\"Step 2a: Approximate NTR\")\n",
    "        tilde_omega_t, convex_hull = approximate_ntr_parallel(\n",
    "            vt_next_in=V[t+1][0],\n",
    "            vt_next_out=V[t+1][1],\n",
    "            D=D,\n",
    "            t=t,\n",
    "            T=T,\n",
    "            beta=beta,\n",
    "            gamma=gamma,\n",
    "            Delta_t=Delta_t,\n",
    "            tau=tau,\n",
    "            Rf=Rf,\n",
    "            mu=mu,\n",
    "            Sigma=Sigma,\n",
    "            c_min=c_min,\n",
    "            include_consumption=include_consumption,\n",
    "            quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "            integration_method=integration_method,\n",
    "            num_mc_samples=num_mc_samples,\n",
    "            backendtype=backendtype\n",
    "        )\n",
    "\n",
    "        NTR[t] = convex_hull\n",
    "        print(tilde_omega_t)\n",
    "\n",
    "        print(f\"len tilde_omega_t: {len(tilde_omega_t)}\")\n",
    "        # Step 2b: Sample state points\n",
    "        print(\"Step 2b: Sample state points\")\n",
    "        # i sample points with a new seed at each iteration!\n",
    "        points_inside_ntr, points_around_kinks, points_outside_ntr = sample_points_around_ntr_separated(tilde_omega_t, N,seed=121001-t)\n",
    "        all_points = np.vstack([points_inside_ntr, points_around_kinks, points_outside_ntr])\n",
    "        shuffled_indices = np.random.permutation(all_points.shape[0])\n",
    "        # Reorder the points using the shuffled indices\n",
    "        all_points = all_points[shuffled_indices]\n",
    "        #Round the points to 8 decimals\n",
    "        all_points = np.round(all_points, 8)\n",
    "        X_t = torch.tensor(all_points[:N], dtype=torch.float64)\n",
    "        X_t = torch.tensor(all_points, dtype=torch.float64)\n",
    "\n",
    "        data_in = []\n",
    "        data_out = []\n",
    "\n",
    "        # Step 2c: Parallel processing of points\n",
    "        num_jobs = 2  # NEVER use all cores. num_jobs should be <= N # NOTE threading / loky backend . loky is faster\n",
    "        results = Parallel(n_jobs=num_jobs, backend=backendtype)(\n",
    "            delayed(process_point)(\n",
    "                x_i_t,\n",
    "                V_t_plus1_in=V[t+1][0],\n",
    "                V_t_plus1_out=V[t+1][1],\n",
    "                t=t,\n",
    "                T=T,\n",
    "                beta=beta,\n",
    "                gamma=gamma,\n",
    "                Delta_t=Delta_t,\n",
    "                tau=tau,\n",
    "                Rf=Rf,\n",
    "                mu=mu,\n",
    "                Sigma=Sigma,\n",
    "                c_min=c_min,\n",
    "                NTR_t=NTR[t],\n",
    "                D=D,\n",
    "                include_consumption=include_consumption,\n",
    "                quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "                integration_method=integration_method,\n",
    "                num_mc_samples=num_mc_samples\n",
    "            ) for x_i_t in X_t\n",
    "        )\n",
    "\n",
    "        # Process the results\n",
    "        for result in results:\n",
    "            if result is None:\n",
    "                continue\n",
    "            if include_consumption:\n",
    "                x_i_t, v_i_t_value, in_ntr_value, c_t = result\n",
    "            else:\n",
    "                x_i_t, v_i_t_value, in_ntr_value = result\n",
    "            if in_ntr_value:\n",
    "                data_in.append((x_i_t, v_i_t_value))\n",
    "                # Optionally, store c_t if needed\n",
    "            else:\n",
    "                data_out.append((x_i_t, v_i_t_value))\n",
    "                # Optionally, store c_t if needed\n",
    "\n",
    "        # Step 2e: Train GPR models for inside and outside NTR (V_{t+1}^{in/out})\n",
    "        print(\"Step 2e: Train GPR models for inside and outside NTR\")\n",
    "        if data_in:\n",
    "            train_x_in = torch.stack([d[0] for d in data_in])  # [num_in, D]\n",
    "            train_y_in = torch.tensor([d[1] for d in data_in], dtype=torch.float64)  # [num_in]\n",
    "            model_in, likelihood_in = train_gp_model(train_x_in, train_y_in)\n",
    "            V[t][0] = model_in\n",
    "            print(f\"train gp model_in done \")\n",
    "\n",
    "        if data_out:\n",
    "            train_x_out = torch.stack([d[0] for d in data_out]) # [num_out, D]\n",
    "            train_y_out = torch.tensor([d[1] for d in data_out], dtype=torch.float64) # [num_out]\n",
    "            model_out, likelihood_out = train_gp_model(train_x_out, train_y_out)\n",
    "            V[t][1] = model_out\n",
    "            print(f\"train gp model_out done\")\n",
    "\n",
    "        # Clear previous value functions to free memory\n",
    "        if t < T - 1:\n",
    "            if V[t+1][0] is not None:\n",
    "                del V[t+1]\n",
    "\n",
    "        # Clear other variables if necessary\n",
    "        del data_in, data_out, train_x_in, train_y_in, train_x_out, train_y_out\n",
    "        torch.cuda.empty_cache()  # If using CUDA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the NTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTR array saved to NTRs/NTR_Cai_High_Correlation_d2_tau_0.005__no_consumption.pkl\n"
     ]
    }
   ],
   "source": [
    "def save_ntr_array_to_file(NTR, filename_prefix, D, tau,include_consumption):\n",
    "    \"\"\"\n",
    "    Saves the NTR array to a file with a dynamically generated name using pickle in the \"NTRs\" folder.\n",
    "\n",
    "    Parameters:\n",
    "    - NTR: List of ConvexHull objects (or None).\n",
    "    - filename_prefix: A string to indicate the parameter set (e.g., \"Schober_Parameters\").\n",
    "    - D: The number of assets (dimensionality).\n",
    "    - tau: The transaction cost rate.\n",
    "\n",
    "    The file will be named `NTR_<filename_prefix>_d<D>_tau_<tau>.pkl` and saved in the \"NTRs\" folder.\n",
    "    \"\"\"\n",
    "    # Ensure the \"NTRs\" folder exists\n",
    "    os.makedirs(\"NTRs\", exist_ok=True)\n",
    "\n",
    "    if include_consumption:\n",
    "        consumption = \"_with_consumption\"\n",
    "    else:\n",
    "        consumption = \"_no_consumption\"\n",
    "\n",
    "    # Construct the full file path\n",
    "    filename = f\"NTRs/NTR_{filename_prefix}_d{D}_tau_{tau}_{consumption}.pkl\"\n",
    "\n",
    "    # Save the NTR array using pickle\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(NTR, file)\n",
    "    print(f\"NTR array saved to {filename}\")\n",
    "\n",
    "def load_ntr_array_from_file(filename):\n",
    "    \"\"\"\n",
    "    Loads the NTR array from a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: The name of the file to load.\n",
    "\n",
    "    Returns:\n",
    "    - The NTR array (list of ConvexHull objects or None).\n",
    "    \"\"\"\n",
    "    # Ensure the \"NTRs\" folder exists\n",
    "    os.makedirs(\"NTRs\", exist_ok=True)\n",
    "\n",
    "    # Construct the full file path\n",
    "    full_filename = os.path.join(\"NTRs\", filename)\n",
    "\n",
    "    with open(full_filename, \"rb\") as file:\n",
    "        NTR = pickle.load(file)\n",
    "    print(f\"NTR array loaded from {full_filename}\")\n",
    "    return NTR\n",
    "\n",
    "# Choose the parameter prefix based on the active parameter set\n",
    "if Schober_Parameters:\n",
    "    filename_prefix = \"Schober_Parameters\"\n",
    "elif Cai_Judd_Identical:\n",
    "    filename_prefix = \"Cai_Identical\"\n",
    "elif Cai_Judd_High_Correlation:\n",
    "    filename_prefix = \"Cai_High_Correlation\"\n",
    "else:\n",
    "    filename_prefix = \"Unknown_Parameters\"\n",
    "\n",
    "save_ntr_array_to_file(NTR, filename_prefix, D, tau,include_consumption)\n",
    "# NTR = load_ntr_array_from_file(f\"NTR_Cai_Identical_d2_tau_0.001__no_consumption.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Quasi Monte Carlo (Sobol) integral over R_t samples: [1.062  1.0619]\n",
      "Monte Carlo integral over R_t samples: [1.0634 1.0708]\n",
      "Quasi Monte Carlo (Halton) integral over R_t samples: [1.0613 1.0611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Peytz2/lib/python3.11/site-packages/scipy/stats/_qmc.py:958: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  sample = self._random(n, workers=workers)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"MC\", low_discrepancy=\"sobol\"):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo, Quasi Monte Carlo, or Randomized Quasi Monte Carlo integration\n",
    "    for multivariate normal distributions.\n",
    "\n",
    "    Parameters:\n",
    "        mu (np.array): Mean vector for the normal distribution.\n",
    "        Sigma (np.array): Covariance matrix.\n",
    "        Delta_t (float): Time step.\n",
    "        num_mc_samples (int): Number of Monte Carlo samples.\n",
    "        method (str): Sampling method - \"MC\" for Monte Carlo, \"QMC\" for Quasi-Monte Carlo, \"RQMC\" for Randomized QMC.\n",
    "        low_discrepancy (str): Low discrepancy sequence method for QMC - \"sobol\" or \"halton\".\n",
    "\n",
    "    Returns:\n",
    "        mc_integral_Rt (torch.Tensor): Monte Carlo integral approximation for E[R_t].\n",
    "    \"\"\"\n",
    "\n",
    "    # Adjusted mean according to Cai, Judd, Xu (2013)\n",
    "    adjusted_mu = torch.tensor(mu * Delta_t - 0.5 * np.diag(Sigma) * Delta_t, dtype=torch.float64)\n",
    "\n",
    "    # Sampling\n",
    "    if method == \"MC\":\n",
    "        # Standard Monte Carlo sampling\n",
    "        standard_normal_samples = torch.randn((num_mc_samples, len(mu)), dtype=torch.float64)\n",
    "\n",
    "    elif method == \"QMC\":\n",
    "        # Quasi-Monte Carlo (deterministic)\n",
    "        if low_discrepancy == \"sobol\":\n",
    "            sampler = qmc.Sobol(d=len(mu), scramble=False)\n",
    "        elif low_discrepancy == \"halton\":\n",
    "            sampler = qmc.Halton(d=len(mu), scramble=False)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported low discrepancy method. Choose 'sobol' or 'halton'.\")\n",
    "\n",
    "        # Generate low-discrepancy samples in [0,1] and map to standard normal\n",
    "        samples = sampler.random(num_mc_samples)\n",
    "        \n",
    "        # Avoid values at exactly 0 or 1 to prevent `nan` in inverse CDF transformation\n",
    "        epsilon = 1e-10\n",
    "        samples = samples * (1 - 2 * epsilon) + epsilon\n",
    "\n",
    "        # Transform [0,1] samples to standard normal using inverse CDF\n",
    "        standard_normal_samples = torch.tensor(samples, dtype=torch.float64)\n",
    "        standard_normal_samples = torch.erfinv(2 * standard_normal_samples - 1) * np.sqrt(2)\n",
    "\n",
    "    elif method == \"RQMC\":\n",
    "        # Randomized Quasi-Monte Carlo (with scrambling)\n",
    "        if low_discrepancy == \"sobol\":\n",
    "            sampler = qmc.Sobol(d=len(mu), scramble=True)\n",
    "        elif low_discrepancy == \"halton\":\n",
    "            sampler = qmc.Halton(d=len(mu), scramble=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported low discrepancy method. Choose 'sobol' or 'halton'.\")\n",
    "\n",
    "        # Generate scrambled low-discrepancy samples in [0,1] and map to standard normal\n",
    "        samples = sampler.random(num_mc_samples)\n",
    "        \n",
    "        # Avoid values at exactly 0 or 1 to prevent `nan` in inverse CDF transformation\n",
    "        epsilon = 1e-10\n",
    "        samples = samples * (1 - 2 * epsilon) + epsilon\n",
    "\n",
    "        # Transform [0,1] samples to standard normal using inverse CDF\n",
    "        standard_normal_samples = torch.tensor(samples, dtype=torch.float64)\n",
    "        standard_normal_samples = torch.erfinv(2 * standard_normal_samples - 1) * np.sqrt(2)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose 'MC', 'QMC', or 'RQMC'.\")\n",
    "\n",
    "    # Cholesky decomposition for covariance transformation\n",
    "    cholesky_factor = torch.tensor(np.linalg.cholesky(Sigma * Delta_t), dtype=torch.float64)\n",
    "\n",
    "    # Apply transformation to obtain log-normal samples\n",
    "    log_Rt_samples = adjusted_mu[:, None] + cholesky_factor @ standard_normal_samples.T\n",
    "    log_Rt_samples = log_Rt_samples.T\n",
    "\n",
    "    # Transform samples to R_t\n",
    "    Rt = torch.exp(log_Rt_samples)\n",
    "\n",
    "    # Monte Carlo integration approximation for E[R_t]\n",
    "    mc_integral_Rt = torch.mean(Rt, axis=0)\n",
    "\n",
    "    return mc_integral_Rt\n",
    "\n",
    "# Example usage:\n",
    "mu = np.array([0.06, 0.06])\n",
    "Sigma = np.array([[0.04, 0.0], [0.0, 0.04]])\n",
    "Delta_t = 1.0\n",
    "num_mc_samples = 5000\n",
    "\n",
    "# Run Randomized Quasi Monte Carlo (Sobol)\n",
    "result_rqmc = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"RQMC\", low_discrepancy=\"sobol\")\n",
    "print(\"Randomized Quasi Monte Carlo (Sobol) integral over R_t samples:\", result_rqmc.numpy())\n",
    "\n",
    "# Run standard Monte Carlo\n",
    "result_mc = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"MC\")\n",
    "print(\"Monte Carlo integral over R_t samples:\", result_mc.numpy())\n",
    "\n",
    "# Run Quasi Monte Carlo with Halton\n",
    "result_qmc_halton = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"QMC\", low_discrepancy=\"halton\")\n",
    "print(\"Quasi Monte Carlo (Halton) integral over R_t samples:\", result_qmc_halton.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Quasi Monte Carlo integral over R_t samples: [1.0619 1.0619]\n",
      "Monte Carlo integral over R_t samples: [1.065  1.0585]\n",
      "Quasi Monte Carlo (Sobol) integral over R_t samples: [nan nan]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"MC\", low_discrepancy=\"sobol\"):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo, Quasi Monte Carlo, or Randomized Quasi Monte Carlo integration\n",
    "    for multivariate normal distributions.\n",
    "\n",
    "    Parameters:\n",
    "        mu (np.array): Mean vector for the normal distribution.\n",
    "        Sigma (np.array): Covariance matrix.\n",
    "        Delta_t (float): Time step.\n",
    "        num_mc_samples (int): Number of Monte Carlo samples.\n",
    "        method (str): Sampling method - \"MC\" for Monte Carlo, \"QMC\" for Quasi-Monte Carlo, \"RQMC\" for Randomized QMC.\n",
    "        low_discrepancy (str): Low discrepancy sequence method for QMC - only \"sobol\" is supported.\n",
    "\n",
    "    Returns:\n",
    "        mc_integral_Rt (torch.Tensor): Monte Carlo integral approximation for E[R_t].\n",
    "    \"\"\"\n",
    "    # Adjusted mean according to Cai, Judd, Xu (2013)\n",
    "    adjusted_mu = torch.tensor(mu * Delta_t - 0.5 * np.diag(Sigma) * Delta_t, dtype=torch.float64)\n",
    "\n",
    "    # Sampling\n",
    "    if method == \"MC\":\n",
    "        # Standard Monte Carlo sampling\n",
    "        standard_normal_samples = torch.randn((num_mc_samples, len(mu)))\n",
    "    elif method in [\"QMC\", \"RQMC\"]:\n",
    "        if low_discrepancy != \"sobol\":\n",
    "            raise ValueError(\"Only 'sobol' is supported for low discrepancy sampling.\")\n",
    "\n",
    "        # Sobol sequence sampling with optional scrambling\n",
    "        sobol_engine = torch.quasirandom.SobolEngine(dimension=len(mu), scramble=(method == \"RQMC\"))\n",
    "        samples = sobol_engine.draw(num_mc_samples)\n",
    "        \n",
    "        # Avoid values at exactly 0 or 1 to prevent `nan` in inverse CDF transformation\n",
    "        epsilon = 1e-10\n",
    "        samples = torch.clamp(samples, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Transform [0,1] samples to standard normal using inverse CDF\n",
    "        standard_normal_samples = torch.erfinv(2 * samples - 1) * np.sqrt(2)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose 'MC', 'QMC', or 'RQMC'.\")\n",
    "\n",
    "    # Cholesky decomposition for covariance transformation\n",
    "    cholesky_factor = torch.tensor(np.linalg.cholesky(Sigma * Delta_t), dtype=torch.float32)\n",
    "\n",
    "    # Apply transformation to obtain log-normal samples\n",
    "    log_Rt_samples = adjusted_mu[:, None] + cholesky_factor @ standard_normal_samples.T\n",
    "    log_Rt_samples = log_Rt_samples.T\n",
    "\n",
    "    # Transform samples to R_t\n",
    "    Rt = torch.exp(log_Rt_samples)\n",
    "\n",
    "    # Monte Carlo integration approximation for E[R_t]\n",
    "    mc_integral_Rt = torch.mean(Rt, axis=0)\n",
    "\n",
    "    return mc_integral_Rt\n",
    "\n",
    "# Example usage:\n",
    "mu = np.array([0.06, 0.06])\n",
    "Sigma = np.array([[0.04, 0.0], [0.0, 0.04]])\n",
    "Delta_t = 1.0\n",
    "num_mc_samples = 5000\n",
    "\n",
    "# Run Randomized Quasi Monte Carlo\n",
    "result_rqmc = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"RQMC\")\n",
    "print(\"Randomized Quasi Monte Carlo integral over R_t samples:\", result_rqmc.numpy())\n",
    "\n",
    "# Run standard Monte Carlo\n",
    "result_mc = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"MC\")\n",
    "print(\"Monte Carlo integral over R_t samples:\", result_mc.numpy())\n",
    "\n",
    "# Run Quasi Monte Carlo with Sobol\n",
    "result_qmc_sobol = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"QMC\", low_discrepancy=\"sobol\")\n",
    "print(\"Quasi Monte Carlo (Sobol) integral over R_t samples:\", result_qmc_sobol.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "def plot_ntr_at_time(NTR_history, t):\n",
    "    hull = NTR_history[t]\n",
    "    \n",
    "    if hull is not None:\n",
    "        vertices = hull.points  # Vertices are stored in the 'points' attribute of ConvexHull\n",
    "        D = vertices.shape[1]  # Dimension of the state space\n",
    "        plt.figure(figsize=(4,3),dpi=200)\n",
    "\n",
    "        if D == 2:\n",
    "            # 2D plot\n",
    "            plt.fill(vertices[hull.vertices, 0], vertices[hull.vertices, 1], color = colors[1], alpha=0.2,label='NTR')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            plt.scatter(merton_p[0], merton_p[1],label='Merton Point')\n",
    "            plt.legend()\n",
    "            plt.xlabel('State dimension 1')\n",
    "            plt.ylabel('State dimension 2')\n",
    "            x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "            y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "            plt.xlim(x_min - 0.1, x_max + 0.1)\n",
    "            plt.ylim(y_min - 0.1, y_max + 0.1)\n",
    "            plt.grid(alpha=0.5)\n",
    "\n",
    "        elif D == 3:\n",
    "                # 3D plot\n",
    "                ax = plt.axes(projection='3d')\n",
    "                ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], color=colors[1],alpha=0.2,s=10,marker='*')\n",
    "                \n",
    "                # Plot only the convex hull surfaces without edges\n",
    "                faces = hull.simplices\n",
    "                poly3d = [[vertices[face] for face in simplex] for simplex in faces]\n",
    "                ax.add_collection3d(Poly3DCollection(poly3d, facecolors=colors[4], edgecolor='none', alpha=0.2))\n",
    "                \n",
    "                ax.scatter(merton_p[0], merton_p[1], merton_p[2], color=colors[0], s=75, label='Merton Point')\n",
    "                ax.legend()\n",
    "                ax.set_xlabel('State dimension 1')\n",
    "                ax.set_ylabel('State dimension 2')\n",
    "                ax.set_zlabel('State dimension 3')\n",
    "                plt.title(f'NTR at time {t}')\n",
    "                x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "                y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "                z_min, z_max = vertices[:, 2].min(), vertices[:, 2].max()\n",
    "                ax.set_xlim(x_min - 0.05, x_max + 0.05)\n",
    "                ax.set_ylim(y_min - 0.05, y_max + 0.05)\n",
    "                ax.set_zlim(z_min - 0.05, z_max + 0.05)  \n",
    "                ax.view_init(elev=25, azim=50)  # Adjust elev and azim for desired viewing angle\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"Not enough vertices to form an NTR at time {t}\")\n",
    "\n",
    "# Example: Plot NTR at time t=1\n",
    "plot_ntr_at_time(NTR,int(T/Delta_t)-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "def plot_ntr_at_time(NTR_history, t):\n",
    "    hull = NTR_history[t]\n",
    "    \n",
    "    if hull is not None:\n",
    "        vertices = hull.points  # Vertices are stored in the 'points' attribute of ConvexHull\n",
    "        D = vertices.shape[1]  # Dimension of the state space\n",
    "        plt.figure(figsize=(4,3),dpi=200)\n",
    "\n",
    "        if D == 2:\n",
    "            # 2D plot\n",
    "            plt.fill(vertices[hull.vertices, 0], vertices[hull.vertices, 1], color = colors[1], alpha=0.2,label='NTR')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            plt.scatter(merton_p[0], merton_p[1],label='Merton Point')\n",
    "            plt.legend()\n",
    "            plt.xlabel('State dimension 1')\n",
    "            plt.ylabel('State dimension 2')\n",
    "            x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "            y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "            plt.xlim(x_min - 0.1, x_max + 0.1)\n",
    "            plt.ylim(y_min - 0.1, y_max + 0.1)\n",
    "            plt.grid(alpha=0.5)\n",
    "        elif D == 3:\n",
    "            # 3D plot\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], color='red')\n",
    "            ax.add_collection3d(Poly3DCollection(vertices[hull.simplices], facecolors='lightgray', edgecolors='k', alpha=0.4))\n",
    "            ax.scatter(merton_p[0], merton_p[1], merton_p[2], color='blue', s=100, label='Merton Point')\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('State dimension 1')\n",
    "            ax.set_ylabel('State dimension 2')\n",
    "            ax.set_zlabel('State dimension 3')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "            y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "            z_min, z_max = vertices[:, 2].min(), vertices[:, 2].max()\n",
    "            ax.set_xlim(x_min - 0.05, x_max + 0.05)\n",
    "            ax.set_ylim(y_min - 0.1, y_max + 0.1)\n",
    "            ax.set_zlim(z_min - 0.1, z_max + 0.1)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"Not enough vertices to form an NTR at time {t}\")\n",
    "\n",
    "# Example: Plot NTR at time t=1\n",
    "# plot_ntr_at_time(NTR,int(T/Delta_t)-2)\n",
    "def plot_ntr_at_time_select_dims(NTR_history, t, dims=(0, 1)):\n",
    "    hull = NTR_history[t]\n",
    "    \n",
    "    if hull is not None:\n",
    "        vertices = hull.points  # Vertices are stored in the 'points' attribute of ConvexHull\n",
    "        D = vertices.shape[1]  # Dimension of the state space\n",
    "        plt.figure(figsize=(4,3),dpi=200)\n",
    "\n",
    "        if D == 2:\n",
    "            # 2D plot\n",
    "            plt.fill(vertices[hull.vertices, 0], vertices[hull.vertices, 1], color = colors[4], alpha=0.2,label='NTR')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            plt.scatter(merton_p[0], merton_p[1],label='Merton Point')\n",
    "            plt.legend()\n",
    "            plt.xlabel('State dimension 1')\n",
    "            plt.ylabel('State dimension 2')\n",
    "            x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "            y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "            plt.xlim(x_min - 0.1, x_max + 0.1)\n",
    "            plt.ylim(y_min - 0.1, y_max + 0.1)\n",
    "            plt.grid(alpha=0.5)\n",
    "        elif D >= 3:\n",
    "            # Select dimensions to plot\n",
    "            vertices_2d = vertices[:, dims]\n",
    "            hull_2d = ConvexHull(vertices_2d)\n",
    "            plt.fill(vertices_2d[hull_2d.vertices, 0], vertices_2d[hull_2d.vertices, 1], color = colors[4], alpha=0.2,label='NTR')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            plt.scatter(merton_p[dims[0]], merton_p[dims[1]],label='Merton Point')\n",
    "            plt.legend()\n",
    "            plt.xlabel(f'State dimension {dims[0]}')\n",
    "            plt.ylabel(f'State dimension {dims[1]}')\n",
    "            x_min, x_max = vertices_2d[:, 0].min(), vertices_2d[:, 0].max()\n",
    "            y_min, y_max = vertices_2d[:, 1].min(), vertices_2d[:, 1].max()\n",
    "            plt.xlim(x_min - 0.1, x_max + 0.1)\n",
    "            plt.ylim(y_min - 0.1, y_max + 0.1)\n",
    "            plt.grid(alpha=0.5)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"Not enough vertices to form an NTR at time {t}\")\n",
    "\n",
    "# Example: Plot NTR at time t=1, selecting dimensions 0 and 2\n",
    "plot_ntr_at_time_select_dims(NTR, int(T/Delta_t)-5, dims=(0, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Peytz2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
