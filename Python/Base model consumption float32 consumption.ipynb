{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "import multiprocessing\n",
    "\n",
    "# Numeric computation\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.linalg import cholesky  # For linear algebra (e.g., Cholesky decomposition)\n",
    "from scipy.spatial import ConvexHull, Delaunay # For sampling and NTR\n",
    "from scipy.optimize import minimize #For projection to the NTR\n",
    "from scipy.spatial.distance import pdist, squareform #For projection to the NTR\n",
    "# from scipy.special import roots_hermite # Polynomials of the form e^(-x^2)\n",
    "# from scipy.special import roots_hermitenorm # Polynomials of the form e^(-x^(2)/2)\n",
    "\n",
    "# Gaussian Process Regression (GPR)\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import (Kernel, ScaleKernel, MaternKernel, \n",
    "                              GridInterpolationKernel, ProductKernel)\n",
    "# from gpytorch.utils.grid import choose_grid_size\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from torch.nn import ModuleList  # Correct import for ModuleList (For SKIP)\n",
    "# from gpytorch.variational import (CholeskyVariationalDistribution, \n",
    "#                                   VariationalStrategy)  # For SVGP\n",
    "# from gpytorch.lazy import MatmulLazyTensor, InterpolatedLazyTensor\n",
    "\n",
    "from gpytorch.settings import fast_computations, lazily_evaluate_kernels, detach_test_caches, skip_posterior_variances\n",
    "# from gpytorch.settings import fast_pred_var, fast_pred_samples\n",
    "\n",
    "# Optimization\n",
    "import cyipopt\n",
    "from cyipopt import Problem\n",
    "\n",
    "# Quasi-Monte Carlo (QMC) and sparse grids\n",
    "# import Tasmanian  # Tasmanian Sparse Grid library\n",
    "from Tasmanian import makeGlobalGrid\n",
    "from torch.quasirandom import SobolEngine\n",
    "import chaospy as cp\n",
    "\n",
    "# We can save our No-trade-regions (Convex hulls) as .pkl files\n",
    "import pickle\n",
    "    #Save\n",
    "    # with open(\"convex_hulls_array.pkl\", \"wb\") as file:\n",
    "    #     pickle.dump(convex_hulls, file)\n",
    "    #Open\n",
    "    # with open(\"convex_hulls_array.pkl\", \"rb\") as file:\n",
    "    #     loaded_hulls = pickle.load(file)\n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from cycler import cycler\n",
    "import scienceplots  # For custom style based on science plots\n",
    "\n",
    "# Parallel processing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Logging configuration\n",
    "import logging\n",
    "logging.basicConfig(filename='optimization_log.txt', \n",
    "                    filemode='w',\n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Random seed setup\n",
    "random_seed = 12012001\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "multiprocessing.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a custom plotting style and updating scienceplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('science')\n",
    "\n",
    "custom = True\n",
    "if custom:\n",
    "\n",
    "    colors = ['#094a84','#cc2300', \n",
    "                '#009437', '#cc7700',\n",
    "                '#694878', '#383838',\n",
    "                '#7e7e7e']\n",
    "    mpl.rcParams['axes.prop_cycle'] = cycler('color', \n",
    "                                            ['#094a84','#cc2300', \n",
    "                                            '#009437', '#cc7700',\n",
    "                                            '#694878', '#383838',\n",
    "                                            '#7e7e7e'])\n",
    "\n",
    "    mpl.rcParams['figure.facecolor'] = '#ffffff'  # Lightest Snow Storm background\n",
    "    mpl.rcParams['axes.facecolor'] = '#FCFDFE'    # Same light background inside plots\n",
    "    mpl.rcParams['axes.facecolor'] = '#ffffff'    # Same light background inside plots\n",
    "    # mpl.rcParams['axes.facecolor'] = '#3B4252'    # Same light background inside plots\n",
    "    # # mpl.rcParams['axes.facecolor'] = '#ffffff'    # Same light background inside plots\n",
    "    # mpl.rcParams['axes.edgecolor'] = '#3B4252'    # Dark Slate from Polar Night for edges\n",
    "    # mpl.rcParams['axes.labelcolor'] = '#3B4252'   # Text color for labels using Dark Slate\n",
    "    # mpl.rcParams['xtick.color'] = '#3B4252'       # Tick color from Polar Night palette\n",
    "    # mpl.rcParams['ytick.color'] = '#3B4252'\n",
    "\n",
    "    mpl.rcParams['font.size'] = 11\n",
    "    mpl.rcParams['axes.titlesize'] = 11\n",
    "    mpl.rcParams['axes.labelsize'] = 11\n",
    "    mpl.rcParams['legend.fontsize'] = 11\n",
    "\n",
    "    # Remove spines\n",
    "    # mpl.rcParams['axes.spines.top'] = False\n",
    "    # mpl.rcParams['axes.spines.right'] = False\n",
    "    # mpl.rcParams['axes.spines.bottom'] = False\n",
    "    # mpl.rcParams['axes.spines.left'] = False\n",
    "\n",
    "    # Grid settings\n",
    "    mpl.rcParams['axes.grid'] = True\n",
    "    mpl.rcParams['grid.color'] = '#e2e3e4'        # Subtle grid lines using light Snow Storm color\n",
    "    mpl.rcParams['grid.linestyle'] = '--'\n",
    "    mpl.rcParams['grid.linewidth'] = 0.8\n",
    "    mpl.rcParams['axes.titlecolor'] = 'black'\n",
    "    # Ticks\n",
    "    mpl.rcParams['xtick.major.size'] = 5\n",
    "    mpl.rcParams['ytick.major.size'] = 5\n",
    "    mpl.rcParams['xtick.minor.size'] = 3\n",
    "    mpl.rcParams['ytick.minor.size'] = 3\n",
    "    mpl.rcParams['xtick.direction'] = 'in'\n",
    "    mpl.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # Lines and markers\n",
    "    mpl.rcParams['lines.linewidth'] = 3\n",
    "    mpl.rcParams['lines.markersize'] = 6\n",
    "    mpl.rcParams['lines.markeredgewidth'] = 1.5\n",
    "\n",
    "    # Legends\n",
    "    mpl.rcParams['legend.frameon'] = True\n",
    "    mpl.rcParams['legend.loc'] = 'best'\n",
    "\n",
    "    # Subplots and layout\n",
    "    mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "    mpl.rcParams['figure.dpi'] = 600\n",
    "    mpl.rcParams['figure.autolayout'] = True\n",
    "\n",
    "    # Always save as 'tight'\n",
    "    mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "    mpl.rcParams['savefig.pad_inches'] = 0.02\n",
    "\n",
    "    # Save figures to the folder Figures\n",
    "    output_folder = '../Speciale dokumentet/Figures'\n",
    "    os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ISNAN warning probably stems from my bellman (pi_t1 or xt1).\n",
    "Need to ensure these are tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** : Code takes longer for bigger tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dynamic Portfolio Optimization Parameters =====\n",
      "Number of Assets (D): 2\n",
      "Total Years (T): 6\n",
      "Time Step Size (Delta_t): 1.0\n",
      "Number of Time Steps (step size * T): 6\n",
      "Discount Factor (beta): 0.97\n",
      "Relative Risk Aversion (gamma): 3.0\n",
      "Transaction Cost Rate (tau): 0.005\n",
      "Yearly Net Risk-Free Rate (r): 0.030044121348376644\n",
      "Expected Yearly Net Returns (mu): [0.07 0.07]\n",
      "Covariance Matrix (Sigma):\n",
      "[[0.04 0.  ]\n",
      " [0.   0.04]]\n",
      "Include Consumption: True\n",
      "Minimum Consumption (c_min): 0.05\n",
      "Number of State Points (N): 100\n",
      "merton_p: [0.333 0.333]\n",
      "Integration Method: quadrature\n",
      "==============================================\n",
      "\n",
      "Time step 5\n",
      "include consumption: True\n",
      "Step 2a: Approximate NTR\n",
      "[[0.0977 0.0977]\n",
      " [0.1313 0.097 ]\n",
      " [0.097  0.1313]\n",
      " [0.1309 0.1309]]\n",
      "len tilde_omega_t: 4\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point: tensor([0.1115, 0.1181], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1115 0.1181]], bt: 0.1672, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1177, 0.1105], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1177 0.1105]], bt: 0.1687, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1171, 0.1102], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1171 0.1102]], bt: 0.1696, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1063, 0.1074], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1063 0.1074]], bt: 0.1831, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.1047, 0.1147], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1047 0.1147]], bt: 0.1774, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.1297, 0.1144], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1297 0.1144]], bt: 0.1529, Consumption: 0.603\n",
      "Best solution found. Point: tensor([0.1130, 0.1129], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.113  0.1129]], bt: 0.1709, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1080, 0.1100], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.108 0.11 ]], bt: 0.1788, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.1128, 0.1182], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1128 0.1182]], bt: 0.166, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1120, 0.1247], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.112  0.1247]], bt: 0.1603, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1250, 0.0999], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.125  0.0999]], bt: 0.1721, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1235, 0.1044], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1235 0.1044]], bt: 0.169, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1135, 0.1252], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1135 0.1252]], bt: 0.1582, Consumption: 0.603\n",
      "Best solution found. Point: tensor([0.1076, 0.1157], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1076 0.1157]], bt: 0.1736, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.1185, 0.1202], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1185 0.1202]], bt: 0.1582, Consumption: 0.603\n",
      "Best solution found. Point: tensor([0.1081, 0.1248], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1081 0.1248]], bt: 0.164, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1111, 0.1218], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1111 0.1218]], bt: 0.164, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1205, 0.1184], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1205 0.1184]], bt: 0.1581, Consumption: 0.603\n",
      "Best solution found. Point: tensor([0.1201, 0.1009], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1201 0.1009]], bt: 0.1759, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1125, 0.1181], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1125 0.1181]], bt: 0.1663, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1034, 0.1229], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1034 0.1229]], bt: 0.1706, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1047, 0.1121], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1047 0.1121]], bt: 0.1801, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.1113, 0.1111], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1113 0.1111]], bt: 0.1744, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.0994, 0.1108], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.0994 0.1108]], bt: 0.1866, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.1229, 0.1086], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1229 0.1086]], bt: 0.1653, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.0844, 0.0838], dtype=torch.float64), Delta+: [0.0135 0.014 ], Delta-: [0. 0.], Delta: [0.0135 0.014 ], Omega: [[0.0978 0.0978]], bt: 0.201, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.0777, 0.1099], dtype=torch.float64), Delta+: [ 0.02 -0.  ], Delta-: [0. 0.], Delta: [ 0.02 -0.  ], Omega: [[0.0977 0.1099]], bt: 0.1891, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.1326, 0.1348], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0012 0.0034], Delta: [-0.0012 -0.0034], Omega: [[0.1314 0.1314]], bt: 0.1344, Consumption: 0.6028\n",
      "Best solution found. Point: tensor([0.1725, 0.1171], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0409 -0.    ], Delta: [-0.0409  0.    ], Omega: [[0.1316 0.1171]], bt: 0.1483, Consumption: 0.6028\n",
      "Best solution found. Point: tensor([0.0780, 0.1365], dtype=torch.float64), Delta+: [0.0194 0.    ], Delta-: [0.     0.0046], Delta: [ 0.0194 -0.0046], Omega: [[0.0974 0.1319]], bt: 0.1676, Consumption: 0.603\n",
      "Best solution found. Point: tensor([0.0691, 0.0739], dtype=torch.float64), Delta+: [0.0288 0.0239], Delta-: [0. 0.], Delta: [0.0288 0.0239], Omega: [[0.0978 0.0978]], bt: 0.201, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.0775, 0.1178], dtype=torch.float64), Delta+: [ 0.0201 -0.    ], Delta-: [0. 0.], Delta: [ 0.0201 -0.    ], Omega: [[0.0976 0.1178]], bt: 0.1813, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1220, 0.0831], dtype=torch.float64), Delta+: [-0.      0.0145], Delta-: [0. 0.], Delta: [-0.      0.0145], Omega: [[0.122  0.0976]], bt: 0.1773, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.1384, 0.1294], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.007 0.   ], Delta: [-0.007 -0.   ], Omega: [[0.1314 0.1294]], bt: 0.1363, Consumption: 0.6028\n",
      "Best solution found. Point: tensor([0.1615, 0.1040], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0297 -0.    ], Delta: [-0.0297  0.    ], Omega: [[0.1318 0.104 ]], bt: 0.1611, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.1728, 0.0696], dtype=torch.float64), Delta+: [0.     0.0278], Delta-: [0.0409 0.    ], Delta: [-0.0409  0.0278], Omega: [[0.1319 0.0974]], bt: 0.1676, Consumption: 0.6028\n",
      "Best solution found. Point: tensor([0.0923, 0.1096], dtype=torch.float64), Delta+: [ 0.0054 -0.    ], Delta-: [0. 0.], Delta: [ 0.0054 -0.    ], Omega: [[0.0977 0.1096]], bt: 0.1895, Consumption: 0.6032\n",
      "Best solution found. Point: tensor([0.1324, 0.1145], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0008 -0.    ], Delta: [-0.0008  0.    ], Omega: [[0.1317 0.1145]], bt: 0.1509, Consumption: 0.603\n",
      "Best solution found. Point: tensor([0.1247, 0.1390], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0075], Delta: [-0.     -0.0075], Omega: [[0.1247 0.1315]], bt: 0.1409, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.1070, 0.1633], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0315], Delta: [ 0.     -0.0315], Omega: [[0.107  0.1318]], bt: 0.1582, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.1213, 0.1565], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.     0.025], Delta: [ 0.    -0.025], Omega: [[0.1213 0.1315]], bt: 0.1442, Consumption: 0.6028\n",
      "Best solution found. Point: tensor([0.1225, 0.1388], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0073], Delta: [ 0.     -0.0073], Omega: [[0.1225 0.1315]], bt: 0.1431, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.1626, 0.0939], dtype=torch.float64), Delta+: [0.     0.0036], Delta-: [0.0307 0.    ], Delta: [-0.0307  0.0036], Omega: [[0.1319 0.0974]], bt: 0.1676, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.1166, 0.1350], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0034], Delta: [ 0.     -0.0034], Omega: [[0.1166 0.1316]], bt: 0.1488, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.1648, 0.1394], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0334 0.008 ], Delta: [-0.0334 -0.008 ], Omega: [[0.1313 0.1313]], bt: 0.1344, Consumption: 0.6027\n",
      "Best solution found. Point: tensor([0.1387, 0.1184], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0071 -0.    ], Delta: [-0.0071  0.    ], Omega: [[0.1316 0.1184]], bt: 0.1471, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.1553, 0.1210], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0238 -0.    ], Delta: [-0.0238  0.    ], Omega: [[0.1315 0.121 ]], bt: 0.1445, Consumption: 0.6028\n",
      "Best solution found. Point: tensor([0.7083, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5772 0.    ], Delta: [-0.5772 -0.    ], Omega: [[0.1311 0.125 ]], bt: 0.1399, Consumption: 0.6011\n",
      "Best solution found. Point: tensor([0.3333, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2023 0.2856], Delta: [-0.2023 -0.2856], Omega: [[0.131 0.131]], bt: 0.1341, Consumption: 0.6013\n",
      "Best solution found. Point: tensor([0.6667, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5358 0.2025], Delta: [-0.5358 -0.2025], Omega: [[0.1309 0.1309]], bt: 0.134, Consumption: 0.6006\n",
      "Best solution found. Point: tensor([0.1491, 0.1634], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0178 0.0321], Delta: [-0.0178 -0.0321], Omega: [[0.1313 0.1313]], bt: 0.1344, Consumption: 0.6027\n",
      "Best solution found. Point: tensor([0.2500, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.119  0.4106], Delta: [-0.119  -0.4106], Omega: [[0.131 0.131]], bt: 0.1341, Consumption: 0.6012\n",
      "Best solution found. Point: tensor([0.1312, 0.1110], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0. -0.], Delta: [-0.  0.], Omega: [[0.1312 0.111 ]], bt: 0.1548, Consumption: 0.603\n",
      "Best solution found. Point: tensor([0.2917, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1608 0.5358], Delta: [-0.1608 -0.5358], Omega: [[0.1309 0.1309]], bt: 0.134, Consumption: 0.6007\n",
      "Best solution found. Point: tensor([0.5000, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3691 0.3274], Delta: [-0.3691 -0.3274], Omega: [[0.1309 0.1309]], bt: 0.134, Consumption: 0.6007\n",
      "Best solution found. Point: tensor([0.0000, 0.7917], dtype=torch.float64), Delta+: [0.0971 0.    ], Delta-: [0.     0.6603], Delta: [ 0.0971 -0.6603], Omega: [[0.0971 0.1314]], bt: 0.167, Consumption: 0.6008\n",
      "Best solution found. Point: tensor([0.5833, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4522 0.    ], Delta: [-0.4522 -0.    ], Omega: [[0.1312 0.125 ]], bt: 0.14, Consumption: 0.6015\n",
      "Best solution found. Point: tensor([0.0417, 0.9167], dtype=torch.float64), Delta+: [0.0554 0.    ], Delta-: [0.     0.7853], Delta: [ 0.0554 -0.7853], Omega: [[0.097  0.1313]], bt: 0.1669, Consumption: 0.6005\n",
      "Best solution found. Point: tensor([0.0833, 0.7500], dtype=torch.float64), Delta+: [0.0138 0.    ], Delta-: [0.     0.6185], Delta: [ 0.0138 -0.6185], Omega: [[0.0971 0.1315]], bt: 0.1671, Consumption: 0.6011\n",
      "Best solution found. Point: tensor([0.1250, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4522], Delta: [-0.     -0.4522], Omega: [[0.125  0.1312]], bt: 0.14, Consumption: 0.6015\n",
      "Best solution found. Point: tensor([0.4167, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2854 0.    ], Delta: [-0.2854 -0.    ], Omega: [[0.1313 0.125 ]], bt: 0.1403, Consumption: 0.602\n",
      "Best solution found. Point: tensor([0.5417, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4105 0.    ], Delta: [-0.4105 -0.    ], Omega: [[0.1312 0.125 ]], bt: 0.1401, Consumption: 0.6016\n",
      "Best solution found. Point: tensor([0.3750, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2439 0.1189], Delta: [-0.2439 -0.1189], Omega: [[0.1311 0.1311]], bt: 0.1342, Consumption: 0.6017\n",
      "Best solution found. Point: tensor([0.2917, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1605 0.1188], Delta: [-0.1605 -0.1188], Omega: [[0.1312 0.1312]], bt: 0.1343, Consumption: 0.602\n",
      "Best solution found. Point: tensor([0.0000, 0.2083], dtype=torch.float64), Delta+: [0.0974 0.    ], Delta-: [0.     0.0765], Delta: [ 0.0974 -0.0765], Omega: [[0.0974 0.1318]], bt: 0.1675, Consumption: 0.6025\n",
      "Best solution found. Point: tensor([0.0000, 0.0833], dtype=torch.float64), Delta+: [0.0978 0.0144], Delta-: [0. 0.], Delta: [0.0978 0.0144], Omega: [[0.0978 0.0978]], bt: 0.2009, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.6250, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4938 0.    ], Delta: [-0.4938 -0.    ], Omega: [[0.1312 0.125 ]], bt: 0.14, Consumption: 0.6014\n",
      "Best solution found. Point: tensor([0.2500, 0.0000], dtype=torch.float64), Delta+: [0.     0.0973], Delta-: [0.1182 0.    ], Delta: [-0.1182  0.0973], Omega: [[0.1318 0.0973]], bt: 0.1674, Consumption: 0.6024\n",
      "Best solution found. Point: tensor([0.2917, 0.0833], dtype=torch.float64), Delta+: [0.    0.014], Delta-: [0.1599 0.    ], Delta: [-0.1599  0.014 ], Omega: [[0.1318 0.0974]], bt: 0.1675, Consumption: 0.6025\n",
      "Best solution found. Point: tensor([0.2083, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0774 0.6191], Delta: [-0.0774 -0.6191], Omega: [[0.1309 0.1309]], bt: 0.134, Consumption: 0.6007\n",
      "Best solution found. Point: tensor([0.5000, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.369 0.119], Delta: [-0.369 -0.119], Omega: [[0.131 0.131]], bt: 0.1341, Consumption: 0.6013\n",
      "Best solution found. Point: tensor([0.0833, 0.6250], dtype=torch.float64), Delta+: [0.0139 0.    ], Delta-: [0.     0.4934], Delta: [ 0.0139 -0.4934], Omega: [[0.0972 0.1316]], bt: 0.1672, Consumption: 0.6015\n",
      "Best solution found. Point: tensor([0.0833, 0.5417], dtype=torch.float64), Delta+: [0.0139 0.    ], Delta-: [0.   0.41], Delta: [ 0.0139 -0.41  ], Omega: [[0.0972 0.1316]], bt: 0.1673, Consumption: 0.6018\n",
      "Best solution found. Point: tensor([0.6667, 0.0833], dtype=torch.float64), Delta+: [0.     0.0138], Delta-: [0.5351 0.    ], Delta: [-0.5351  0.0138], Omega: [[0.1315 0.0972]], bt: 0.1672, Consumption: 0.6014\n",
      "Best solution found. Point: tensor([0.0833, 0.2083], dtype=torch.float64), Delta+: [0.0141 0.    ], Delta-: [0.     0.0765], Delta: [ 0.0141 -0.0765], Omega: [[0.0974 0.1318]], bt: 0.1675, Consumption: 0.6028\n",
      "Best solution found. Point: tensor([0.2083, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0773 0.3689], Delta: [-0.0773 -0.3689], Omega: [[0.1311 0.1311]], bt: 0.1341, Consumption: 0.6015\n",
      "Best solution found. Point: tensor([0.2917, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1607 0.4941], Delta: [-0.1607 -0.4941], Omega: [[0.1309 0.1309]], bt: 0.134, Consumption: 0.6008\n",
      "Best solution found. Point: tensor([0.0417, 0.8333], dtype=torch.float64), Delta+: [0.0554 0.    ], Delta-: [0.     0.7019], Delta: [ 0.0554 -0.7019], Omega: [[0.0971 0.1314]], bt: 0.167, Consumption: 0.6008\n",
      "Best solution found. Point: tensor([0.0000, 0.6667], dtype=torch.float64), Delta+: [0.0971 0.    ], Delta-: [0.     0.5352], Delta: [ 0.0971 -0.5352], Omega: [[0.0971 0.1315]], bt: 0.1671, Consumption: 0.6011\n",
      "Best solution found. Point: tensor([0.2500, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1189 0.2856], Delta: [-0.1189 -0.2856], Omega: [[0.1311 0.1311]], bt: 0.1342, Consumption: 0.6016\n",
      "Best solution found. Point: tensor([0.0000, 0.9167], dtype=torch.float64), Delta+: [0.097 0.   ], Delta-: [0.     0.7853], Delta: [ 0.097  -0.7853], Omega: [[0.097  0.1313]], bt: 0.1669, Consumption: 0.6004\n",
      "Best solution found. Point: tensor([0.2917, 0.0417], dtype=torch.float64), Delta+: [0.     0.0557], Delta-: [0.1599 0.    ], Delta: [-0.1599  0.0557], Omega: [[0.1318 0.0973]], bt: 0.1674, Consumption: 0.6024\n",
      "Best solution found. Point: tensor([0.0000, 0.1250], dtype=torch.float64), Delta+: [ 0.0975 -0.    ], Delta-: [0. 0.], Delta: [ 0.0975 -0.    ], Omega: [[0.0975 0.125 ]], bt: 0.1742, Consumption: 0.6028\n",
      "Best solution found. Point: tensor([0.0833, 0.3750], dtype=torch.float64), Delta+: [0.014 0.   ], Delta-: [0.     0.2433], Delta: [ 0.014  -0.2433], Omega: [[0.0973 0.1317]], bt: 0.1674, Consumption: 0.6023\n",
      "Best solution found. Point: tensor([0.1667, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0353 0.0353], Delta: [-0.0353 -0.0353], Omega: [[0.1313 0.1313]], bt: 0.1344, Consumption: 0.6026\n",
      "Best solution found. Point: tensor([0.1667, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0355 0.2021], Delta: [-0.0355 -0.2021], Omega: [[0.1312 0.1312]], bt: 0.1343, Consumption: 0.6021\n",
      "Best solution found. Point: tensor([0.6667, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5355 0.    ], Delta: [-0.5355 -0.    ], Omega: [[0.1311 0.125 ]], bt: 0.1399, Consumption: 0.6013\n",
      "Best solution found. Point: tensor([0.2500, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1188 0.1605], Delta: [-0.1188 -0.1605], Omega: [[0.1312 0.1312]], bt: 0.1343, Consumption: 0.602\n",
      "Best solution found. Point: tensor([0.6667, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5358 0.1608], Delta: [-0.5358 -0.1608], Omega: [[0.1309 0.1309]], bt: 0.134, Consumption: 0.6007\n",
      "Best solution found. Point: tensor([0.3750, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2437 0.    ], Delta: [-0.2437 -0.    ], Omega: [[0.1313 0.125 ]], bt: 0.1403, Consumption: 0.6021\n",
      "Best solution found. Point: tensor([0.5417, 0.0417], dtype=torch.float64), Delta+: [0.     0.0555], Delta-: [0.4101 0.    ], Delta: [-0.4101  0.0555], Omega: [[0.1316 0.0972]], bt: 0.1672, Consumption: 0.6016\n",
      "Best solution found. Point: tensor([0.6250, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4941 0.2441], Delta: [-0.4941 -0.2441], Omega: [[0.1309 0.1309]], bt: 0.134, Consumption: 0.6006\n",
      "Best solution found. Point: tensor([0.0833, 0.0417], dtype=torch.float64), Delta+: [0.0145 0.0561], Delta-: [0. 0.], Delta: [0.0145 0.0561], Omega: [[0.0978 0.0978]], bt: 0.201, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.2083, 0.0000], dtype=torch.float64), Delta+: [0.     0.0974], Delta-: [0.0765 0.    ], Delta: [-0.0765  0.0974], Omega: [[0.1318 0.0974]], bt: 0.1675, Consumption: 0.6025\n",
      "Best solution found. Point: tensor([0.1250, 0.0417], dtype=torch.float64), Delta+: [-0.      0.0558], Delta-: [0. 0.], Delta: [-0.      0.0558], Omega: [[0.125  0.0975]], bt: 0.1743, Consumption: 0.6029\n",
      "Best solution found. Point: tensor([0.1667, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0356 0.4523], Delta: [-0.0356 -0.4523], Omega: [[0.131 0.131]], bt: 0.1341, Consumption: 0.6013\n",
      "Best solution found. Point: tensor([0.3333, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2022 0.2022], Delta: [-0.2022 -0.2022], Omega: [[0.1311 0.1311]], bt: 0.1342, Consumption: 0.6016\n",
      "Best solution found. Point: tensor([0.0833, 0.1250], dtype=torch.float64), Delta+: [ 0.0142 -0.    ], Delta-: [0. 0.], Delta: [ 0.0142 -0.    ], Omega: [[0.0975 0.125 ]], bt: 0.1743, Consumption: 0.6031\n",
      "Best solution found. Point: tensor([0.2917, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1606 0.369 ], Delta: [-0.1606 -0.369 ], Omega: [[0.131 0.131]], bt: 0.1341, Consumption: 0.6012\n",
      "Best solution found. Point: tensor([0.2500, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.119 0.494], Delta: [-0.119 -0.494], Omega: [[0.131 0.131]], bt: 0.134, Consumption: 0.601\n",
      "Failure Rate: 0.00%\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "Early stopping at iteration 781\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 4\n",
      "include consumption: True\n",
      "Step 2a: Approximate NTR\n",
      "[[0.1288 0.1273]\n",
      " [0.1727 0.1248]\n",
      " [0.1269 0.1725]\n",
      " [0.1714 0.1718]]\n",
      "len tilde_omega_t: 4\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point: tensor([0.1500, 0.1439], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.15   0.1439]], bt: 0.2274, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1397, 0.1385], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1397 0.1385]], bt: 0.243, Consumption: 0.4788\n",
      "Best solution found. Point: tensor([0.1471, 0.1446], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1471 0.1446]], bt: 0.2295, Consumption: 0.4788\n",
      "Best solution found. Point: tensor([0.1484, 0.1417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1484 0.1417]], bt: 0.2311, Consumption: 0.4788\n",
      "Best solution found. Point: tensor([0.1375, 0.1382], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1375 0.1382]], bt: 0.2456, Consumption: 0.4788\n",
      "Best solution found. Point: tensor([0.1599, 0.1595], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1599 0.1595]], bt: 0.202, Consumption: 0.4786\n",
      "Best solution found. Point: tensor([0.1660, 0.1321], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.166  0.1321]], bt: 0.2233, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1438, 0.1633], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1438 0.1633]], bt: 0.2142, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1338, 0.1641], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1338 0.1641]], bt: 0.2234, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1573, 0.1468], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1573 0.1468]], bt: 0.2172, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1541, 0.1407], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1541 0.1407]], bt: 0.2264, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1637, 0.1602], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1637 0.1602]], bt: 0.1975, Consumption: 0.4786\n",
      "Best solution found. Point: tensor([0.1545, 0.1355], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1545 0.1355]], bt: 0.2313, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1332, 0.1533], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1332 0.1533]], bt: 0.2348, Consumption: 0.4788\n",
      "Best solution found. Point: tensor([0.1502, 0.1616], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1502 0.1616]], bt: 0.2095, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1339, 0.1647], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1339 0.1647]], bt: 0.2227, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1576, 0.1365], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1576 0.1365]], bt: 0.2272, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1368, 0.1440], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1368 0.144 ]], bt: 0.2404, Consumption: 0.4788\n",
      "Best solution found. Point: tensor([0.1551, 0.1581], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1551 0.1581]], bt: 0.2082, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1524, 0.1322], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1524 0.1322]], bt: 0.2367, Consumption: 0.4788\n",
      "Best solution found. Point: tensor([0.1529, 0.1532], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1529 0.1532]], bt: 0.2152, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1369, 0.1598], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1369 0.1598]], bt: 0.2246, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1494, 0.1507], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1494 0.1507]], bt: 0.2212, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1496, 0.1417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1496 0.1417]], bt: 0.23, Consumption: 0.4788\n",
      "Best solution found. Point: tensor([0.1424, 0.1163], dtype=torch.float64), Delta+: [-0.      0.0105], Delta-: [0. 0.], Delta: [-0.      0.0105], Omega: [[0.1424 0.1268]], bt: 0.2522, Consumption: 0.4785\n",
      "Best solution found. Point: tensor([0.1039, 0.1125], dtype=torch.float64), Delta+: [0.0251 0.0149], Delta-: [0. 0.], Delta: [0.0251 0.0149], Omega: [[0.129  0.1274]], bt: 0.2649, Consumption: 0.4785\n",
      "Best solution found. Point: tensor([0.1517, 0.1050], dtype=torch.float64), Delta+: [-0.      0.0211], Delta-: [0. 0.], Delta: [-0.      0.0211], Omega: [[0.1517 0.1261]], bt: 0.2437, Consumption: 0.4785\n",
      "Best solution found. Point: tensor([0.1625, 0.1361], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1625 0.1361]], bt: 0.2227, Consumption: 0.4787\n",
      "Best solution found. Point: tensor([0.1028, 0.1433], dtype=torch.float64), Delta+: [ 0.0256 -0.    ], Delta-: [0. 0.], Delta: [ 0.0256 -0.    ], Omega: [[0.1284 0.1433]], bt: 0.2496, Consumption: 0.4785\n",
      "Best solution found. Point: tensor([0.1465, 0.1204], dtype=torch.float64), Delta+: [-0.      0.0061], Delta-: [0. 0.], Delta: [-0.      0.0061], Omega: [[0.1465 0.1265]], bt: 0.2484, Consumption: 0.4785\n",
      "Best solution found. Point: tensor([0.1796, 0.1064], dtype=torch.float64), Delta+: [0.    0.019], Delta-: [0.0062 0.    ], Delta: [-0.0062  0.019 ], Omega: [[0.1735 0.1253]], bt: 0.2228, Consumption: 0.4783\n",
      "Best solution found. Point: tensor([0.1286, 0.1201], dtype=torch.float64), Delta+: [0.0004 0.0073], Delta-: [0. 0.], Delta: [0.0004 0.0073], Omega: [[0.129  0.1275]], bt: 0.2649, Consumption: 0.4786\n",
      "Best solution found. Point: tensor([0.1935, 0.1044], dtype=torch.float64), Delta+: [0.     0.0209], Delta-: [0.02 0.  ], Delta: [-0.02    0.0209], Omega: [[0.1735 0.1253]], bt: 0.2228, Consumption: 0.4783\n",
      "Best solution found. Point: tensor([0.1545, 0.1234], dtype=torch.float64), Delta+: [-0.      0.0026], Delta-: [0. 0.], Delta: [-0.      0.0026], Omega: [[0.1545 0.1259]], bt: 0.2411, Consumption: 0.4785\n",
      "Best solution found. Point: tensor([0.1820, 0.1248], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0085 -0.    ], Delta: [-0.0085  0.    ], Omega: [[0.1735 0.1248]], bt: 0.2233, Consumption: 0.4783\n",
      "Best solution found. Point: tensor([0.1745, 0.1098], dtype=torch.float64), Delta+: [0.     0.0156], Delta-: [0.001 0.   ], Delta: [-0.001   0.0156], Omega: [[0.1735 0.1253]], bt: 0.2228, Consumption: 0.4783\n",
      "Best solution found. Point: tensor([0.1003, 0.1626], dtype=torch.float64), Delta+: [ 0.0274 -0.    ], Delta-: [0. 0.], Delta: [ 0.0274 -0.    ], Omega: [[0.1276 0.1626]], bt: 0.2313, Consumption: 0.4784\n",
      "Best solution found. Point: tensor([0.2005, 0.1409], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0274 -0.    ], Delta: [-0.0274  0.    ], Omega: [[0.1732 0.1409]], bt: 0.2075, Consumption: 0.4782\n",
      "Best solution found. Point: tensor([0.1185, 0.1859], dtype=torch.float64), Delta+: [0.009 0.   ], Delta-: [0.     0.0127], Delta: [ 0.009  -0.0127], Omega: [[0.1275 0.1733]], bt: 0.2208, Consumption: 0.4783\n",
      "Best solution found. Point: tensor([0.1212, 0.2016], dtype=torch.float64), Delta+: [0.0063 0.    ], Delta-: [0.     0.0283], Delta: [ 0.0063 -0.0283], Omega: [[0.1275 0.1733]], bt: 0.2208, Consumption: 0.4783\n",
      "Best solution found. Point: tensor([0.1259, 0.2114], dtype=torch.float64), Delta+: [0.0017 0.    ], Delta-: [0.     0.0382], Delta: [ 0.0017 -0.0382], Omega: [[0.1275 0.1733]], bt: 0.2208, Consumption: 0.4783\n",
      "Best solution found. Point: tensor([0.0988, 0.1530], dtype=torch.float64), Delta+: [ 0.0291 -0.    ], Delta-: [0. 0.], Delta: [ 0.0291 -0.    ], Omega: [[0.1279 0.153 ]], bt: 0.2405, Consumption: 0.4784\n",
      "Best solution found. Point: tensor([0.1130, 0.2042], dtype=torch.float64), Delta+: [0.0145 0.    ], Delta-: [0.     0.0309], Delta: [ 0.0145 -0.0309], Omega: [[0.1275 0.1733]], bt: 0.2208, Consumption: 0.4782\n",
      "Best solution found. Point: tensor([0.2060, 0.2123], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.034  0.0399], Delta: [-0.034  -0.0399], Omega: [[0.1719 0.1723]], bt: 0.1774, Consumption: 0.4779\n",
      "Best solution found. Point: tensor([0.1552, 0.1940], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0215], Delta: [ 0.     -0.0215], Omega: [[0.1552 0.1725]], bt: 0.1941, Consumption: 0.4782\n",
      "Best solution found. Point: tensor([0.1647, 0.1884], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0161], Delta: [-0.     -0.0161], Omega: [[0.1647 0.1723]], bt: 0.1848, Consumption: 0.4781\n",
      "Best solution found. Point: tensor([0.1810, 0.2021], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.009  0.0297], Delta: [-0.009  -0.0297], Omega: [[0.172  0.1724]], bt: 0.1775, Consumption: 0.478\n",
      "Best solution found. Point: tensor([0.1686, 0.1902], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0178], Delta: [-0.     -0.0178], Omega: [[0.1686 0.1724]], bt: 0.1808, Consumption: 0.4781\n",
      "Best solution found. Point: tensor([0.8750, 0.0833], dtype=torch.float64), Delta+: [0.     0.0416], Delta-: [0.7021 0.    ], Delta: [-0.7021  0.0416], Omega: [[0.1729 0.1249]], bt: 0.222, Consumption: 0.4766\n",
      "Best solution found. Point: tensor([0.1667, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2445], Delta: [-0.     -0.2445], Omega: [[0.1667 0.1722]], bt: 0.1824, Consumption: 0.4776\n",
      "Best solution found. Point: tensor([0.1970, 0.1691], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.025 0.   ], Delta: [-0.025 -0.   ], Omega: [[0.1719 0.1691]], bt: 0.1808, Consumption: 0.4781\n",
      "Best solution found. Point: tensor([0.2917, 0.0000], dtype=torch.float64), Delta+: [0.     0.1252], Delta-: [0.1184 0.    ], Delta: [-0.1184  0.1252], Omega: [[0.1733 0.1252]], bt: 0.2225, Consumption: 0.4778\n",
      "Best solution found. Point: tensor([0.3333, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1616 0.1195], Delta: [-0.1616 -0.1195], Omega: [[0.1717 0.1722]], bt: 0.1772, Consumption: 0.4774\n",
      "Best solution found. Point: tensor([0.1250, 0.8333], dtype=torch.float64), Delta+: [0.0021 0.    ], Delta-: [0.     0.6606], Delta: [ 0.0021 -0.6606], Omega: [[0.1271 0.1727]], bt: 0.2201, Consumption: 0.4768\n",
      "Best solution found. Point: tensor([0.4583, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2867 0.0779], Delta: [-0.2867 -0.0779], Omega: [[0.1717 0.1721]], bt: 0.1772, Consumption: 0.4772\n",
      "Best solution found. Point: tensor([0.1250, 0.7083], dtype=torch.float64), Delta+: [0.0022 0.    ], Delta-: [0.     0.5355], Delta: [ 0.0022 -0.5355], Omega: [[0.1272 0.1728]], bt: 0.2202, Consumption: 0.4771\n",
      "Best solution found. Point: tensor([0.4583, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.2851 -0.    ], Delta: [-0.2851  0.    ], Omega: [[0.1733 0.125 ]], bt: 0.2227, Consumption: 0.4777\n",
      "Best solution found. Point: tensor([0.0833, 0.6667], dtype=torch.float64), Delta+: [0.0439 0.    ], Delta-: [0.     0.4938], Delta: [ 0.0439 -0.4938], Omega: [[0.1272 0.1728]], bt: 0.2202, Consumption: 0.4771\n",
      "Best solution found. Point: tensor([0.8750, 0.0000], dtype=torch.float64), Delta+: [0.     0.1248], Delta-: [0.7022 0.    ], Delta: [-0.7022  0.1248], Omega: [[0.1728 0.1248]], bt: 0.2219, Consumption: 0.4764\n",
      "Best solution found. Point: tensor([0.2917, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1198 0.0778], Delta: [-0.1198 -0.0778], Omega: [[0.1718 0.1722]], bt: 0.1773, Consumption: 0.4776\n",
      "Best solution found. Point: tensor([0.1667, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.6198], Delta: [-0.     -0.6198], Omega: [[0.1667 0.1718]], bt: 0.1817, Consumption: 0.4767\n",
      "Best solution found. Point: tensor([0.1667, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.2028], Delta: [-0.     -0.2028], Omega: [[0.1667 0.1722]], bt: 0.1825, Consumption: 0.4777\n",
      "Best solution found. Point: tensor([0.3750, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2032 0.0361], Delta: [-0.2032 -0.0361], Omega: [[0.1718 0.1722]], bt: 0.1773, Consumption: 0.4775\n",
      "Best solution found. Point: tensor([0.1250, 0.1250], dtype=torch.float64), Delta+: [0.004  0.0025], Delta-: [0. 0.], Delta: [0.004  0.0025], Omega: [[0.129  0.1275]], bt: 0.2649, Consumption: 0.4786\n",
      "Best solution found. Point: tensor([0.2917, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1202 0.4948], Delta: [-0.1202 -0.4948], Omega: [[0.1715 0.1719]], bt: 0.1769, Consumption: 0.4766\n",
      "Best solution found. Point: tensor([0.0417, 0.7917], dtype=torch.float64), Delta+: [0.0854 0.    ], Delta-: [0.    0.619], Delta: [ 0.0854 -0.619 ], Omega: [[0.1271 0.1727]], bt: 0.22, Consumption: 0.4767\n",
      "Best solution found. Point: tensor([0.5417, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3702 0.2448], Delta: [-0.3702 -0.2448], Omega: [[0.1715 0.1719]], bt: 0.1769, Consumption: 0.4766\n",
      "Best solution found. Point: tensor([0.0000, 0.7500], dtype=torch.float64), Delta+: [0.1271 0.    ], Delta-: [0.     0.5773], Delta: [ 0.1271 -0.5773], Omega: [[0.1271 0.1727]], bt: 0.22, Consumption: 0.4767\n",
      "Best solution found. Point: tensor([0.1250, 0.5833], dtype=torch.float64), Delta+: [0.0023 0.    ], Delta-: [0.     0.4104], Delta: [ 0.0023 -0.4104], Omega: [[0.1273 0.1729]], bt: 0.2203, Consumption: 0.4774\n",
      "Best solution found. Point: tensor([0.9583, 0.0000], dtype=torch.float64), Delta+: [0.     0.1248], Delta-: [0.7856 0.    ], Delta: [-0.7856  0.1248], Omega: [[0.1727 0.1248]], bt: 0.2218, Consumption: 0.4762\n",
      "Best solution found. Point: tensor([0.2917, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1202 0.4531], Delta: [-0.1202 -0.4531], Omega: [[0.1715 0.1719]], bt: 0.177, Consumption: 0.4767\n",
      "Best solution found. Point: tensor([0.6250, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4535 0.1615], Delta: [-0.4535 -0.1615], Omega: [[0.1715 0.1719]], bt: 0.1769, Consumption: 0.4766\n",
      "Best solution found. Point: tensor([0.1250, 0.2917], dtype=torch.float64), Delta+: [0.0025 0.    ], Delta-: [0.     0.1185], Delta: [ 0.0025 -0.1185], Omega: [[0.1275 0.1732]], bt: 0.2207, Consumption: 0.4781\n",
      "Best solution found. Point: tensor([0.6667, 0.1250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.4936 -0.    ], Delta: [-0.4936  0.    ], Omega: [[0.1731 0.125 ]], bt: 0.2223, Consumption: 0.4772\n",
      "Best solution found. Point: tensor([0.2917, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.12   0.2029], Delta: [-0.12   -0.2029], Omega: [[0.1717 0.1721]], bt: 0.1772, Consumption: 0.4773\n",
      "Best solution found. Point: tensor([0.2083, 0.7917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0369 0.6198], Delta: [-0.0369 -0.6198], Omega: [[0.1714 0.1718]], bt: 0.1769, Consumption: 0.4765\n",
      "Best solution found. Point: tensor([0.3750, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2035 0.4115], Delta: [-0.2035 -0.4115], Omega: [[0.1715 0.1719]], bt: 0.1769, Consumption: 0.4766\n",
      "Best solution found. Point: tensor([0.0000, 0.1667], dtype=torch.float64), Delta+: [ 0.1275 -0.    ], Delta-: [0. 0.], Delta: [ 0.1275 -0.    ], Omega: [[0.1275 0.1667]], bt: 0.2271, Consumption: 0.4781\n",
      "Best solution found. Point: tensor([0.0833, 0.2500], dtype=torch.float64), Delta+: [0.0441 0.    ], Delta-: [0.     0.0768], Delta: [ 0.0441 -0.0768], Omega: [[0.1275 0.1732]], bt: 0.2207, Consumption: 0.4781\n",
      "Best solution found. Point: tensor([0.1250, 0.3750], dtype=torch.float64), Delta+: [0.0024 0.    ], Delta-: [0.     0.2019], Delta: [ 0.0024 -0.2019], Omega: [[0.1274 0.1731]], bt: 0.2206, Consumption: 0.4779\n",
      "Best solution found. Point: tensor([0.1667, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4113], Delta: [-0.     -0.4113], Omega: [[0.1667 0.172 ]], bt: 0.1821, Consumption: 0.4772\n",
      "Best solution found. Point: tensor([0.3333, 0.0833], dtype=torch.float64), Delta+: [0.     0.0419], Delta-: [0.16 0.  ], Delta: [-0.16    0.0419], Omega: [[0.1733 0.1252]], bt: 0.2226, Consumption: 0.4779\n",
      "Best solution found. Point: tensor([0.2917, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1199 0.1612], Delta: [-0.1199 -0.1612], Omega: [[0.1717 0.1722]], bt: 0.1772, Consumption: 0.4774\n",
      "Best solution found. Point: tensor([0.0000, 0.6667], dtype=torch.float64), Delta+: [0.1272 0.    ], Delta-: [0.     0.4939], Delta: [ 0.1272 -0.4939], Omega: [[0.1272 0.1728]], bt: 0.2201, Consumption: 0.4769\n",
      "Best solution found. Point: tensor([0.7917, 0.0833], dtype=torch.float64), Delta+: [0.     0.0416], Delta-: [0.6187 0.    ], Delta: [-0.6187  0.0416], Omega: [[0.1729 0.1249]], bt: 0.2221, Consumption: 0.4768\n",
      "Best solution found. Point: tensor([0.5000, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3285 0.2448], Delta: [-0.3285 -0.2448], Omega: [[0.1715 0.1719]], bt: 0.177, Consumption: 0.4767\n",
      "Best solution found. Point: tensor([0.6250, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4535 0.078 ], Delta: [-0.4535 -0.078 ], Omega: [[0.1715 0.172 ]], bt: 0.177, Consumption: 0.4768\n",
      "Best solution found. Point: tensor([0.2083, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0364 0.036 ], Delta: [-0.0364 -0.036 ], Omega: [[0.1719 0.1723]], bt: 0.1774, Consumption: 0.4779\n",
      "Best solution found. Point: tensor([0.4167, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2452 0.4115], Delta: [-0.2452 -0.4115], Omega: [[0.1714 0.1718]], bt: 0.1769, Consumption: 0.4765\n",
      "Best solution found. Point: tensor([0.0000, 0.0417], dtype=torch.float64), Delta+: [0.1289 0.0857], Delta-: [0. 0.], Delta: [0.1289 0.0857], Omega: [[0.1289 0.1273]], bt: 0.2647, Consumption: 0.4781\n",
      "Best solution found. Point: tensor([0.0833, 0.7500], dtype=torch.float64), Delta+: [0.0438 0.    ], Delta-: [0.     0.5772], Delta: [ 0.0438 -0.5772], Omega: [[0.1272 0.1728]], bt: 0.2201, Consumption: 0.4769\n",
      "Best solution found. Point: tensor([0.1667, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.    0.453], Delta: [-0.    -0.453], Omega: [[0.1667 0.172 ]], bt: 0.182, Consumption: 0.4771\n",
      "Best solution found. Point: tensor([0.5833, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4119 0.2031], Delta: [-0.4119 -0.2031], Omega: [[0.1715 0.1719]], bt: 0.1769, Consumption: 0.4766\n",
      "Best solution found. Point: tensor([0.7083, 0.0417], dtype=torch.float64), Delta+: [0.     0.0833], Delta-: [0.5354 0.    ], Delta: [-0.5354  0.0833], Omega: [[0.173 0.125]], bt: 0.2221, Consumption: 0.4769\n",
      "Best solution found. Point: tensor([0.6250, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4536 0.2032], Delta: [-0.4536 -0.2032], Omega: [[0.1714 0.1718]], bt: 0.1769, Consumption: 0.4765\n",
      "Best solution found. Point: tensor([0.5417, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.37   0.0363], Delta: [-0.37   -0.0363], Omega: [[0.1716 0.1721]], bt: 0.1771, Consumption: 0.4771\n",
      "Best solution found. Point: tensor([0.1250, 0.0000], dtype=torch.float64), Delta+: [0.0039 0.1274], Delta-: [0. 0.], Delta: [0.0039 0.1274], Omega: [[0.1289 0.1274]], bt: 0.2648, Consumption: 0.4783\n",
      "Best solution found. Point: tensor([0.3333, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1618 0.4114], Delta: [-0.1618 -0.4114], Omega: [[0.1715 0.1719]], bt: 0.177, Consumption: 0.4767\n",
      "Best solution found. Point: tensor([0.1250, 0.5417], dtype=torch.float64), Delta+: [0.0023 0.    ], Delta-: [0.     0.3687], Delta: [ 0.0023 -0.3687], Omega: [[0.1273 0.173 ]], bt: 0.2204, Consumption: 0.4775\n",
      "Best solution found. Point: tensor([0.8333, 0.0000], dtype=torch.float64), Delta+: [0.     0.1249], Delta-: [0.6605 0.    ], Delta: [-0.6605  0.1249], Omega: [[0.1728 0.1249]], bt: 0.2219, Consumption: 0.4765\n",
      "Failure Rate: 0.00%\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 3\n",
      "include consumption: True\n",
      "Step 2a: Approximate NTR\n",
      "[[0.1424 0.1454]\n",
      " [0.1914 0.1435]\n",
      " [0.1404 0.1927]\n",
      " [0.1889 0.1907]]\n",
      "len tilde_omega_t: 4\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point: tensor([0.1629, 0.1765], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1629 0.1765]], bt: 0.2389, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1473, 0.1772], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1473 0.1772]], bt: 0.2537, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1763, 0.1815], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1763 0.1815]], bt: 0.2205, Consumption: 0.4217\n",
      "Best solution found. Point: tensor([0.1723, 0.1637], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1723 0.1637]], bt: 0.2422, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1517, 0.1788], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1517 0.1788]], bt: 0.2477, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1748, 0.1594], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1748 0.1594]], bt: 0.2441, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1645, 0.1609], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1645 0.1609]], bt: 0.2528, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1530, 0.1655], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.153  0.1655]], bt: 0.2597, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1770, 0.1796], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.177  0.1796]], bt: 0.2217, Consumption: 0.4217\n",
      "Best solution found. Point: tensor([0.1668, 0.1528], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1668 0.1528]], bt: 0.2586, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1746, 0.1474], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1746 0.1474]], bt: 0.2562, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1420, 0.1682], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.142  0.1682]], bt: 0.268, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1807, 0.1562], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1807 0.1562]], bt: 0.2414, Consumption: 0.4217\n",
      "Best solution found. Point: tensor([0.1494, 0.1803], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1494 0.1803]], bt: 0.2485, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1822, 0.1550], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1822 0.155 ]], bt: 0.2411, Consumption: 0.4217\n",
      "Best solution found. Point: tensor([0.1685, 0.1723], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1685 0.1723]], bt: 0.2375, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1846, 0.1601], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1846 0.1601]], bt: 0.2336, Consumption: 0.4217\n",
      "Best solution found. Point: tensor([0.1591, 0.1562], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1591 0.1562]], bt: 0.2629, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1728, 0.1594], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1728 0.1594]], bt: 0.246, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1636, 0.1743], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1636 0.1743]], bt: 0.2403, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1709, 0.1668], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1709 0.1668]], bt: 0.2405, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1719, 0.1723], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1719 0.1723]], bt: 0.234, Consumption: 0.4217\n",
      "Best solution found. Point: tensor([0.1748, 0.1792], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1748 0.1792]], bt: 0.2243, Consumption: 0.4217\n",
      "Best solution found. Point: tensor([0.1572, 0.1645], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1572 0.1645]], bt: 0.2565, Consumption: 0.4218\n",
      "Best solution found. Point: tensor([0.1630, 0.1844], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.163  0.1844]], bt: 0.2309, Consumption: 0.4217\n",
      "Best solution found. Point: tensor([0.1157, 0.1444], dtype=torch.float64), Delta+: [0.0269 0.0012], Delta-: [0. 0.], Delta: [0.0269 0.0012], Omega: [[0.1426 0.1456]], bt: 0.2903, Consumption: 0.4213\n",
      "Best solution found. Point: tensor([0.1724, 0.1427], dtype=torch.float64), Delta+: [-0.      0.0023], Delta-: [0. 0.], Delta: [-0.      0.0023], Omega: [[0.1724 0.145 ]], bt: 0.2613, Consumption: 0.4213\n",
      "Best solution found. Point: tensor([0.1527, 0.1232], dtype=torch.float64), Delta+: [0.     0.0224], Delta-: [0. 0.], Delta: [0.     0.0224], Omega: [[0.1527 0.1456]], bt: 0.2802, Consumption: 0.4213\n",
      "Best solution found. Point: tensor([0.1184, 0.1379], dtype=torch.float64), Delta+: [0.0242 0.0076], Delta-: [0. 0.], Delta: [0.0242 0.0076], Omega: [[0.1426 0.1456]], bt: 0.2903, Consumption: 0.4213\n",
      "Best solution found. Point: tensor([0.2372, 0.1655], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.046 -0.   ], Delta: [-0.046  0.   ], Omega: [[0.1912 0.1655]], bt: 0.222, Consumption: 0.421\n",
      "Best solution found. Point: tensor([0.2267, 0.1413], dtype=torch.float64), Delta+: [0.     0.0029], Delta-: [0.0344 0.    ], Delta: [-0.0344  0.0029], Omega: [[0.1923 0.1442]], bt: 0.2422, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.1370, 0.1431], dtype=torch.float64), Delta+: [0.0056 0.0025], Delta-: [0. 0.], Delta: [0.0056 0.0025], Omega: [[0.1426 0.1456]], bt: 0.2903, Consumption: 0.4214\n",
      "Best solution found. Point: tensor([0.2344, 0.1160], dtype=torch.float64), Delta+: [0.     0.0281], Delta-: [0.0421 0.    ], Delta: [-0.0421  0.0281], Omega: [[0.1923 0.1442]], bt: 0.2422, Consumption: 0.421\n",
      "Best solution found. Point: tensor([0.2262, 0.1755], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0357 0.    ], Delta: [-0.0357 -0.    ], Omega: [[0.1906 0.1755]], bt: 0.2128, Consumption: 0.421\n",
      "Best solution found. Point: tensor([0.1548, 0.1264], dtype=torch.float64), Delta+: [0.     0.0192], Delta-: [0. 0.], Delta: [0.     0.0192], Omega: [[0.1548 0.1456]], bt: 0.2782, Consumption: 0.4213\n",
      "Best solution found. Point: tensor([0.2300, 0.1158], dtype=torch.float64), Delta+: [0.     0.0284], Delta-: [0.0377 0.    ], Delta: [-0.0377  0.0284], Omega: [[0.1923 0.1442]], bt: 0.2422, Consumption: 0.421\n",
      "Best solution found. Point: tensor([0.1534, 0.2207], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0279], Delta: [ 0.     -0.0279], Omega: [[0.1534 0.1928]], bt: 0.2326, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.1453, 0.2235], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0302], Delta: [ 0.     -0.0302], Omega: [[0.1453 0.1933]], bt: 0.2401, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.1148, 0.1912], dtype=torch.float64), Delta+: [ 0.0263 -0.    ], Delta-: [0. 0.], Delta: [ 0.0263 -0.    ], Omega: [[0.1411 0.1912]], bt: 0.2464, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.1201, 0.2056], dtype=torch.float64), Delta+: [0.0209 0.    ], Delta-: [0.     0.0121], Delta: [ 0.0209 -0.0121], Omega: [[0.141  0.1936]], bt: 0.2442, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.1207, 0.1890], dtype=torch.float64), Delta+: [ 0.0205 -0.    ], Delta-: [0. 0.], Delta: [ 0.0205 -0.    ], Omega: [[0.1412 0.189 ]], bt: 0.2485, Consumption: 0.4212\n",
      "Best solution found. Point: tensor([0.2288, 0.1197], dtype=torch.float64), Delta+: [0.     0.0245], Delta-: [0.0365 0.    ], Delta: [-0.0365  0.0245], Omega: [[0.1923 0.1442]], bt: 0.2422, Consumption: 0.421\n",
      "Best solution found. Point: tensor([0.2167, 0.2245], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0272 0.0332], Delta: [-0.0272 -0.0332], Omega: [[0.1895 0.1913]], bt: 0.1981, Consumption: 0.4208\n",
      "Best solution found. Point: tensor([0.2100, 0.2140], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0205 0.0227], Delta: [-0.0205 -0.0227], Omega: [[0.1895 0.1913]], bt: 0.1982, Consumption: 0.4208\n",
      "Best solution found. Point: tensor([0.1267, 0.2073], dtype=torch.float64), Delta+: [0.0143 0.    ], Delta-: [0.     0.0137], Delta: [ 0.0143 -0.0137], Omega: [[0.141  0.1936]], bt: 0.2442, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.2266, 0.2179], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0371 0.0266], Delta: [-0.0371 -0.0266], Omega: [[0.1895 0.1913]], bt: 0.1981, Consumption: 0.4208\n",
      "Best solution found. Point: tensor([0.2253, 0.2217], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0358 0.0304], Delta: [-0.0358 -0.0304], Omega: [[0.1895 0.1913]], bt: 0.1981, Consumption: 0.4208\n",
      "Best solution found. Point: tensor([0.2188, 0.2176], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0293 0.0263], Delta: [-0.0293 -0.0263], Omega: [[0.1895 0.1913]], bt: 0.1981, Consumption: 0.4208\n",
      "Best solution found. Point: tensor([0.2287, 0.2013], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0392 0.01  ], Delta: [-0.0392 -0.01  ], Omega: [[0.1895 0.1913]], bt: 0.1982, Consumption: 0.4208\n",
      "Best solution found. Point: tensor([0.5833, 0.0833], dtype=torch.float64), Delta+: [0.     0.0606], Delta-: [0.3914 0.    ], Delta: [-0.3914  0.0606], Omega: [[0.1919 0.1439]], bt: 0.2417, Consumption: 0.4202\n",
      "Best solution found. Point: tensor([0.8750, 0.0833], dtype=torch.float64), Delta+: [0.     0.0604], Delta-: [0.6834 0.    ], Delta: [-0.6834  0.0604], Omega: [[0.1916 0.1437]], bt: 0.2414, Consumption: 0.4196\n",
      "Best solution found. Point: tensor([0.8333, 0.1250], dtype=torch.float64), Delta+: [0.     0.0187], Delta-: [0.6416 0.    ], Delta: [-0.6416  0.0187], Omega: [[0.1917 0.1437]], bt: 0.2415, Consumption: 0.4198\n",
      "Best solution found. Point: tensor([0.4167, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2277 0.3509], Delta: [-0.2277 -0.3509], Omega: [[0.189  0.1908]], bt: 0.1976, Consumption: 0.4197\n",
      "Best solution found. Point: tensor([0.0417, 0.6667], dtype=torch.float64), Delta+: [0.099 0.   ], Delta-: [0.     0.4736], Delta: [ 0.099  -0.4736], Omega: [[0.1406 0.193 ]], bt: 0.2435, Consumption: 0.42\n",
      "Best solution found. Point: tensor([0.4167, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2274 0.1006], Delta: [-0.2274 -0.1006], Omega: [[0.1892 0.191 ]], bt: 0.1979, Consumption: 0.4202\n",
      "Best solution found. Point: tensor([0.1250, 0.1250], dtype=torch.float64), Delta+: [0.0176 0.0206], Delta-: [0. 0.], Delta: [0.0176 0.0206], Omega: [[0.1426 0.1456]], bt: 0.2903, Consumption: 0.4213\n",
      "Best solution found. Point: tensor([0.9167, 0.0833], dtype=torch.float64), Delta+: [0.     0.0603], Delta-: [0.7251 0.    ], Delta: [-0.7251  0.0603], Omega: [[0.1916 0.1437]], bt: 0.2413, Consumption: 0.4195\n",
      "Best solution found. Point: tensor([0.0000, 0.6250], dtype=torch.float64), Delta+: [0.1406 0.    ], Delta-: [0.    0.432], Delta: [ 0.1406 -0.432 ], Omega: [[0.1406 0.193 ]], bt: 0.2435, Consumption: 0.42\n",
      "Best solution found. Point: tensor([0.0417, 0.7500], dtype=torch.float64), Delta+: [0.0989 0.    ], Delta-: [0.    0.557], Delta: [ 0.0989 -0.557 ], Omega: [[0.1406 0.193 ]], bt: 0.2434, Consumption: 0.4198\n",
      "Best solution found. Point: tensor([0.0833, 0.0833], dtype=torch.float64), Delta+: [0.0592 0.0622], Delta-: [0. 0.], Delta: [0.0592 0.0622], Omega: [[0.1426 0.1455]], bt: 0.2902, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.1667, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.2665], Delta: [ 0.     -0.2665], Omega: [[0.1667 0.1918]], bt: 0.2197, Consumption: 0.4205\n",
      "Best solution found. Point: tensor([0.4167, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2274 0.0172], Delta: [-0.2274 -0.0172], Omega: [[0.1893 0.1911]], bt: 0.198, Consumption: 0.4204\n",
      "Best solution found. Point: tensor([0.3750, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1859 0.2674], Delta: [-0.1859 -0.2674], Omega: [[0.1891 0.1909]], bt: 0.1978, Consumption: 0.42\n",
      "Best solution found. Point: tensor([0.2917, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1026 0.3925], Delta: [-0.1026 -0.3925], Omega: [[0.1891 0.1909]], bt: 0.1977, Consumption: 0.4199\n",
      "Best solution found. Point: tensor([0.0833, 0.6667], dtype=torch.float64), Delta+: [0.0573 0.    ], Delta-: [0.     0.4736], Delta: [ 0.0573 -0.4736], Omega: [[0.1407 0.1931]], bt: 0.2435, Consumption: 0.42\n",
      "Best solution found. Point: tensor([0.7500, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.5593 -0.    ], Delta: [-0.5593  0.    ], Omega: [[0.1907 0.1667]], bt: 0.22, Consumption: 0.4199\n",
      "Best solution found. Point: tensor([1., 0.], dtype=torch.float64), Delta+: [0.     0.1435], Delta-: [0.8086 0.    ], Delta: [-0.8086  0.1435], Omega: [[0.1914 0.1435]], bt: 0.2411, Consumption: 0.4192\n",
      "Best solution found. Point: tensor([0.4583, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2692 0.1007], Delta: [-0.2692 -0.1007], Omega: [[0.1892 0.191 ]], bt: 0.1978, Consumption: 0.4202\n",
      "Best solution found. Point: tensor([0.0833, 0.5417], dtype=torch.float64), Delta+: [0.0574 0.    ], Delta-: [0.     0.3485], Delta: [ 0.0574 -0.3485], Omega: [[0.1408 0.1932]], bt: 0.2437, Consumption: 0.4203\n",
      "Best solution found. Point: tensor([0.8333, 0.0000], dtype=torch.float64), Delta+: [0.     0.1437], Delta-: [0.6417 0.    ], Delta: [-0.6417  0.1437], Omega: [[0.1916 0.1437]], bt: 0.2413, Consumption: 0.4195\n",
      "Best solution found. Point: tensor([0.2917, 0.0833], dtype=torch.float64), Delta+: [0.     0.0608], Delta-: [0.0995 0.    ], Delta: [-0.0995  0.0608], Omega: [[0.1922 0.1441]], bt: 0.2421, Consumption: 0.4208\n",
      "Best solution found. Point: tensor([0.0833, 0.4583], dtype=torch.float64), Delta+: [0.0575 0.    ], Delta-: [0.    0.265], Delta: [ 0.0575 -0.265 ], Omega: [[0.1408 0.1933]], bt: 0.2438, Consumption: 0.4205\n",
      "Best solution found. Point: tensor([0.2500, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0609 0.3507], Delta: [-0.0609 -0.3507], Omega: [[0.1891 0.1909]], bt: 0.1978, Consumption: 0.4201\n",
      "Best solution found. Point: tensor([0.2917, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1023 0.0588], Delta: [-0.1023 -0.0588], Omega: [[0.1894 0.1912]], bt: 0.198, Consumption: 0.4206\n",
      "Best solution found. Point: tensor([0.2500, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0607 0.2256], Delta: [-0.0607 -0.2256], Omega: [[0.1893 0.1911]], bt: 0.1979, Consumption: 0.4203\n",
      "Best solution found. Point: tensor([0.7083, 0.0833], dtype=torch.float64), Delta+: [0.     0.0605], Delta-: [0.5165 0.    ], Delta: [-0.5165  0.0605], Omega: [[0.1918 0.1438]], bt: 0.2416, Consumption: 0.42\n",
      "Best solution found. Point: tensor([0.1250, 0.8333], dtype=torch.float64), Delta+: [0.0156 0.    ], Delta-: [0.     0.6404], Delta: [ 0.0156 -0.6404], Omega: [[0.1406 0.193 ]], bt: 0.2434, Consumption: 0.4198\n",
      "Best solution found. Point: tensor([0.2083, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0191 0.2673], Delta: [-0.0191 -0.2673], Omega: [[0.1893 0.1911]], bt: 0.1979, Consumption: 0.4203\n",
      "Best solution found. Point: tensor([0.4583, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2692 0.1841], Delta: [-0.2692 -0.1841], Omega: [[0.1891 0.1909]], bt: 0.1978, Consumption: 0.42\n",
      "Best solution found. Point: tensor([0.1250, 0.0417], dtype=torch.float64), Delta+: [0.0176 0.1038], Delta-: [0. 0.], Delta: [0.0176 0.1038], Omega: [[0.1426 0.1455]], bt: 0.2902, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.4167, 0.0833], dtype=torch.float64), Delta+: [0.     0.0607], Delta-: [0.2246 0.    ], Delta: [-0.2246  0.0607], Omega: [[0.1921 0.144 ]], bt: 0.2419, Consumption: 0.4206\n",
      "Best solution found. Point: tensor([0.2083, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0193 0.4758], Delta: [-0.0193 -0.4758], Omega: [[0.1891 0.1909]], bt: 0.1977, Consumption: 0.4199\n",
      "Best solution found. Point: tensor([0.0417, 0.4583], dtype=torch.float64), Delta+: [0.0991 0.    ], Delta-: [0.     0.2651], Delta: [ 0.0991 -0.2651], Omega: [[0.1408 0.1933]], bt: 0.2437, Consumption: 0.4204\n",
      "Best solution found. Point: tensor([0.5833, 0.0000], dtype=torch.float64), Delta+: [0.     0.1438], Delta-: [0.3915 0.    ], Delta: [-0.3915  0.1438], Omega: [[0.1918 0.1438]], bt: 0.2416, Consumption: 0.42\n",
      "Best solution found. Point: tensor([0.6250, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4359 0.0591], Delta: [-0.4359 -0.0591], Omega: [[0.1891 0.1909]], bt: 0.1977, Consumption: 0.4199\n",
      "Best solution found. Point: tensor([0.7917, 0.0417], dtype=torch.float64), Delta+: [0.    0.102], Delta-: [0.6 0. ], Delta: [-0.6    0.102], Omega: [[0.1917 0.1437]], bt: 0.2414, Consumption: 0.4197\n",
      "Best solution found. Point: tensor([0.0417, 0.0833], dtype=torch.float64), Delta+: [0.1009 0.0621], Delta-: [0. 0.], Delta: [0.1009 0.0621], Omega: [[0.1425 0.1455]], bt: 0.2901, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.0417, 0.1667], dtype=torch.float64), Delta+: [ 0.1005 -0.    ], Delta-: [0. 0.], Delta: [ 0.1005 -0.    ], Omega: [[0.1422 0.1667]], bt: 0.2695, Consumption: 0.4211\n",
      "Best solution found. Point: tensor([0.9167, 0.0000], dtype=torch.float64), Delta+: [0.     0.1436], Delta-: [0.7252 0.    ], Delta: [-0.7252  0.1436], Omega: [[0.1915 0.1436]], bt: 0.2412, Consumption: 0.4193\n",
      "Best solution found. Point: tensor([0.0417, 0.7917], dtype=torch.float64), Delta+: [0.0989 0.    ], Delta-: [0.     0.5987], Delta: [ 0.0989 -0.5987], Omega: [[0.1405 0.1929]], bt: 0.2433, Consumption: 0.4197\n",
      "Best solution found. Point: tensor([0.3750, 0.0833], dtype=torch.float64), Delta+: [0.     0.0607], Delta-: [0.1829 0.    ], Delta: [-0.1829  0.0607], Omega: [[0.1921 0.144 ]], bt: 0.242, Consumption: 0.4207\n",
      "Best solution found. Point: tensor([0.0833, 0.3333], dtype=torch.float64), Delta+: [0.0576 0.    ], Delta-: [0.     0.1399], Delta: [ 0.0576 -0.1399], Omega: [[0.1409 0.1934]], bt: 0.244, Consumption: 0.4207\n",
      "Best solution found. Point: tensor([0.5000, 0.0833], dtype=torch.float64), Delta+: [0.     0.0606], Delta-: [0.308 0.   ], Delta: [-0.308   0.0606], Omega: [[0.192 0.144]], bt: 0.2418, Consumption: 0.4204\n",
      "Best solution found. Point: tensor([0.5417, 0.0417], dtype=torch.float64), Delta+: [0.     0.1022], Delta-: [0.3498 0.    ], Delta: [-0.3498  0.1022], Omega: [[0.1919 0.1439]], bt: 0.2417, Consumption: 0.4202\n",
      "Best solution found. Point: tensor([0., 0.], dtype=torch.float64), Delta+: [0.1424 0.1454], Delta-: [0. 0.], Delta: [0.1424 0.1454], Omega: [[0.1424 0.1454]], bt: 0.2899, Consumption: 0.4208\n",
      "Best solution found. Point: tensor([0.6250, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.436  0.1008], Delta: [-0.436  -0.1008], Omega: [[0.189  0.1908]], bt: 0.1977, Consumption: 0.4198\n",
      "Best solution found. Point: tensor([0.4583, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.2674 -0.    ], Delta: [-0.2674  0.    ], Omega: [[0.191  0.1667]], bt: 0.2205, Consumption: 0.4205\n",
      "Best solution found. Point: tensor([0.2917, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1025 0.2674], Delta: [-0.1025 -0.2674], Omega: [[0.1892 0.191 ]], bt: 0.1978, Consumption: 0.4202\n",
      "Best solution found. Point: tensor([0.0833, 0.3750], dtype=torch.float64), Delta+: [0.0575 0.    ], Delta-: [0.     0.1816], Delta: [ 0.0575 -0.1816], Omega: [[0.1409 0.1934]], bt: 0.2439, Consumption: 0.4207\n",
      "Best solution found. Point: tensor([0.5833, 0.0417], dtype=torch.float64), Delta+: [0.     0.1022], Delta-: [0.3915 0.    ], Delta: [-0.3915  0.1022], Omega: [[0.1919 0.1439]], bt: 0.2417, Consumption: 0.4201\n",
      "Failure Rate: 0.00%\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 2\n",
      "include consumption: True\n",
      "Step 2a: Approximate NTR\n",
      "[[0.151  0.1508]\n",
      " [0.202  0.1516]\n",
      " [0.1518 0.2023]\n",
      " [0.2013 0.2012]]\n",
      "len tilde_omega_t: 4\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point: tensor([0.1962, 0.1839], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1962 0.1839]], bt: 0.2286, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1647, 0.1570], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1647 0.157 ]], bt: 0.287, Consumption: 0.3914\n",
      "Best solution found. Point: tensor([0.1557, 0.1705], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1557 0.1705]], bt: 0.2824, Consumption: 0.3914\n",
      "Best solution found. Point: tensor([0.1653, 0.1696], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1653 0.1696]], bt: 0.2737, Consumption: 0.3914\n",
      "Best solution found. Point: tensor([0.1649, 0.1801], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1649 0.1801]], bt: 0.2637, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1764, 0.1769], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1764 0.1769]], bt: 0.2554, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1852, 0.1617], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1852 0.1617]], bt: 0.2617, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1934, 0.1847], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1934 0.1847]], bt: 0.2307, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1579, 0.1723], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1579 0.1723]], bt: 0.2784, Consumption: 0.3914\n",
      "Best solution found. Point: tensor([0.1957, 0.1583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1957 0.1583]], bt: 0.2547, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1752, 0.1868], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1752 0.1868]], bt: 0.2467, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1835, 0.1703], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1835 0.1703]], bt: 0.2549, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1727, 0.1538], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1727 0.1538]], bt: 0.2822, Consumption: 0.3914\n",
      "Best solution found. Point: tensor([0.1781, 0.1674], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1781 0.1674]], bt: 0.2632, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1593, 0.1907], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1593 0.1907]], bt: 0.2587, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1944, 0.1816], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1944 0.1816]], bt: 0.2327, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1980, 0.1596], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.198  0.1596]], bt: 0.2511, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1626, 0.1815], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1626 0.1815]], bt: 0.2645, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1762, 0.1695], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1762 0.1695]], bt: 0.263, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1645, 0.1694], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1645 0.1694]], bt: 0.2747, Consumption: 0.3914\n",
      "Best solution found. Point: tensor([0.1639, 0.1964], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1639 0.1964]], bt: 0.2484, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1758, 0.1752], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1758 0.1752]], bt: 0.2577, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1703, 0.1833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1703 0.1833]], bt: 0.255, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1753, 0.1946], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1753 0.1946]], bt: 0.2388, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1854, 0.1748], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1854 0.1748]], bt: 0.2485, Consumption: 0.3913\n",
      "Best solution found. Point: tensor([0.1209, 0.1758], dtype=torch.float64), Delta+: [0.0317 0.    ], Delta-: [ 0. -0.], Delta: [0.0317 0.    ], Omega: [[0.1526 0.1758]], bt: 0.2809, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.1351, 0.1846], dtype=torch.float64), Delta+: [0.0176 0.    ], Delta-: [0. 0.], Delta: [ 0.0176 -0.    ], Omega: [[0.1527 0.1846]], bt: 0.272, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.1468, 0.1453], dtype=torch.float64), Delta+: [0.0046 0.0059], Delta-: [0. 0.], Delta: [0.0046 0.0059], Omega: [[0.1514 0.1511]], bt: 0.3067, Consumption: 0.3907\n",
      "Best solution found. Point: tensor([0.2113, 0.1264], dtype=torch.float64), Delta+: [0.     0.0259], Delta-: [0.0083 0.    ], Delta: [-0.0083  0.0259], Omega: [[0.2029 0.1523]], bt: 0.2542, Consumption: 0.3904\n",
      "Best solution found. Point: tensor([0.1467, 0.1856], dtype=torch.float64), Delta+: [0.006 0.   ], Delta-: [0. 0.], Delta: [ 0.006 -0.   ], Omega: [[0.1527 0.1856]], bt: 0.271, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.2433, 0.1290], dtype=torch.float64), Delta+: [0.     0.0233], Delta-: [0.0404 0.    ], Delta: [-0.0404  0.0233], Omega: [[0.2029 0.1522]], bt: 0.2542, Consumption: 0.3904\n",
      "Best solution found. Point: tensor([0.2366, 0.1657], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0337 -0.    ], Delta: [-0.0337  0.    ], Omega: [[0.2029 0.1657]], bt: 0.2409, Consumption: 0.3904\n",
      "Best solution found. Point: tensor([0.1216, 0.1268], dtype=torch.float64), Delta+: [0.0298 0.0244], Delta-: [0. 0.], Delta: [0.0298 0.0244], Omega: [[0.1513 0.1511]], bt: 0.3067, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.1340, 0.1779], dtype=torch.float64), Delta+: [0.0186 0.    ], Delta-: [ 0. -0.], Delta: [0.0186 0.    ], Omega: [[0.1526 0.1779]], bt: 0.2787, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.2386, 0.1819], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.036 0.   ], Delta: [-0.036 -0.   ], Omega: [[0.2025 0.1819]], bt: 0.2251, Consumption: 0.3903\n",
      "Best solution found. Point: tensor([0.1324, 0.1804], dtype=torch.float64), Delta+: [0.0202 0.    ], Delta-: [ 0. -0.], Delta: [0.0202 0.    ], Omega: [[0.1527 0.1804]], bt: 0.2762, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.2117, 0.1809], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0091 0.    ], Delta: [-0.0091 -0.    ], Omega: [[0.2026 0.1809]], bt: 0.2261, Consumption: 0.3904\n",
      "Best solution found. Point: tensor([0.2365, 0.1480], dtype=torch.float64), Delta+: [0.     0.0042], Delta-: [0.0336 0.    ], Delta: [-0.0336  0.0042], Omega: [[0.2029 0.1523]], bt: 0.2542, Consumption: 0.3904\n",
      "Best solution found. Point: tensor([0.1712, 0.2254], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0227], Delta: [ 0.     -0.0227], Omega: [[0.1712 0.2027]], bt: 0.2355, Consumption: 0.3904\n",
      "Best solution found. Point: tensor([0.1400, 0.2206], dtype=torch.float64), Delta+: [0.0126 0.    ], Delta-: [0.     0.0173], Delta: [ 0.0126 -0.0173], Omega: [[0.1525 0.2033]], bt: 0.2536, Consumption: 0.3904\n",
      "Best solution found. Point: tensor([0.1227, 0.2203], dtype=torch.float64), Delta+: [0.0298 0.    ], Delta-: [0.    0.017], Delta: [ 0.0298 -0.017 ], Omega: [[0.1525 0.2033]], bt: 0.2536, Consumption: 0.3904\n",
      "Best solution found. Point: tensor([0.1473, 0.1884], dtype=torch.float64), Delta+: [0.0055 0.    ], Delta-: [0. 0.], Delta: [ 0.0055 -0.    ], Omega: [[0.1527 0.1884]], bt: 0.2682, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.1522, 0.2141], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0108], Delta: [ 0.     -0.0108], Omega: [[0.1522 0.2033]], bt: 0.254, Consumption: 0.3905\n",
      "Best solution found. Point: tensor([0.1882, 0.2308], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0287], Delta: [-0.     -0.0287], Omega: [[0.1882 0.2022]], bt: 0.2192, Consumption: 0.3903\n",
      "Best solution found. Point: tensor([0.2183, 0.1884], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0159 0.    ], Delta: [-0.0159 -0.    ], Omega: [[0.2023 0.1884]], bt: 0.2188, Consumption: 0.3903\n",
      "Best solution found. Point: tensor([0.2318, 0.1878], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0294 0.    ], Delta: [-0.0294 -0.    ], Omega: [[0.2023 0.1878]], bt: 0.2194, Consumption: 0.3903\n",
      "Best solution found. Point: tensor([0.2256, 0.2111], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0237 0.0093], Delta: [-0.0237 -0.0093], Omega: [[0.2019 0.2018]], bt: 0.2059, Consumption: 0.3902\n",
      "Best solution found. Point: tensor([0.2250, 0.2113], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0231 0.0095], Delta: [-0.0231 -0.0095], Omega: [[0.2019 0.2018]], bt: 0.2059, Consumption: 0.3902\n",
      "Best solution found. Point: tensor([0.0000, 0.3333], dtype=torch.float64), Delta+: [0.1523 0.    ], Delta-: [0.     0.1303], Delta: [ 0.1523 -0.1303], Omega: [[0.1523 0.203 ]], bt: 0.2533, Consumption: 0.39\n",
      "Best solution found. Point: tensor([0.0833, 0.5000], dtype=torch.float64), Delta+: [0.069 0.   ], Delta-: [0.     0.2971], Delta: [ 0.069  -0.2971], Omega: [[0.1523 0.2029]], bt: 0.2532, Consumption: 0.3898\n",
      "Best solution found. Point: tensor([0.4167, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2152 0.2987], Delta: [-0.2152 -0.2987], Omega: [[0.2014 0.2013]], bt: 0.2054, Consumption: 0.3893\n",
      "Best solution found. Point: tensor([0.0833, 0.0833], dtype=torch.float64), Delta+: [0.0679 0.0677], Delta-: [0. 0.], Delta: [0.0679 0.0677], Omega: [[0.1513 0.1511]], bt: 0.3065, Consumption: 0.3905\n",
      "Best solution found. Point: tensor([0.3333, 0.0417], dtype=torch.float64), Delta+: [0.     0.1104], Delta-: [0.1306 0.    ], Delta: [-0.1306  0.1104], Omega: [[0.2027 0.1521]], bt: 0.2539, Consumption: 0.39\n",
      "Best solution found. Point: tensor([0.2312, 0.2185], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0293 0.0168], Delta: [-0.0293 -0.0168], Omega: [[0.2019 0.2018]], bt: 0.2059, Consumption: 0.3902\n",
      "Best solution found. Point: tensor([0.1667, 0.0833], dtype=torch.float64), Delta+: [0.     0.0683], Delta-: [-0.  0.], Delta: [0.     0.0683], Omega: [[0.1667 0.1516]], bt: 0.2908, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.4583, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2567 0.0485], Delta: [-0.2567 -0.0485], Omega: [[0.2016 0.2015]], bt: 0.2057, Consumption: 0.3897\n",
      "Best solution found. Point: tensor([0.1250, 0.5417], dtype=torch.float64), Delta+: [0.0273 0.    ], Delta-: [0.     0.3387], Delta: [ 0.0273 -0.3387], Omega: [[0.1523 0.2029]], bt: 0.2532, Consumption: 0.3898\n",
      "Best solution found. Point: tensor([0.9583, 0.0417], dtype=torch.float64), Delta+: [0.   0.11], Delta-: [0.7563 0.    ], Delta: [-0.7563  0.11  ], Omega: [[0.2021 0.1516]], bt: 0.2531, Consumption: 0.3888\n",
      "Best solution found. Point: tensor([0.3750, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1732 0.0067], Delta: [-0.1732 -0.0067], Omega: [[0.2018 0.2016]], bt: 0.2058, Consumption: 0.3899\n",
      "Best solution found. Point: tensor([0.5833, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.3808 -0.    ], Delta: [-0.3808  0.    ], Omega: [[0.2025 0.1667]], bt: 0.2392, Consumption: 0.3897\n",
      "Best solution found. Point: tensor([0.9167, 0.0417], dtype=torch.float64), Delta+: [0.   0.11], Delta-: [0.7145 0.    ], Delta: [-0.7145  0.11  ], Omega: [[0.2021 0.1517]], bt: 0.2532, Consumption: 0.3889\n",
      "Best solution found. Point: tensor([0.7083, 0.0417], dtype=torch.float64), Delta+: [0.     0.1102], Delta-: [0.506 0.   ], Delta: [-0.506   0.1102], Omega: [[0.2023 0.1518]], bt: 0.2535, Consumption: 0.3893\n",
      "Best solution found. Point: tensor([0.4167, 0.1250], dtype=torch.float64), Delta+: [0.     0.0271], Delta-: [0.214 0.   ], Delta: [-0.214   0.0271], Omega: [[0.2027 0.1521]], bt: 0.2539, Consumption: 0.39\n",
      "Best solution found. Point: tensor([0.0000, 0.6250], dtype=torch.float64), Delta+: [0.1521 0.    ], Delta-: [0.     0.4223], Delta: [ 0.1521 -0.4223], Omega: [[0.1521 0.2027]], bt: 0.2529, Consumption: 0.3894\n",
      "Best solution found. Point: tensor([0.0417, 0.5833], dtype=torch.float64), Delta+: [0.1105 0.    ], Delta-: [0.     0.3805], Delta: [ 0.1105 -0.3805], Omega: [[0.1522 0.2028]], bt: 0.253, Consumption: 0.3895\n",
      "Best solution found. Point: tensor([0.2083, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0064 0.0065], Delta: [-0.0064 -0.0065], Omega: [[0.2019 0.2018]], bt: 0.206, Consumption: 0.3903\n",
      "Best solution found. Point: tensor([0.5417, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3402 0.0903], Delta: [-0.3402 -0.0903], Omega: [[0.2015 0.2014]], bt: 0.2055, Consumption: 0.3894\n",
      "Best solution found. Point: tensor([0.1667, 0.6667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.4643], Delta: [ 0.     -0.4643], Omega: [[0.1667 0.2024]], bt: 0.239, Consumption: 0.3896\n",
      "Best solution found. Point: tensor([0.0833, 0.3333], dtype=torch.float64), Delta+: [0.0691 0.    ], Delta-: [0.     0.1302], Delta: [ 0.0691 -0.1302], Omega: [[0.1524 0.2031]], bt: 0.2534, Consumption: 0.3901\n",
      "Best solution found. Point: tensor([0.5417, 0.1250], dtype=torch.float64), Delta+: [0.    0.027], Delta-: [0.3391 0.    ], Delta: [-0.3391  0.027 ], Omega: [[0.2026 0.152 ]], bt: 0.2538, Consumption: 0.3898\n",
      "Best solution found. Point: tensor([0.3333, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1316 0.0901], Delta: [-0.1316 -0.0901], Omega: [[0.2017 0.2016]], bt: 0.2057, Consumption: 0.3898\n",
      "Best solution found. Point: tensor([0.5000, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2984 0.0485], Delta: [-0.2984 -0.0485], Omega: [[0.2016 0.2015]], bt: 0.2056, Consumption: 0.3896\n",
      "Best solution found. Point: tensor([0.2917, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.09   0.1735], Delta: [-0.09   -0.1735], Omega: [[0.2017 0.2015]], bt: 0.2057, Consumption: 0.3898\n",
      "Best solution found. Point: tensor([0., 0.], dtype=torch.float64), Delta+: [0.1511 0.1509], Delta-: [0. 0.], Delta: [0.1511 0.1509], Omega: [[0.1511 0.1509]], bt: 0.3063, Consumption: 0.3901\n",
      "Best solution found. Point: tensor([0.2917, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0902 0.3403], Delta: [-0.0902 -0.3403], Omega: [[0.2015 0.2014]], bt: 0.2055, Consumption: 0.3894\n",
      "Best solution found. Point: tensor([0.8333, 0.0833], dtype=torch.float64), Delta+: [0.     0.0684], Delta-: [0.6311 0.    ], Delta: [-0.6311  0.0684], Omega: [[0.2023 0.1518]], bt: 0.2533, Consumption: 0.3891\n",
      "Best solution found. Point: tensor([0.7917, 0.1250], dtype=torch.float64), Delta+: [0.     0.0268], Delta-: [0.5893 0.    ], Delta: [-0.5893  0.0268], Omega: [[0.2023 0.1518]], bt: 0.2535, Consumption: 0.3893\n",
      "Best solution found. Point: tensor([0.3750, 0.0417], dtype=torch.float64), Delta+: [0.     0.1104], Delta-: [0.1723 0.    ], Delta: [-0.1723  0.1104], Omega: [[0.2027 0.1521]], bt: 0.2539, Consumption: 0.39\n",
      "Best solution found. Point: tensor([0.1250, 0.0833], dtype=torch.float64), Delta+: [0.0263 0.0677], Delta-: [0. 0.], Delta: [0.0263 0.0677], Omega: [[0.1513 0.1511]], bt: 0.3066, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.7917, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.5894 -0.    ], Delta: [-0.5894  0.    ], Omega: [[0.2023 0.1667]], bt: 0.2388, Consumption: 0.3893\n",
      "Best solution found. Point: tensor([0.4167, 0.0417], dtype=torch.float64), Delta+: [0.     0.1104], Delta-: [0.214 0.   ], Delta: [-0.214   0.1104], Omega: [[0.2026 0.152 ]], bt: 0.2538, Consumption: 0.3899\n",
      "Best solution found. Point: tensor([0.4167, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.215  0.0902], Delta: [-0.215  -0.0902], Omega: [[0.2016 0.2015]], bt: 0.2057, Consumption: 0.3897\n",
      "Best solution found. Point: tensor([0.0417, 0.2917], dtype=torch.float64), Delta+: [0.1107 0.    ], Delta-: [0.     0.0886], Delta: [ 0.1107 -0.0886], Omega: [[0.1524 0.2031]], bt: 0.2534, Consumption: 0.3901\n",
      "Best solution found. Point: tensor([0.5833, 0.0417], dtype=torch.float64), Delta+: [0.     0.1103], Delta-: [0.3809 0.    ], Delta: [-0.3809  0.1103], Omega: [[0.2025 0.1519]], bt: 0.2536, Consumption: 0.3895\n",
      "Best solution found. Point: tensor([0.0000, 0.6667], dtype=torch.float64), Delta+: [0.1521 0.    ], Delta-: [0.    0.464], Delta: [ 0.1521 -0.464 ], Omega: [[0.1521 0.2027]], bt: 0.2529, Consumption: 0.3893\n",
      "Best solution found. Point: tensor([0.4583, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2569 0.2571], Delta: [-0.2569 -0.2571], Omega: [[0.2014 0.2013]], bt: 0.2054, Consumption: 0.3893\n",
      "Best solution found. Point: tensor([0.2500, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0487 0.5488], Delta: [-0.0487 -0.5488], Omega: [[0.2013 0.2012]], bt: 0.2054, Consumption: 0.3891\n",
      "Best solution found. Point: tensor([0.2500, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0486 0.5071], Delta: [-0.0486 -0.5071], Omega: [[0.2014 0.2012]], bt: 0.2054, Consumption: 0.3892\n",
      "Best solution found. Point: tensor([0.4583, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.257  0.3405], Delta: [-0.257  -0.3405], Omega: [[0.2013 0.2012]], bt: 0.2054, Consumption: 0.3891\n",
      "Best solution found. Point: tensor([0.7083, 0.1250], dtype=torch.float64), Delta+: [0.     0.0269], Delta-: [0.5059 0.    ], Delta: [-0.5059  0.0269], Omega: [[0.2024 0.1519]], bt: 0.2536, Consumption: 0.3895\n",
      "Best solution found. Point: tensor([0.0417, 0.4583], dtype=torch.float64), Delta+: [0.1106 0.    ], Delta-: [0.     0.2554], Delta: [ 0.1106 -0.2554], Omega: [[0.1523 0.2029]], bt: 0.2532, Consumption: 0.3898\n",
      "Best solution found. Point: tensor([0.2917, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0902 0.4237], Delta: [-0.0902 -0.4237], Omega: [[0.2014 0.2013]], bt: 0.2054, Consumption: 0.3893\n",
      "Best solution found. Point: tensor([0.6250, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4235 0.0487], Delta: [-0.4235 -0.0487], Omega: [[0.2015 0.2013]], bt: 0.2055, Consumption: 0.3894\n",
      "Best solution found. Point: tensor([0.2083, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0069 0.5071], Delta: [-0.0069 -0.5071], Omega: [[0.2014 0.2013]], bt: 0.2054, Consumption: 0.3893\n",
      "Best solution found. Point: tensor([0.6667, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4653 0.0904], Delta: [-0.4653 -0.0904], Omega: [[0.2014 0.2012]], bt: 0.2054, Consumption: 0.3892\n",
      "Best solution found. Point: tensor([0.2917, 0.1250], dtype=torch.float64), Delta+: [0.     0.0272], Delta-: [0.0888 0.    ], Delta: [-0.0888  0.0272], Omega: [[0.2028 0.1522]], bt: 0.2541, Consumption: 0.3903\n",
      "Best solution found. Point: tensor([0.1667, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [-0.      0.0054], Delta: [ 0.     -0.0054], Omega: [[0.1667 0.2029]], bt: 0.24, Consumption: 0.3905\n",
      "Best solution found. Point: tensor([0.1667, 0.1250], dtype=torch.float64), Delta+: [0.     0.0267], Delta-: [-0.  0.], Delta: [0.     0.0267], Omega: [[0.1667 0.1517]], bt: 0.2909, Consumption: 0.3906\n",
      "Best solution found. Point: tensor([0.2083, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0068 0.3819], Delta: [-0.0068 -0.3819], Omega: [[0.2016 0.2014]], bt: 0.2056, Consumption: 0.3895\n",
      "Best solution found. Point: tensor([0.6250, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4237 0.1738], Delta: [-0.4237 -0.1738], Omega: [[0.2013 0.2012]], bt: 0.2054, Consumption: 0.3891\n",
      "Failure Rate: 0.00%\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 1\n",
      "include consumption: True\n",
      "Step 2a: Approximate NTR\n",
      "[[0.1572 0.1555]\n",
      " [0.2074 0.1558]\n",
      " [0.1592 0.2057]\n",
      " [0.2073 0.2063]]\n",
      "len tilde_omega_t: 4\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point: tensor([0.1690, 0.1957], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.169  0.1957]], bt: 0.2616, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1836, 0.1818], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1836 0.1818]], bt: 0.2609, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1959, 0.1876], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1959 0.1876]], bt: 0.2428, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.2014, 0.2007], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2014 0.2007]], bt: 0.2243, Consumption: 0.3736\n",
      "Best solution found. Point: tensor([0.1988, 0.1575], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1988 0.1575]], bt: 0.27, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1775, 0.1950], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1775 0.195 ]], bt: 0.2538, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1764, 0.1712], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1764 0.1712]], bt: 0.2787, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1789, 0.1773], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1789 0.1773]], bt: 0.2701, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1801, 0.1777], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1801 0.1777]], bt: 0.2684, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1964, 0.1997], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1964 0.1997]], bt: 0.2303, Consumption: 0.3736\n",
      "Best solution found. Point: tensor([0.1740, 0.1685], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.174  0.1685]], bt: 0.2838, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1724, 0.1960], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1724 0.196 ]], bt: 0.2579, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1936, 0.1759], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1936 0.1759]], bt: 0.2568, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1758, 0.1829], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1758 0.1829]], bt: 0.2675, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1818, 0.1973], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1818 0.1973]], bt: 0.2473, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1795, 0.1796], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1795 0.1796]], bt: 0.2672, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1913, 0.1743], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1913 0.1743]], bt: 0.2607, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1773, 0.1823], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1773 0.1823]], bt: 0.2667, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1783, 0.1960], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1783 0.196 ]], bt: 0.2521, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1746, 0.1664], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1746 0.1664]], bt: 0.2853, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1870, 0.1758], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.187  0.1758]], bt: 0.2636, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1841, 0.1948], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1841 0.1948]], bt: 0.2474, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1705, 0.1702], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1705 0.1702]], bt: 0.2856, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1630, 0.1937], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.163  0.1937]], bt: 0.2697, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1750, 0.1376], dtype=torch.float64), Delta+: [0.     0.0181], Delta-: [-0.  0.], Delta: [0.     0.0181], Omega: [[0.175  0.1557]], bt: 0.2964, Consumption: 0.3728\n",
      "Best solution found. Point: tensor([0.1628, 0.1490], dtype=torch.float64), Delta+: [0.     0.0068], Delta-: [-0.  0.], Delta: [0.     0.0068], Omega: [[0.1628 0.1558]], bt: 0.3085, Consumption: 0.3729\n",
      "Best solution found. Point: tensor([0.1854, 0.1637], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1854 0.1637]], bt: 0.2773, Consumption: 0.3737\n",
      "Best solution found. Point: tensor([0.1342, 0.1451], dtype=torch.float64), Delta+: [0.0233 0.0107], Delta-: [0. 0.], Delta: [0.0233 0.0107], Omega: [[0.1575 0.1559]], bt: 0.3136, Consumption: 0.3729\n",
      "Best solution found. Point: tensor([0.1388, 0.1714], dtype=torch.float64), Delta+: [0.0194 0.    ], Delta-: [ 0. -0.], Delta: [0.0194 0.    ], Omega: [[0.1582 0.1714]], bt: 0.2975, Consumption: 0.3728\n",
      "Best solution found. Point: tensor([0.2112, 0.1536], dtype=torch.float64), Delta+: [0.    0.003], Delta-: [0.0028 0.    ], Delta: [-0.0028  0.003 ], Omega: [[0.2084 0.1566]], bt: 0.2623, Consumption: 0.3727\n",
      "Best solution found. Point: tensor([0.2236, 0.1506], dtype=torch.float64), Delta+: [0.     0.0059], Delta-: [0.0152 0.    ], Delta: [-0.0152  0.0059], Omega: [[0.2084 0.1566]], bt: 0.2623, Consumption: 0.3727\n",
      "Best solution found. Point: tensor([0.2128, 0.1656], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0041 -0.    ], Delta: [-0.0041  0.    ], Omega: [[0.2087 0.1656]], bt: 0.253, Consumption: 0.3727\n",
      "Best solution found. Point: tensor([0.1490, 0.1415], dtype=torch.float64), Delta+: [0.0085 0.0144], Delta-: [0. 0.], Delta: [0.0085 0.0144], Omega: [[0.1575 0.1559]], bt: 0.3136, Consumption: 0.3729\n",
      "Best solution found. Point: tensor([0.2318, 0.1456], dtype=torch.float64), Delta+: [0.    0.011], Delta-: [0.0234 0.    ], Delta: [-0.0234  0.011 ], Omega: [[0.2084 0.1565]], bt: 0.2623, Consumption: 0.3726\n",
      "Best solution found. Point: tensor([0.2490, 0.1767], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0403 -0.    ], Delta: [-0.0403  0.    ], Omega: [[0.2086 0.1767]], bt: 0.2419, Consumption: 0.3725\n",
      "Best solution found. Point: tensor([0.1625, 0.2239], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0172], Delta: [ 0.     -0.0172], Omega: [[0.1625 0.2067]], bt: 0.258, Consumption: 0.3727\n",
      "Best solution found. Point: tensor([0.1293, 0.1978], dtype=torch.float64), Delta+: [0.0304 0.    ], Delta-: [0. 0.], Delta: [ 0.0304 -0.    ], Omega: [[0.1597 0.1978]], bt: 0.2697, Consumption: 0.3727\n",
      "Best solution found. Point: tensor([0.1304, 0.1873], dtype=torch.float64), Delta+: [0.0289 0.    ], Delta-: [0. 0.], Delta: [ 0.0289 -0.    ], Omega: [[0.1593 0.1873]], bt: 0.2805, Consumption: 0.3727\n",
      "Best solution found. Point: tensor([0.1279, 0.1826], dtype=torch.float64), Delta+: [0.0311 0.    ], Delta-: [0. 0.], Delta: [ 0.0311 -0.    ], Omega: [[0.1591 0.1826]], bt: 0.2854, Consumption: 0.3728\n",
      "Best solution found. Point: tensor([0.2008, 0.1308], dtype=torch.float64), Delta+: [0.     0.0255], Delta-: [0. 0.], Delta: [-0.      0.0255], Omega: [[0.2008 0.1563]], bt: 0.27, Consumption: 0.3727\n",
      "Best solution found. Point: tensor([0.1561, 0.1321], dtype=torch.float64), Delta+: [0.0014 0.0238], Delta-: [0. 0.], Delta: [0.0014 0.0238], Omega: [[0.1575 0.1559]], bt: 0.3136, Consumption: 0.3729\n",
      "Best solution found. Point: tensor([0.1361, 0.2023], dtype=torch.float64), Delta+: [0.0238 0.    ], Delta-: [0. 0.], Delta: [ 0.0238 -0.    ], Omega: [[0.1599 0.2023]], bt: 0.265, Consumption: 0.3727\n",
      "Best solution found. Point: tensor([0.2115, 0.2515], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0036 0.0446], Delta: [-0.0036 -0.0446], Omega: [[0.2079 0.2069]], bt: 0.2126, Consumption: 0.3724\n",
      "Best solution found. Point: tensor([0.1630, 0.2312], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0245], Delta: [ 0.     -0.0245], Omega: [[0.163  0.2067]], bt: 0.2575, Consumption: 0.3726\n",
      "Best solution found. Point: tensor([0.2199, 0.2207], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.012  0.0138], Delta: [-0.012  -0.0138], Omega: [[0.2079 0.2069]], bt: 0.2127, Consumption: 0.3724\n",
      "Best solution found. Point: tensor([0.2227, 0.2182], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0148 0.0113], Delta: [-0.0148 -0.0113], Omega: [[0.2079 0.2069]], bt: 0.2127, Consumption: 0.3724\n",
      "Best solution found. Point: tensor([0.2002, 0.2523], dtype=torch.float64), Delta+: [-0.  0.], Delta-: [0.     0.0455], Delta: [-0.     -0.0455], Omega: [[0.2002 0.2068]], bt: 0.2204, Consumption: 0.3724\n",
      "Best solution found. Point: tensor([0.1904, 0.2332], dtype=torch.float64), Delta+: [-0.  0.], Delta-: [0.     0.0265], Delta: [-0.     -0.0265], Omega: [[0.1904 0.2067]], bt: 0.2302, Consumption: 0.3725\n",
      "Best solution found. Point: tensor([0.0000, 0.2917], dtype=torch.float64), Delta+: [0.1598 0.    ], Delta-: [0.     0.0853], Delta: [ 0.1598 -0.0853], Omega: [[0.1598 0.2064]], bt: 0.2604, Consumption: 0.3722\n",
      "Best solution found. Point: tensor([0.3333, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1256 0.0432], Delta: [-0.1256 -0.0432], Omega: [[0.2077 0.2068]], bt: 0.2125, Consumption: 0.3721\n",
      "Best solution found. Point: tensor([0.7083, 0.1250], dtype=torch.float64), Delta+: [0.     0.0312], Delta-: [0.5005 0.    ], Delta: [-0.5005  0.0312], Omega: [[0.2078 0.1562]], bt: 0.2616, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.5417, 0.0833], dtype=torch.float64), Delta+: [0.     0.0729], Delta-: [0.3337 0.    ], Delta: [-0.3337  0.0729], Omega: [[0.208  0.1563]], bt: 0.2618, Consumption: 0.3719\n",
      "Best solution found. Point: tensor([0.0833, 0.6667], dtype=torch.float64), Delta+: [0.0762 0.    ], Delta-: [0.     0.4606], Delta: [ 0.0762 -0.4606], Omega: [[0.1596 0.2061]], bt: 0.26, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.1912, 0.2520], dtype=torch.float64), Delta+: [-0.  0.], Delta-: [0.     0.0453], Delta: [-0.     -0.0453], Omega: [[0.1912 0.2067]], bt: 0.2294, Consumption: 0.3725\n",
      "Best solution found. Point: tensor([0.3750, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1675 0.2101], Delta: [-0.1675 -0.2101], Omega: [[0.2075 0.2065]], bt: 0.2123, Consumption: 0.3718\n",
      "Best solution found. Point: tensor([0.0833, 0.4167], dtype=torch.float64), Delta+: [0.0764 0.    ], Delta-: [0.     0.2103], Delta: [ 0.0764 -0.2103], Omega: [[0.1598 0.2063]], bt: 0.2603, Consumption: 0.3722\n",
      "Best solution found. Point: tensor([0.7500, 0.0417], dtype=torch.float64), Delta+: [0.     0.1144], Delta-: [0.5423 0.    ], Delta: [-0.5423  0.1144], Omega: [[0.2077 0.1561]], bt: 0.2615, Consumption: 0.3715\n",
      "Best solution found. Point: tensor([0.1250, 0.6667], dtype=torch.float64), Delta+: [0.0346 0.    ], Delta-: [0.     0.4605], Delta: [ 0.0346 -0.4605], Omega: [[0.1596 0.2061]], bt: 0.26, Consumption: 0.3718\n",
      "Best solution found. Point: tensor([0.5000, 0.0833], dtype=torch.float64), Delta+: [0.    0.073], Delta-: [0.292 0.   ], Delta: [-0.292  0.073], Omega: [[0.208  0.1563]], bt: 0.2619, Consumption: 0.372\n",
      "Best solution found. Point: tensor([0.6250, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4175 0.0018], Delta: [-0.4175 -0.0018], Omega: [[0.2075 0.2065]], bt: 0.2122, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.4167, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2092 0.2102], Delta: [-0.2092 -0.2102], Omega: [[0.2075 0.2065]], bt: 0.2122, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.0000, 0.5833], dtype=torch.float64), Delta+: [0.1596 0.    ], Delta-: [0.     0.3772], Delta: [ 0.1596 -0.3772], Omega: [[0.1596 0.2061]], bt: 0.26, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.5000, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.2915 -0.    ], Delta: [-0.2915  0.    ], Omega: [[0.2085 0.1667]], bt: 0.2513, Consumption: 0.3721\n",
      "Best solution found. Point: tensor([0.0000, 0.4167], dtype=torch.float64), Delta+: [0.1597 0.    ], Delta-: [0.     0.2104], Delta: [ 0.1597 -0.2104], Omega: [[0.1597 0.2063]], bt: 0.2602, Consumption: 0.372\n",
      "Best solution found. Point: tensor([0.7083, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.5009 0.0019], Delta: [-0.5009 -0.0019], Omega: [[0.2074 0.2064]], bt: 0.2121, Consumption: 0.3715\n",
      "Best solution found. Point: tensor([0.0000, 0.1250], dtype=torch.float64), Delta+: [0.1574 0.0308], Delta-: [0. 0.], Delta: [0.1574 0.0308], Omega: [[0.1574 0.1558]], bt: 0.3133, Consumption: 0.3726\n",
      "Best solution found. Point: tensor([0.4167, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2094 0.377 ], Delta: [-0.2094 -0.377 ], Omega: [[0.2073 0.2063]], bt: 0.2121, Consumption: 0.3714\n",
      "Best solution found. Point: tensor([0., 0.], dtype=torch.float64), Delta+: [0.1573 0.1557], Delta-: [0. 0.], Delta: [0.1573 0.1557], Omega: [[0.1573 0.1557]], bt: 0.3131, Consumption: 0.3723\n",
      "Best solution found. Point: tensor([0.8750, 0.0833], dtype=torch.float64), Delta+: [0.     0.0727], Delta-: [0.6674 0.    ], Delta: [-0.6674  0.0727], Omega: [[0.2076 0.156 ]], bt: 0.2614, Consumption: 0.3713\n",
      "Best solution found. Point: tensor([0.2500, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0423 0.21  ], Delta: [-0.0423 -0.21  ], Omega: [[0.2077 0.2067]], bt: 0.2124, Consumption: 0.372\n",
      "Best solution found. Point: tensor([0.7083, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.5001 -0.    ], Delta: [-0.5001  0.    ], Omega: [[0.2082 0.1667]], bt: 0.2509, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.1250, 0.1250], dtype=torch.float64), Delta+: [0.0325 0.0309], Delta-: [0. 0.], Delta: [0.0325 0.0309], Omega: [[0.1575 0.1559]], bt: 0.3135, Consumption: 0.3728\n",
      "Best solution found. Point: tensor([0.2500, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0424 0.2517], Delta: [-0.0424 -0.2517], Omega: [[0.2076 0.2066]], bt: 0.2124, Consumption: 0.3719\n",
      "Best solution found. Point: tensor([0.3333, 0.1667], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.1247 -0.    ], Delta: [-0.1247  0.    ], Omega: [[0.2086 0.1667]], bt: 0.2517, Consumption: 0.3724\n",
      "Best solution found. Point: tensor([0.5000, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2925 0.1268], Delta: [-0.2925 -0.1268], Omega: [[0.2075 0.2065]], bt: 0.2122, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.5417, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3341 0.0017], Delta: [-0.3341 -0.0017], Omega: [[0.2076 0.2066]], bt: 0.2123, Consumption: 0.3718\n",
      "Best solution found. Point: tensor([0.0833, 0.7917], dtype=torch.float64), Delta+: [0.0761 0.    ], Delta-: [0.     0.5857], Delta: [ 0.0761 -0.5857], Omega: [[0.1595 0.206 ]], bt: 0.2598, Consumption: 0.3715\n",
      "Best solution found. Point: tensor([0.1250, 0.4167], dtype=torch.float64), Delta+: [0.0348 0.    ], Delta-: [0.     0.2103], Delta: [ 0.0348 -0.2103], Omega: [[0.1598 0.2064]], bt: 0.2604, Consumption: 0.3722\n",
      "Best solution found. Point: tensor([0.1667, 0.8333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.6272], Delta: [ 0.     -0.6272], Omega: [[0.1667 0.2062]], bt: 0.2525, Consumption: 0.3715\n",
      "Best solution found. Point: tensor([0.3333, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1257 0.1684], Delta: [-0.1257 -0.1684], Omega: [[0.2076 0.2066]], bt: 0.2124, Consumption: 0.3719\n",
      "Best solution found. Point: tensor([0.3333, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1259 0.3769], Delta: [-0.1259 -0.3769], Omega: [[0.2074 0.2064]], bt: 0.2121, Consumption: 0.3715\n",
      "Best solution found. Point: tensor([0.1250, 0.3333], dtype=torch.float64), Delta+: [0.0349 0.    ], Delta-: [0.     0.1269], Delta: [ 0.0349 -0.1269], Omega: [[0.1599 0.2065]], bt: 0.2605, Consumption: 0.3724\n",
      "Best solution found. Point: tensor([0.6667, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4592 0.0019], Delta: [-0.4592 -0.0019], Omega: [[0.2074 0.2065]], bt: 0.2122, Consumption: 0.3716\n",
      "Best solution found. Point: tensor([0.0417, 0.3750], dtype=torch.float64), Delta+: [0.1181 0.    ], Delta-: [0.     0.1687], Delta: [ 0.1181 -0.1687], Omega: [[0.1598 0.2063]], bt: 0.2603, Consumption: 0.3722\n",
      "Best solution found. Point: tensor([0.1250, 0.7083], dtype=torch.float64), Delta+: [0.0346 0.    ], Delta-: [0.     0.5022], Delta: [ 0.0346 -0.5022], Omega: [[0.1596 0.2061]], bt: 0.26, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.1250, 0.8750], dtype=torch.float64), Delta+: [0.0344 0.    ], Delta-: [0.     0.6691], Delta: [ 0.0344 -0.6691], Omega: [[0.1594 0.2059]], bt: 0.2598, Consumption: 0.3714\n",
      "Best solution found. Point: tensor([0.7917, 0.0833], dtype=torch.float64), Delta+: [0.     0.0727], Delta-: [0.5839 0.    ], Delta: [-0.5839  0.0727], Omega: [[0.2077 0.1561]], bt: 0.2615, Consumption: 0.3715\n",
      "Best solution found. Point: tensor([0.2917, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0839 0.0432], Delta: [-0.0839 -0.0432], Omega: [[0.2078 0.2068]], bt: 0.2125, Consumption: 0.3722\n",
      "Best solution found. Point: tensor([0.3333, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1258 0.2101], Delta: [-0.1258 -0.2101], Omega: [[0.2076 0.2066]], bt: 0.2123, Consumption: 0.3718\n",
      "Best solution found. Point: tensor([0.5417, 0.1250], dtype=torch.float64), Delta+: [0.     0.0313], Delta-: [0.3336 0.    ], Delta: [-0.3336  0.0313], Omega: [[0.208  0.1563]], bt: 0.2619, Consumption: 0.372\n",
      "Best solution found. Point: tensor([0.7917, 0.0000], dtype=torch.float64), Delta+: [0.    0.156], Delta-: [0.584 0.   ], Delta: [-0.584  0.156], Omega: [[0.2076 0.156 ]], bt: 0.2614, Consumption: 0.3713\n",
      "Best solution found. Point: tensor([0.4583, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2509 0.2519], Delta: [-0.2509 -0.2519], Omega: [[0.2074 0.2064]], bt: 0.2121, Consumption: 0.3715\n",
      "Best solution found. Point: tensor([0.0000, 0.2083], dtype=torch.float64), Delta+: [0.1599 0.    ], Delta-: [0.     0.0019], Delta: [ 0.1599 -0.0019], Omega: [[0.1599 0.2065]], bt: 0.2605, Consumption: 0.3724\n",
      "Best solution found. Point: tensor([0.3333, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.126  0.4186], Delta: [-0.126  -0.4186], Omega: [[0.2074 0.2064]], bt: 0.2121, Consumption: 0.3714\n",
      "Best solution found. Point: tensor([0.6667, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4593 0.0853], Delta: [-0.4593 -0.0853], Omega: [[0.2074 0.2064]], bt: 0.2121, Consumption: 0.3714\n",
      "Best solution found. Point: tensor([0.3750, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1675 0.2518], Delta: [-0.1675 -0.2518], Omega: [[0.2075 0.2065]], bt: 0.2122, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.2917, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0844 0.502 ], Delta: [-0.0844 -0.502 ], Omega: [[0.2073 0.2063]], bt: 0.2121, Consumption: 0.3714\n",
      "Best solution found. Point: tensor([0.5833, 0.0000], dtype=torch.float64), Delta+: [0.     0.1562], Delta-: [0.3755 0.    ], Delta: [-0.3755  0.1562], Omega: [[0.2078 0.1562]], bt: 0.2616, Consumption: 0.3717\n",
      "Best solution found. Point: tensor([0.1667, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4186], Delta: [ 0.     -0.4186], Omega: [[0.1667 0.2064]], bt: 0.253, Consumption: 0.3719\n",
      "Best solution found. Point: tensor([0.6250, 0.3750], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4177 0.1687], Delta: [-0.4177 -0.1687], Omega: [[0.2073 0.2063]], bt: 0.2121, Consumption: 0.3714\n",
      "Failure Rate: 0.00%\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n",
      "Time step 0\n",
      "include consumption: True\n",
      "Step 2a: Approximate NTR\n",
      "[[0.1598 0.1573]\n",
      " [0.2122 0.1583]\n",
      " [0.161  0.2105]\n",
      " [0.2115 0.2106]]\n",
      "len tilde_omega_t: 4\n",
      "Step 2b: Sample state points\n",
      "Best solution found. Point: tensor([0.1867, 0.1728], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1867 0.1728]], bt: 0.2776, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1880, 0.1943], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.188  0.1943]], bt: 0.2548, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1892, 0.1881], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1892 0.1881]], bt: 0.2598, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1791, 0.1924], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1791 0.1924]], bt: 0.2656, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1994, 0.1759], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1994 0.1759]], bt: 0.2618, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1700, 0.1976], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.17   0.1976]], bt: 0.2695, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1713, 0.1860], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1713 0.186 ]], bt: 0.2797, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.2052, 0.2062], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2052 0.2062]], bt: 0.2258, Consumption: 0.3628\n",
      "Best solution found. Point: tensor([0.1788, 0.1716], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1788 0.1716]], bt: 0.2866, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.1889, 0.1691], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1889 0.1691]], bt: 0.279, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1975, 0.2016], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1975 0.2016]], bt: 0.2381, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1658, 0.1832], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1658 0.1832]], bt: 0.288, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.1776, 0.1800], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1776 0.18  ]], bt: 0.2794, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.1742, 0.2010], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1742 0.201 ]], bt: 0.2618, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1786, 0.1712], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1786 0.1712]], bt: 0.2873, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.1779, 0.1910], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1779 0.191 ]], bt: 0.2682, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.2082, 0.1787], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2082 0.1787]], bt: 0.2503, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.2016, 0.1879], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2016 0.1879]], bt: 0.2476, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1934, 0.1820], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1934 0.182 ]], bt: 0.2617, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1762, 0.1980], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1762 0.198 ]], bt: 0.2628, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1826, 0.1693], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1826 0.1693]], bt: 0.2851, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.2012, 0.1941], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.2012 0.1941]], bt: 0.2418, Consumption: 0.3629\n",
      "Best solution found. Point: tensor([0.1785, 0.1868], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1785 0.1868]], bt: 0.2718, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.1689, 0.1883], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1689 0.1883]], bt: 0.2798, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.1427, 0.1908], dtype=torch.float64), Delta+: [0.018 0.   ], Delta-: [0. 0.], Delta: [ 0.018 -0.   ], Omega: [[0.1607 0.1908]], bt: 0.2865, Consumption: 0.3619\n",
      "Best solution found. Point: tensor([0.1482, 0.1627], dtype=torch.float64), Delta+: [0.0122 0.    ], Delta-: [ 0. -0.], Delta: [0.0122 0.    ], Omega: [[0.1604 0.1627]], bt: 0.3148, Consumption: 0.362\n",
      "Best solution found. Point: tensor([0.1832, 0.1397], dtype=torch.float64), Delta+: [0.     0.0189], Delta-: [-0.  0.], Delta: [0.     0.0189], Omega: [[0.1832 0.1587]], bt: 0.2961, Consumption: 0.362\n",
      "Best solution found. Point: tensor([0.1823, 0.1737], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0. 0.], Delta: [0. 0.], Omega: [[0.1823 0.1737]], bt: 0.281, Consumption: 0.363\n",
      "Best solution found. Point: tensor([0.1506, 0.1576], dtype=torch.float64), Delta+: [0.0096 0.    ], Delta-: [0. 0.], Delta: [ 0.0096 -0.    ], Omega: [[0.1601 0.1576]], bt: 0.3201, Consumption: 0.3621\n",
      "Best solution found. Point: tensor([0.1455, 0.1476], dtype=torch.float64), Delta+: [0.0147 0.0101], Delta-: [0. 0.], Delta: [0.0147 0.0101], Omega: [[0.1601 0.1577]], bt: 0.32, Consumption: 0.362\n",
      "Best solution found. Point: tensor([0.2182, 0.1493], dtype=torch.float64), Delta+: [0.     0.0097], Delta-: [0.005 0.   ], Delta: [-0.005   0.0097], Omega: [[0.2132 0.1591]], bt: 0.2659, Consumption: 0.3618\n",
      "Best solution found. Point: tensor([0.1351, 0.1826], dtype=torch.float64), Delta+: [0.0252 0.    ], Delta-: [ 0. -0.], Delta: [0.0252 0.    ], Omega: [[0.1603 0.1826]], bt: 0.295, Consumption: 0.362\n",
      "Best solution found. Point: tensor([0.2033, 0.1429], dtype=torch.float64), Delta+: [0.     0.0163], Delta-: [0. 0.], Delta: [-0.      0.0163], Omega: [[0.2033 0.1592]], bt: 0.2756, Consumption: 0.3619\n",
      "Best solution found. Point: tensor([0.2452, 0.1278], dtype=torch.float64), Delta+: [0.     0.0313], Delta-: [0.0321 0.    ], Delta: [-0.0321  0.0313], Omega: [[0.2131 0.159 ]], bt: 0.2658, Consumption: 0.3617\n",
      "Best solution found. Point: tensor([0.2042, 0.1546], dtype=torch.float64), Delta+: [0.     0.0046], Delta-: [0. 0.], Delta: [-0.      0.0046], Omega: [[0.2042 0.1592]], bt: 0.2746, Consumption: 0.3619\n",
      "Best solution found. Point: tensor([0.2195, 0.1636], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0066 -0.    ], Delta: [-0.0066  0.    ], Omega: [[0.213  0.1636]], bt: 0.2616, Consumption: 0.3618\n",
      "Best solution found. Point: tensor([0.1522, 0.2170], dtype=torch.float64), Delta+: [0.0095 0.    ], Delta-: [0.     0.0056], Delta: [ 0.0095 -0.0056], Omega: [[0.1617 0.2114]], bt: 0.2649, Consumption: 0.3618\n",
      "Best solution found. Point: tensor([0.1405, 0.2455], dtype=torch.float64), Delta+: [0.0212 0.    ], Delta-: [0.     0.0341], Delta: [ 0.0212 -0.0341], Omega: [[0.1617 0.2114]], bt: 0.2649, Consumption: 0.3618\n",
      "Best solution found. Point: tensor([0.2430, 0.1859], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0.0303 -0.    ], Delta: [-0.0303  0.    ], Omega: [[0.2127 0.1859]], bt: 0.2395, Consumption: 0.3617\n",
      "Best solution found. Point: tensor([0.1742, 0.2263], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.0144], Delta: [ 0.     -0.0144], Omega: [[0.1742 0.2119]], bt: 0.252, Consumption: 0.3618\n",
      "Best solution found. Point: tensor([0.1433, 0.2087], dtype=torch.float64), Delta+: [0.0183 0.    ], Delta-: [0. 0.], Delta: [ 0.0183 -0.    ], Omega: [[0.1616 0.2087]], bt: 0.2677, Consumption: 0.3618\n",
      "Best solution found. Point: tensor([0.1935, 0.2120], dtype=torch.float64), Delta+: [-0.  0.], Delta-: [0.     0.0001], Delta: [-0.     -0.0001], Omega: [[0.1935 0.2119]], bt: 0.2329, Consumption: 0.3617\n",
      "Best solution found. Point: tensor([0.1494, 0.2343], dtype=torch.float64), Delta+: [0.0122 0.    ], Delta-: [0.     0.0229], Delta: [ 0.0122 -0.0229], Omega: [[0.1617 0.2114]], bt: 0.2649, Consumption: 0.3618\n",
      "Best solution found. Point: tensor([0.1962, 0.2173], dtype=torch.float64), Delta+: [-0.  0.], Delta-: [0.     0.0054], Delta: [-0.     -0.0054], Omega: [[0.1962 0.2118]], bt: 0.2302, Consumption: 0.3617\n",
      "Best solution found. Point: tensor([0.2437, 0.2216], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0316 0.0105], Delta: [-0.0316 -0.0105], Omega: [[0.2121 0.2111]], bt: 0.215, Consumption: 0.3615\n",
      "Best solution found. Point: tensor([0.2560, 0.2547], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.044  0.0436], Delta: [-0.044  -0.0436], Omega: [[0.212  0.2111]], bt: 0.215, Consumption: 0.3615\n",
      "Best solution found. Point: tensor([0.2103, 0.2108], dtype=torch.float64), Delta+: [0. 0.], Delta-: [ 0. -0.], Delta: [0. 0.], Omega: [[0.2103 0.2108]], bt: 0.216, Consumption: 0.3628\n",
      "Best solution found. Point: tensor([0.3333, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1214 0.0807], Delta: [-0.1214 -0.0807], Omega: [[0.2119 0.211 ]], bt: 0.2149, Consumption: 0.3613\n",
      "Best solution found. Point: tensor([0.2083, 0.2917], dtype=torch.float64), Delta+: [-0.  0.], Delta-: [0.     0.0804], Delta: [-0.     -0.0804], Omega: [[0.2083 0.2113]], bt: 0.2185, Consumption: 0.3615\n",
      "Best solution found. Point: tensor([0.2384, 0.2343], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0263 0.0232], Delta: [-0.0263 -0.0232], Omega: [[0.2121 0.2111]], bt: 0.215, Consumption: 0.3615\n",
      "Best solution found. Point: tensor([0.2501, 0.2187], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0381 0.0076], Delta: [-0.0381 -0.0076], Omega: [[0.2121 0.2111]], bt: 0.215, Consumption: 0.3615\n",
      "Best solution found. Point: tensor([0.1667, 0.5417], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.3304], Delta: [ 0.     -0.3304], Omega: [[0.1667 0.2113]], bt: 0.2591, Consumption: 0.3612\n",
      "Best solution found. Point: tensor([0.2917, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0801 0.4144], Delta: [-0.0801 -0.4144], Omega: [[0.2116 0.2106]], bt: 0.2146, Consumption: 0.3607\n",
      "Best solution found. Point: tensor([0.0833, 0.5000], dtype=torch.float64), Delta+: [0.0781 0.    ], Delta-: [0.     0.2889], Delta: [ 0.0781 -0.2889], Omega: [[0.1614 0.2111]], bt: 0.2645, Consumption: 0.3612\n",
      "Best solution found. Point: tensor([0.3333, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1215 0.1224], Delta: [-0.1215 -0.1224], Omega: [[0.2119 0.2109]], bt: 0.2148, Consumption: 0.3612\n",
      "Best solution found. Point: tensor([0.3750, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1633 0.2476], Delta: [-0.1633 -0.2476], Omega: [[0.2117 0.2107]], bt: 0.2146, Consumption: 0.3609\n",
      "Best solution found. Point: tensor([0.4167, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2048 0.0808], Delta: [-0.2048 -0.0808], Omega: [[0.2118 0.2109]], bt: 0.2148, Consumption: 0.3611\n",
      "Best solution found. Point: tensor([0.1250, 0.5833], dtype=torch.float64), Delta+: [0.0364 0.    ], Delta-: [0.     0.3723], Delta: [ 0.0364 -0.3723], Omega: [[0.1614 0.211 ]], bt: 0.2644, Consumption: 0.3611\n",
      "Best solution found. Point: tensor([0.4167, 0.5000], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2051 0.2894], Delta: [-0.2051 -0.2894], Omega: [[0.2116 0.2106]], bt: 0.2146, Consumption: 0.3607\n",
      "Best solution found. Point: tensor([0.5833, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3715 0.    ], Delta: [-0.3715 -0.    ], Omega: [[0.2118 0.2083]], bt: 0.217, Consumption: 0.361\n",
      "Best solution found. Point: tensor([0.2500, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0381 0.2058], Delta: [-0.0381 -0.2058], Omega: [[0.2119 0.2109]], bt: 0.2148, Consumption: 0.3612\n",
      "Best solution found. Point: tensor([0.8333, 0.0417], dtype=torch.float64), Delta+: [0.     0.1168], Delta-: [0.621 0.   ], Delta: [-0.621   0.1168], Omega: [[0.2124 0.1585]], bt: 0.2649, Consumption: 0.3605\n",
      "Best solution found. Point: tensor([0.1250, 0.3750], dtype=torch.float64), Delta+: [0.0366 0.    ], Delta-: [0.     0.1638], Delta: [ 0.0366 -0.1638], Omega: [[0.1616 0.2112]], bt: 0.2647, Consumption: 0.3615\n",
      "Best solution found. Point: tensor([0.9167, 0.0833], dtype=torch.float64), Delta+: [0.     0.0751], Delta-: [0.7043 0.    ], Delta: [-0.7043  0.0751], Omega: [[0.2123 0.1585]], bt: 0.2649, Consumption: 0.3604\n",
      "Best solution found. Point: tensor([0.5417, 0.1250], dtype=torch.float64), Delta+: [0.     0.0338], Delta-: [0.3289 0.    ], Delta: [-0.3289  0.0338], Omega: [[0.2128 0.1588]], bt: 0.2654, Consumption: 0.3612\n",
      "Best solution found. Point: tensor([0.5833, 0.0000], dtype=torch.float64), Delta+: [0.     0.1587], Delta-: [0.3707 0.    ], Delta: [-0.3707  0.1587], Omega: [[0.2126 0.1587]], bt: 0.2652, Consumption: 0.3609\n",
      "Best solution found. Point: tensor([0.6250, 0.0833], dtype=torch.float64), Delta+: [0.     0.0754], Delta-: [0.4124 0.    ], Delta: [-0.4124  0.0754], Omega: [[0.2126 0.1587]], bt: 0.2653, Consumption: 0.361\n",
      "Best solution found. Point: tensor([0.8750, 0.0417], dtype=torch.float64), Delta+: [0.     0.1168], Delta-: [0.6627 0.    ], Delta: [-0.6627  0.1168], Omega: [[0.2123 0.1585]], bt: 0.2649, Consumption: 0.3604\n",
      "Best solution found. Point: tensor([0.2500, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0382 0.2475], Delta: [-0.0382 -0.2475], Omega: [[0.2118 0.2109]], bt: 0.2148, Consumption: 0.3611\n",
      "Best solution found. Point: tensor([0.4583, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2465 0.0391], Delta: [-0.2465 -0.0391], Omega: [[0.2118 0.2109]], bt: 0.2148, Consumption: 0.3611\n",
      "Best solution found. Point: tensor([0.0000, 0.8750], dtype=torch.float64), Delta+: [0.1611 0.    ], Delta-: [0.     0.6644], Delta: [ 0.1611 -0.6644], Omega: [[0.1611 0.2106]], bt: 0.2639, Consumption: 0.3604\n",
      "Best solution found. Point: tensor([0.1667, 0.7083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.4972], Delta: [ 0.     -0.4972], Omega: [[0.1667 0.2111]], bt: 0.2588, Consumption: 0.3609\n",
      "Best solution found. Point: tensor([0.3333, 0.4167], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1216 0.2058], Delta: [-0.1216 -0.2058], Omega: [[0.2118 0.2108]], bt: 0.2147, Consumption: 0.361\n",
      "Best solution found. Point: tensor([0.0417, 0.7500], dtype=torch.float64), Delta+: [0.1195 0.    ], Delta-: [0.     0.5392], Delta: [ 0.1195 -0.5392], Omega: [[0.1612 0.2108]], bt: 0.2641, Consumption: 0.3607\n",
      "Best solution found. Point: tensor([0.1667, 0.7500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.     0.5389], Delta: [ 0.     -0.5389], Omega: [[0.1667 0.2111]], bt: 0.2587, Consumption: 0.3609\n",
      "Best solution found. Point: tensor([0.5833, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3716 0.0393], Delta: [-0.3716 -0.0393], Omega: [[0.2117 0.2107]], bt: 0.2146, Consumption: 0.3609\n",
      "Best solution found. Point: tensor([0.1250, 0.1250], dtype=torch.float64), Delta+: [0.0351 0.0326], Delta-: [0. 0.], Delta: [0.0351 0.0326], Omega: [[0.1601 0.1576]], bt: 0.32, Consumption: 0.362\n",
      "Best solution found. Point: tensor([0.2917, 0.1250], dtype=torch.float64), Delta+: [0.    0.034], Delta-: [0.0786 0.    ], Delta: [-0.0786  0.034 ], Omega: [[0.213 0.159]], bt: 0.2658, Consumption: 0.3616\n",
      "Best solution found. Point: tensor([0.1250, 0.0833], dtype=torch.float64), Delta+: [0.0351 0.0743], Delta-: [0. 0.], Delta: [0.0351 0.0743], Omega: [[0.1601 0.1576]], bt: 0.3199, Consumption: 0.3619\n",
      "Best solution found. Point: tensor([0.2917, 0.5833], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.08   0.3726], Delta: [-0.08   -0.3726], Omega: [[0.2116 0.2107]], bt: 0.2146, Consumption: 0.3608\n",
      "Best solution found. Point: tensor([0.2917, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0799 0.2475], Delta: [-0.0799 -0.2475], Omega: [[0.2118 0.2108]], bt: 0.2147, Consumption: 0.361\n",
      "Best solution found. Point: tensor([0.2083, 0.0000], dtype=torch.float64), Delta+: [0.     0.1591], Delta-: [0. 0.], Delta: [-0.      0.1591], Omega: [[0.2083 0.1591]], bt: 0.2702, Consumption: 0.3616\n",
      "Best solution found. Point: tensor([0.0417, 0.8333], dtype=torch.float64), Delta+: [0.1195 0.    ], Delta-: [0.     0.6227], Delta: [ 0.1195 -0.6227], Omega: [[0.1611 0.2107]], bt: 0.264, Consumption: 0.3605\n",
      "Best solution found. Point: tensor([0.0417, 0.7083], dtype=torch.float64), Delta+: [0.1196 0.    ], Delta-: [0.     0.4975], Delta: [ 0.1196 -0.4975], Omega: [[0.1612 0.2108]], bt: 0.2642, Consumption: 0.3607\n",
      "Best solution found. Point: tensor([0.4583, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2466 0.1226], Delta: [-0.2466 -0.1226], Omega: [[0.2117 0.2108]], bt: 0.2147, Consumption: 0.361\n",
      "Best solution found. Point: tensor([0.3333, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1212 0.    ], Delta: [-0.1212 -0.    ], Omega: [[0.2121 0.2083]], bt: 0.2175, Consumption: 0.3614\n",
      "Best solution found. Point: tensor([0.2500, 0.6250], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.0384 0.4143], Delta: [-0.0384 -0.4143], Omega: [[0.2116 0.2107]], bt: 0.2146, Consumption: 0.3608\n",
      "Best solution found. Point: tensor([0.4583, 0.4583], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2467 0.2477], Delta: [-0.2467 -0.2477], Omega: [[0.2116 0.2106]], bt: 0.2146, Consumption: 0.3607Best solution found. Point: tensor([0.6667, 0.0833], dtype=torch.float64), Delta+: [0.     0.0753], Delta-: [0.4541 0.    ], Delta: [-0.4541  0.0753], Omega: [[0.2126 0.1587]], bt: 0.2652, Consumption: 0.3609\n",
      "\n",
      "Best solution found. Point: tensor([0.6250, 0.2917], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.4134 0.081 ], Delta: [-0.4134 -0.081 ], Omega: [[0.2116 0.2106]], bt: 0.2146, Consumption: 0.3607\n",
      "Best solution found. Point: tensor([0.5833, 0.3333], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.3717 0.1227], Delta: [-0.3717 -0.1227], Omega: [[0.2116 0.2106]], bt: 0.2146, Consumption: 0.3607\n",
      "Best solution found. Point: tensor([0.7083, 0.1250], dtype=torch.float64), Delta+: [0.     0.0337], Delta-: [0.4957 0.    ], Delta: [-0.4957  0.0337], Omega: [[0.2126 0.1587]], bt: 0.2652, Consumption: 0.3609\n",
      "Best solution found. Point: tensor([0.3750, 0.2500], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.1631 0.039 ], Delta: [-0.1631 -0.039 ], Omega: [[0.2119 0.211 ]], bt: 0.2149, Consumption: 0.3613\n",
      "Best solution found. Point: tensor([0.0000, 0.7500], dtype=torch.float64), Delta+: [0.1612 0.    ], Delta-: [0.     0.5393], Delta: [ 0.1612 -0.5393], Omega: [[0.1612 0.2107]], bt: 0.264, Consumption: 0.3606\n",
      "Best solution found. Point: tensor([0.6250, 0.0417], dtype=torch.float64), Delta+: [0.    0.117], Delta-: [0.4124 0.    ], Delta: [-0.4124  0.117 ], Omega: [[0.2126 0.1587]], bt: 0.2652, Consumption: 0.3609\n",
      "Best solution found. Point: tensor([0.0000, 0.6667], dtype=torch.float64), Delta+: [0.1612 0.    ], Delta-: [0.     0.4559], Delta: [ 0.1612 -0.4559], Omega: [[0.1612 0.2108]], bt: 0.2642, Consumption: 0.3607\n",
      "Best solution found. Point: tensor([0.4167, 0.2083], dtype=torch.float64), Delta+: [0. 0.], Delta-: [0.2046 0.    ], Delta: [-0.2046 -0.    ], Omega: [[0.212  0.2083]], bt: 0.2174, Consumption: 0.3613\n",
      "Best solution found. Point: tensor([0.0000, 0.7917], dtype=torch.float64), Delta+: [0.1611 0.    ], Delta-: [0.    0.581], Delta: [ 0.1611 -0.581 ], Omega: [[0.1611 0.2107]], bt: 0.264, Consumption: 0.3605\n",
      "Best solution found. Point: tensor([0.0000, 0.1667], dtype=torch.float64), Delta+: [0.1603 0.    ], Delta-: [ 0. -0.], Delta: [0.1603 0.    ], Omega: [[0.1603 0.1667]], bt: 0.3104, Consumption: 0.3618\n",
      "Best solution found. Point: tensor([0.0833, 0.2917], dtype=torch.float64), Delta+: [0.0783 0.    ], Delta-: [0.     0.0804], Delta: [ 0.0783 -0.0804], Omega: [[0.1616 0.2113]], bt: 0.2648, Consumption: 0.3616\n",
      "Failure Rate: 0.00%\n",
      "Step 2e: Train GPR models for inside and outside NTR\n",
      "train gp model_in done \n",
      "train gp model_out done\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n",
    "\n",
    "# Set print options\n",
    "torch.set_printoptions(sci_mode=False, precision=4)\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Limit PyTorch and NumPy to use a single thread per worker\n",
    "torch.set_num_threads(2)\n",
    "os.environ['OMP_NUM_THREADS'] = '2'\n",
    "os.environ['MKL_NUM_THREADS'] = '2'\n",
    "\n",
    "def TasmanianSGLogQuadNorm(n, mu=None, cov=None):\n",
    "    \"\"\"\n",
    "    Computes nodes and weights for a multivariate normal distribution\n",
    "    using Tasmanian's Gauss-Hermite quadrature. (Same as Schober 2022 uses)\n",
    "\n",
    "    Args:\n",
    "        n (list or array-like): 1 by d array of number of refinements (nodes) per dimension.\n",
    "        mu (array-like): 1 by d mean vector. Defaults to zeros.\n",
    "        cov (array-like): d by d covariance matrix. Defaults to identity.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - x (np.ndarray): Matrix of evaluation nodes (num_nodes x d). Exponential transformed.\n",
    "            - w (np.ndarray): Array of quadrature weights (num_nodes,).\n",
    "    \"\"\"\n",
    "    n = np.asarray(n)\n",
    "    dim = n.size\n",
    "\n",
    "    # Default covariance matrix\n",
    "    if cov is None:\n",
    "        cov = np.eye(dim)\n",
    "    else:\n",
    "        cov = np.asarray(cov)\n",
    "        if cov.shape != (dim, dim):\n",
    "            raise ValueError(\"Covariance matrix must be of shape (d, d).\")\n",
    "\n",
    "    # Default mean vector\n",
    "    if mu is None:\n",
    "        mu = np.zeros(dim)\n",
    "    else:\n",
    "        mu = np.asarray(mu)\n",
    "        if mu.size != dim:\n",
    "            raise ValueError(\"Mean vector must be of length d.\")\n",
    "\n",
    "    # Calculate anisotropic refinements\n",
    "    if dim == 1:\n",
    "        refine = []\n",
    "    else:\n",
    "        refine = (1.0 / np.array(n) * np.prod(n)).tolist()\n",
    "\n",
    "    # Determine the maximum level\n",
    "    level = int(np.max(n))\n",
    "\n",
    "    # Create Tasmanian grid using positional arguments\n",
    "    grid = makeGlobalGrid(\n",
    "        int(dim),              # iDimension\n",
    "        1,                     # iOutputs\n",
    "        level,                 # iDepth\n",
    "        'level',               # sType\n",
    "        'gauss-hermite',       # sRule\n",
    "        refine,                # liAnisotropicWeights \n",
    "        0.0,                   # fAlpha #No alpha for Gauss-Hermite\n",
    "        0.0,                   # fBeta #No beta for Gauss-Hermite\n",
    "        \"\",                    # sCustomFilename\n",
    "        []                     # liLevelLimits\n",
    "    )\n",
    "\n",
    "    # Retrieve nodes and weights\n",
    "    nodes = grid.getPoints()    # Shape: (dim, num_nodes)\n",
    "    weights = grid.getQuadratureWeights() # Shape: (num_nodes,)\n",
    "    \n",
    "    # Transpose nodes to shape (num_nodes, dim)\n",
    "    # nodes = nodes.              # Now nodes.shape = (num_nodes, dim)\n",
    "    # nodes *= np.sqrt(2) # Correct scaling by sqrt(2)\n",
    "\n",
    "    L = cholesky(cov, lower=True).T  # Shape: (dim, dim)\n",
    "    transformed_nodes = mu*Delta_t + np.sqrt(2) * np.sqrt(Delta_t) * (nodes @ L)  # Shape: (num_nodes, dim)\n",
    "    transformed_nodes = np.exp(transformed_nodes-0.5*np.diag(cov)*Delta_t)  # Transform to positive domain\n",
    "    scaled_weights = (np.pi ** (-dim / 2)) * weights  # Shape: (num_nodes,)\n",
    "\n",
    "    return transformed_nodes, scaled_weights,L\n",
    "\n",
    "# def gauss_hermite_quadrature(n,mu,Sigma,Delta_t):\n",
    "#     D = len(mu)\n",
    "#     #scipy.special.roots_hermite\n",
    "#     x_1d, w_1d = roots_hermite(n)\n",
    "#     x_1d, w_1d = roots_hermitenorm(n)\n",
    "\n",
    "#     nodes = np.array(list(product(x_1d, repeat=D)))  # Shape: [n^D, D]\n",
    "#     weights = np.prod(np.array(list(product(w_1d, repeat=D))), axis=1)  # Shape: [n^D]\n",
    "    \n",
    "#     L = scipy.linalg.cholesky(Sigma, lower=True)    \n",
    "#     nodes = mu * Delta_t + np.sqrt(2) * (nodes @ L)  # Correct scaling by sqrt(2)\n",
    "#     weights = np.pi**(-D/2)*weights\n",
    "#     return nodes, weights, L\n",
    "\n",
    "# def gauss_hermite_log_normal_quadrature(n, mu, Sigma, Delta_t):\n",
    "#     nodes, weights, L = gauss_hermite_quadrature(n, mu, Sigma, Delta_t)\n",
    "#     # nodes = np.exp(nodes)  # Apply exp column-wise\n",
    "#     # Apply exponential column-wise on nodes\n",
    "#     for i in range(nodes.shape[1]):\n",
    "#         nodes[:, i] = np.exp(nodes[:, i])\n",
    "#     return nodes, weights, L\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            # gpytorch.kernels.MaternKernel(nu=0.5, ard_num_dims=train_x.shape[1])\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=train_x.shape[1])\n",
    "            # ,lengthscale_constraint=gpytorch.constraints.Positive()\n",
    "            # gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=train_x.shape[1])\n",
    "            \n",
    "            # KeopsMaternKernel(nu=0.5, ard_num_dims=train_x.shape[1])\n",
    "            # ,jitter=1e-8  # Adding jitter for numerical stability\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def train_gp_model(train_x, train_y, patience=125, min_delta=1e-8, max_iterations=800):\n",
    "    \"\"\"\n",
    "    Trains a Gaussian Process Regression model with early stopping.\n",
    "\n",
    "    Args:\n",
    "        train_x (torch.Tensor): Training inputs. Shape: [num_samples, D]\n",
    "        train_y (torch.Tensor): Training targets. Shape: [num_samples]\n",
    "        patience (int): Number of iterations to wait for improvement before stopping.\n",
    "        min_delta (float): Minimum change in the loss to qualify as an improvement.\n",
    "        max_iterations (int): Maximum number of iterations to run.\n",
    "\n",
    "    Returns:\n",
    "        model (GPRegressionModel): Trained GP model.\n",
    "        likelihood (gpytorch.likelihoods.GaussianLikelihood): Associated likelihood.\n",
    "    \"\"\"\n",
    "    if train_y.dim() > 1:\n",
    "        train_y = train_y.squeeze(-1)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "        # This is an assumption of noise in training data. See Murphy(2023) 18.3.1\n",
    "        # noise_constraint=gpytorch.constraints.Interval(1e-12, 1e-8)\n",
    "        noise_constraint=gpytorch.constraints.Interval(1e-12, 1e-9)\n",
    "    )\n",
    "    model = GPRegressionModel(train_x, train_y, likelihood)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        # with gpytorch.settings.cholesky_jitter(1e-5):\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "\n",
    "        # Check for improvement\n",
    "        if current_loss < best_loss - min_delta:\n",
    "            best_loss = current_loss\n",
    "            no_improvement_count = 0  # Reset the counter if we see improvement\n",
    "        else:\n",
    "            no_improvement_count += 1  # Increment if no improvement\n",
    "\n",
    "        # Early stopping condition\n",
    "        if no_improvement_count >= patience:\n",
    "            print(f\"Early stopping at iteration {i+1}\")\n",
    "            break\n",
    "    \n",
    "    # After training\n",
    "    del optimizer, mll\n",
    "    del train_x, train_y\n",
    "    # torch.cuda.empty_cache()  # If using CUDA    \n",
    "      # Garbage collection\n",
    "    return model, likelihood\n",
    "\n",
    "def utility(var, gamma):\n",
    "    # var = torch.clamp(var, min=1e-4)\n",
    "    if gamma == 1:\n",
    "        return torch.log(var)  # Log utility for gamma = 1\n",
    "    else:\n",
    "        return (var ** (1.0 - gamma)) / (1.0 - gamma)  # CRRA utility      #Which is correct?\n",
    "\n",
    "def V_terminal(xT, tau, gamma, Rf, Delta_t):\n",
    "    r = np.log(Rf)\n",
    "    # Ensure xT requires grad\n",
    "    holdings = 1.0 - tau * torch.sum(xT, dim=-1)\n",
    "    terminal_utility = ((holdings ** (1.0 - gamma)) * Delta_t) / (1.0 - gamma)\n",
    "    # return terminal_utility #(if using vt as value function)\n",
    "    return holdings # (if using jt as value function)\n",
    "\n",
    "def normalized_bond_holdings(xt, delta_plus, delta_minus, tau, Delta_t, ct=None, include_consumption=False):\n",
    "    # This function is more similar to Schober 2022\n",
    "    if not include_consumption:\n",
    "        ct = torch.tensor([0.0], dtype=torch.float64)\n",
    "    # if ct is None:\n",
    "    #     ct = torch.tensor([0.0], dtype=torch.float64)\n",
    "\n",
    "    # Ensure ct is a scalar tensor\n",
    "    if ct.dim() == 0:\n",
    "        ct = ct  # Already scalar\n",
    "    else:\n",
    "        ct = ct.squeeze()  # Convert [1] to scalar tensor []\n",
    "\n",
    "    # # if torch sum xt > 1 then normalize it\n",
    "    # if torch.sum(xt) > 1:\n",
    "    #     xt = xt / torch.sum(xt)\n",
    "        \n",
    "    # Available cash before transactions\n",
    "    available_cash = 1.0 - torch.sum(xt)\n",
    "\n",
    "    # Buying and selling costs\n",
    "    buying_cost = (1.0 + tau) * torch.sum(delta_plus)\n",
    "    selling_proceeds = (1.0 - tau) * torch.sum(delta_minus)\n",
    "\n",
    "    # Calculate bond holdings (bt)\n",
    "    bt = available_cash - buying_cost + selling_proceeds - torch.sum(ct) * Delta_t \n",
    "    bt = torch.abs(bt)  # Ensure bond holdings are non-negative\n",
    "    return bt\n",
    "\n",
    "def normalized_state_dynamics(xt, delta_plus, delta_minus, Rt, bt, Rf, tau):\n",
    "    \"\"\"\n",
    "    Handles both single and batched Rt inputs.\n",
    "\n",
    "    Args:\n",
    "        xt (torch.Tensor): Current state allocations. Shape: [1, D]\n",
    "        delta_plus (torch.Tensor): Adjustments (increases). Shape: [1, D]\n",
    "        delta_minus (torch.Tensor): Adjustments (decreases). Shape: [1, D]\n",
    "        Rt (torch.Tensor): Returns. Shape: [D] or [n_samples, D]\n",
    "        bt (torch.Tensor or float): Bond holdings.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        tau (float): Transaction cost rate.\n",
    "\n",
    "    Returns:\n",
    "        pi_t1 (torch.Tensor): Next period's portfolio value. Shape: [1] or [n_samples]\n",
    "        xt1 (torch.Tensor): Next period's state allocation proportions. Shape: [D] or [n_samples, D]\n",
    "        Wt1 (torch.Tensor): Wealth factor (scalar or [n_samples])\n",
    "    \"\"\"\n",
    "    # Convert inputs to tensors if necessary\n",
    "    if not torch.is_tensor(bt):\n",
    "        bt = torch.tensor(bt, dtype=torch.float64)\n",
    "    if not torch.is_tensor(Rf):\n",
    "        Rf = torch.tensor(Rf, dtype=torch.float64)\n",
    "\n",
    "    # Squeeze the first dimension if necessary\n",
    "    xt = xt.squeeze(0)          # Shape: [D]\n",
    "    delta_plus = delta_plus.squeeze(0)    # Shape: [D]\n",
    "    delta_minus = delta_minus.squeeze(0)  # Shape: [D]\n",
    "\n",
    "    # Calculate asset adjustments\n",
    "    asset_adjustment = xt + delta_plus - delta_minus  # Shape: [D]\n",
    "\n",
    "    # Check if Rt is batched\n",
    "    if Rt.dim() == 1:\n",
    "        # Single Rt\n",
    "        portfolio_returns = asset_adjustment * Rt  # Shape: [D]\n",
    "        pi_t1 = bt * Rf + torch.sum(portfolio_returns)  # Scalar (float)\n",
    "        pi_t1 = torch.tensor(pi_t1, dtype=torch.float64)  # Ensure tensor\n",
    "        xt1 = portfolio_returns / pi_t1  # Shape: [D]\n",
    "        Wt1 = pi_t1  # Scalar\n",
    "    else:\n",
    "        # Batched Rt\n",
    "        # Rt: [n_samples, D]\n",
    "        portfolio_returns = asset_adjustment.unsqueeze(0) * Rt  # Shape: [n_samples, D]\n",
    "        pi_t1 = bt * Rf + torch.sum(portfolio_returns, dim=1)   # Shape: [n_samples]\n",
    "        xt1 = portfolio_returns / pi_t1.unsqueeze(1)  # Shape: [n_samples, D]\n",
    "        Wt1 = pi_t1  # Shape: [n_samples]\n",
    "\n",
    "    return pi_t1, xt1\n",
    "\n",
    "# my Bellman. Which includes the certainty equivalent transformation\n",
    "def bellman_equation(\n",
    "    vt_next_in,\n",
    "    vt_next_out,\n",
    "    xt,\n",
    "    delta_plus,\n",
    "    delta_minus,\n",
    "    beta,\n",
    "    gamma,\n",
    "    Delta_t,\n",
    "    tau,\n",
    "    Rf,\n",
    "    ct=None,\n",
    "    include_consumption=False,\n",
    "    convex_hull=None,\n",
    "    t=None,\n",
    "    mu=None,\n",
    "    Sigma=None,\n",
    "    quadrature_nodes_weights=None,\n",
    "    integration_method='quadrature',\n",
    "    num_mc_samples=1000  # Number of Monte Carlo samples if using MC integration\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the value function vt using the Bellman equation with specified integration method.\n",
    "\n",
    "    Args:\n",
    "        vt_next_in (gpytorch.models.ExactGP or callable): Value function for inside NTR.\n",
    "        vt_next_out (gpytorch.models.ExactGP or callable): Value function for outside NTR.\n",
    "        xt (torch.Tensor): Current state. Shape: [1, D]\n",
    "        delta_plus (torch.Tensor): Adjustments (increases). Shape: [1, D]\n",
    "        delta_minus (torch.Tensor): Adjustments (decreases). Shape: [1, D]\n",
    "        beta (float): Discount factor.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "        Delta_t (float): Time step size.\n",
    "        tau (float): Transaction cost rate.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        ct (torch.Tensor or None): Consumption at time t.\n",
    "        include_consumption (bool): Flag to include consumption.\n",
    "        convex_hull (ConvexHull or None): Convex hull defining the NTR.\n",
    "        t (int): Current time step.\n",
    "        mu (np.array): Mean vector for asset returns.\n",
    "        Sigma (np.array): Covariance matrix for asset returns.\n",
    "        quadrature_nodes_weights (tuple or None): Quadrature nodes and weights.\n",
    "        integration_method (str): 'quadrature' or 'monte_carlo'\n",
    "        num_mc_samples (int): Number of Monte Carlo samples (used if integration_method='monte_carlo')\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Value function. Shape: [1]\n",
    "    \"\"\"\n",
    "    D = len(mu)\n",
    "    assert xt.dim() == 2 and xt.size(0) == 1, f\"xt must be [1, D], got {xt.shape}\"\n",
    "    assert delta_plus.dim() == 2 and delta_plus.size(0) == 1, f\"delta_plus must be [1, D], got {delta_plus.shape}\"\n",
    "    assert delta_minus.dim() == 2 and delta_minus.size(0) == 1, f\"delta_minus must be [1, D], got {delta_minus.shape}\"\n",
    "    if not include_consumption:\n",
    "        ct = torch.tensor([0.0], dtype=torch.float64)  # Shape: [1]\n",
    "\n",
    "    # if include consumption make sure it is a tensor and make sure it is 0 dimensional\n",
    "    if include_consumption:\n",
    "        if not torch.is_tensor(ct):\n",
    "            ct = torch.tensor(ct, dtype=torch.float64)\n",
    "        if ct.dim() == 1:\n",
    "            ct = ct.squeeze(0)\n",
    "\n",
    "    # Compute bond holdings\n",
    "    bt = normalized_bond_holdings(xt, delta_plus, delta_minus, tau, Delta_t, ct, include_consumption)\n",
    "        # # # if bt is negative but less than 1e-3, set it to 0\n",
    "    if bt < 0 and bt > -1e-3:\n",
    "        bt = torch.tensor([0.0], dtype = torch.float64)\n",
    "        # if bt <0 raise error and display xt delta_plus delta_minus\n",
    "\n",
    "    # if bt < 0:\n",
    "    #     return torch.tensor([-100000], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    if bt < -1e-3:\n",
    "        raise ValueError(f\"bond holdings are negative. bt: {bt}\")\n",
    "\n",
    "    if integration_method == 'quadrature':\n",
    "        # Quadrature integration\n",
    "        # Check if quadrature nodes and weights are provided; if not, compute them\n",
    "        if quadrature_nodes_weights is None:\n",
    "            raise ValueError(\"No quadrature nodes and weights provided.\")\n",
    "        # else:\n",
    "        transformed_nodes, weights, L = quadrature_nodes_weights\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        log_nodes = torch.tensor(transformed_nodes, dtype=torch.float64)  # Shape: [n_q^D, D]\n",
    "        weights = torch.tensor(weights, dtype=torch.float64)          # Shape: [n_q^D]\n",
    "\n",
    "        pi_t1, xt1 = normalized_state_dynamics(xt, delta_plus, delta_minus, log_nodes, bt, Rf, tau)\n",
    "\n",
    "    elif integration_method == 'monte_carlo':\n",
    "        random_seed = 20011210\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        # Monte Carlo integration\n",
    "        adjusted_mu = mu* Delta_t  - 0.5 * np.diag(Sigma) * Delta_t #See Cai Judd Xu 2013\n",
    "        distribution = cp.MvNormal(adjusted_mu, Sigma * Delta_t)\n",
    "        samples = distribution.sample(num_mc_samples, rule='random')\n",
    "        log_Rt_samples = torch.tensor(samples.T, dtype=torch.float64)  # Shape: [num_mc_samples, D]\n",
    "        Rt = torch.exp(log_Rt_samples)\n",
    "        pi_t1, xt1, Wt1 = normalized_state_dynamics(xt, delta_plus, delta_minus, Rt, bt, Rf, tau)\n",
    "        pi_t1, xt1, Wt1 = [], [], []\n",
    "        for node in Rt:\n",
    "            pi, x, W = normalized_state_dynamics(xt, delta_plus, delta_minus, node, bt, Rf, tau)\n",
    "            pi_t1.append(pi)\n",
    "            xt1.append(x)\n",
    "            Wt1.append(W)\n",
    "        pi_t1 = torch.stack(pi_t1)  # Shape: [n_q^D]\n",
    "        xt1 = torch.stack(xt1)      # Shape: [n_q^D, D]\n",
    "        Wt1 = torch.stack(Wt1)      # Shape: [n_q^D]\n",
    "\n",
    "    elif integration_method == 'quasi_monte_carlo':\n",
    "        random_seed = 20011210\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        # Quasi-Monte Carlo integration using Sobol sequences\n",
    "        adjusted_mu = mu * Delta_t - 0.5 * np.diag(Sigma) * Delta_t #See Cai Judd Xu 2013\n",
    "        distribution = cp.MvNormal(adjusted_mu, Sigma * Delta_t)\n",
    "        samples = distribution.sample(num_mc_samples, rule='sobol')  # 'sobol' or 'halton'\n",
    "        log_Rt_samples = torch.tensor(samples.T, dtype=torch.float64)  # Shape: [num_mc_samples, D]\n",
    "        Rt = torch.exp(log_Rt_samples)\n",
    "\n",
    "        pi_t1, xt1, Wt1 = normalized_state_dynamics(xt, delta_plus, delta_minus, Rt, bt, Rf, tau)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid integration method. Choose 'quadrature', 'monte_carlo', or 'quasi_monte_carlo'.\")\n",
    "\n",
    "    # Raise error if NaN or Inf values are encountered\n",
    "    # if torch.isnan(pi_t1).any() or torch.isnan(xt1).any():\n",
    "    if torch.isnan(pi_t1).any() or torch.isnan(xt1).any():\n",
    "        raise ValueError(\"NaN values encountered in pi_t1, xt1.\")\n",
    "\n",
    "    # if any xt is very slightly negative, set it to 0\n",
    "    if ((xt1 < 0) & (xt1 > -1e-4)).any():\n",
    "        xt1[(xt1 < -0.0) & (xt1 > -1e-5)] = 0.0\n",
    "\n",
    "    # Correctly expand delta_plus and delta_minus to match xt1's shape\n",
    "    delta_plus_expanded = delta_plus.repeat(xt1.size(0), 1)    # Shape: [n_samples, D]\n",
    "    delta_minus_expanded = delta_minus.repeat(xt1.size(0), 1)  # Shape: [n_samples, D]\n",
    "\n",
    "    # Determine if next state is inside NTR\n",
    "    with torch.no_grad():\n",
    "        in_ntr = is_in_ntr(xt1, convex_hull, delta_plus_expanded, delta_minus_expanded,epsilon_ntr=1e-6, t=t)  # [n_samples]\n",
    "        # in_ntr = is_in_ntr(xt1, convex_hull)  # [n_samples]\n",
    "\n",
    "    # Evaluate the next period's value function\n",
    "    vt_next_vals = torch.zeros(xt1.size(0), dtype=torch.float64)\n",
    "\n",
    "    # Find points inside and outside the NTR given out decision and return and NTR\n",
    "    xt1_in = xt1[in_ntr] if in_ntr.any() else torch.empty((0, D), dtype=torch.float64, device=xt.device)\n",
    "    xt1_out = xt1[~in_ntr] if (~in_ntr).any() else torch.empty((0, D), dtype=torch.float64, device=xt.device)\n",
    "\n",
    "    # # Select corresponding value function and predict\n",
    "    # if isinstance(vt_next_in, gpytorch.models.ExactGP) or isinstance(vt_next_out, gpytorch.models.ExactGP):\n",
    "    #     vt_next_in.eval()\n",
    "    #     vt_next_out.eval()\n",
    "    #     with torch.no_grad(), \\\n",
    "    #     fast_computations(covar_root_decomposition = True,log_prob=True, solves=True), \\\n",
    "    #     skip_posterior_variances(state=True) ,\\\n",
    "    #     lazily_evaluate_kernels(True) ,\\\n",
    "    #     detach_test_caches():\n",
    "    #             xt1_in = xt1_in.unsqueeze(0) if xt1_in.dim() == 1 else xt1_in\n",
    "    #             xt1_out = xt1_out.unsqueeze(0) if xt1_out.dim() == 1 else xt1_out\n",
    "    #             vt_next_val_out = vt_next_out(xt1_out).mean.squeeze()\n",
    "    #             vt_next_val_in = vt_next_in(xt1_in).mean.squeeze()  # [n_in]\n",
    "    # else:\n",
    "    #     vt_next_val_in = V_terminal(xt1_in, tau, gamma, Rf, Delta_t).squeeze()  # [n_in]\n",
    "    #     vt_next_val_out = V_terminal(xt1_out, tau, gamma, Rf, Delta_t).squeeze()  # [n_out]\n",
    "    # vt_next_vals[in_ntr] = vt_next_val_in\n",
    "    # vt_next_vals[~in_ntr] = vt_next_val_out\n",
    "\n",
    "        # Select corresponding value function and predict\n",
    "    if isinstance(vt_next_in, gpytorch.models.ExactGP) or isinstance(vt_next_out, gpytorch.models.ExactGP):\n",
    "        vt_next_in.eval()\n",
    "        vt_next_out.eval()\n",
    "        with torch.no_grad(), \\\n",
    "        fast_computations(covar_root_decomposition = True,log_prob=True, solves=True), \\\n",
    "        skip_posterior_variances(state=True) ,\\\n",
    "        lazily_evaluate_kernels(True) ,\\\n",
    "        detach_test_caches():\n",
    "                xt1_in = xt1_in.unsqueeze(0) if xt1_in.dim() == 1 else xt1_in\n",
    "                xt1_out = xt1_out.unsqueeze(0) if xt1_out.dim() == 1 else xt1_out\n",
    "                vt_next_val_out = vt_next_out(xt1_out).mean.squeeze()\n",
    "                vt_next_val_in = vt_next_in(xt1_in).mean.squeeze()  # [n_in]\n",
    "                # Replace explicit loops with tensor operations\n",
    "        vt_next_vals = torch.where(\n",
    "            in_ntr,\n",
    "            vt_next_in(xt1).mean.squeeze(),\n",
    "            vt_next_out(xt1).mean.squeeze()\n",
    "        )\n",
    "            \n",
    "    else:\n",
    "        vt_next_val_in = V_terminal(xt1_in, tau, gamma, Rf, Delta_t).squeeze()  # [n_in]\n",
    "        vt_next_val_out = V_terminal(xt1_out, tau, gamma, Rf, Delta_t).squeeze()  # [n_out]\n",
    "        vt_next_vals[in_ntr] = vt_next_val_in\n",
    "        vt_next_vals[~in_ntr] = vt_next_val_out\n",
    "\n",
    "    # if any negative elements in vt_next_vals, set them them positive\n",
    "    # if (vt_next_vals > 0).any():\n",
    "    #     vt_next_vals[vt_next_vals > 0] = vt_next_vals[vt_next_vals > 0]*(-1)\n",
    "\n",
    "    if integration_method == 'quadrature':\n",
    "        # expected_vt = torch.sum( (((pi_t1) ** (1.0 - gamma)) * vt_next_vals) * weights )\n",
    "        # expected_vt = torch.sum(((pi_t1) ** (1.0 - gamma))*weights)*torch.sum(vt_next_vals*weights)\n",
    "\n",
    "        expected_vt = torch.sum( (((pi_t1) ** (1.0 - gamma)) * vt_next_vals) * weights )\n",
    "        # expected_vt = torch.sum(((pi_t1) ** (1.0 - gamma))*weights)*torch.sum(vt_next_vals*weights)\n",
    "\n",
    "        expected_vt_weighted = expected_vt #NOTE Scaling weights. See Hoerneff 2016\n",
    "    elif integration_method == 'monte_carlo':\n",
    "        vt_i = (pi_t1 ** (1.0 - gamma)) * vt_next_vals\n",
    "        expected_vt = torch.sum(vt_i / num_mc_samples)\n",
    "\n",
    "    elif integration_method == 'quasi_monte_carlo':\n",
    "        vt_i = (pi_t1 ** (1.0 - gamma)) * vt_next_vals\n",
    "        expected_vt = torch.sum(vt_i / num_mc_samples)\n",
    "\n",
    "    vt = beta * expected_vt_weighted  # Shape: [1]\n",
    "    if include_consumption:\n",
    "        # vt = vt.view(-1)  # Ensure vt is a 1D tensor\n",
    "        vt += utility(ct, gamma) * Delta_t # Shape: [1]\n",
    "        # vt = vt.unsqueeze(0)\n",
    "\n",
    "    # # NOTE Certainty equivalent transformation from Shober 2022 (Same result actually) (see exponents which cancel...)\n",
    "    # Compute valueFunctionExpectation = E[(valueFunction)^(1 - gamma)]\n",
    "    valueFunction = pi_t1 * vt_next_vals  # Wealth times next period's value\n",
    "    valueFunctionPower = valueFunction ** (1.0 - gamma)\n",
    "    expected_jt = torch.sum(valueFunctionPower * weights)\n",
    "    expected_jt *= (1 / (np.pi ** (D / 2)))  # Scaling weights if necessary\n",
    "\n",
    "    jt = beta * expected_jt #**(1.0/(1.0-gamma))\n",
    "\n",
    "    if include_consumption:\n",
    "        jt += ct**(1-gamma) # Shape: [1]\n",
    "\n",
    "    jt = jt**(1.0/(1.0-gamma))\n",
    "    # Ensure the result is a tensor\n",
    "    if not torch.is_tensor(vt):\n",
    "        vt = torch.tensor(vt, dtype=torch.float64)\n",
    "    \n",
    "    # Delete large tensors before returning\n",
    "    del pi_t1, xt1, vt_next_vals\n",
    "    if 'Rt' in locals():\n",
    "        del Rt\n",
    "    if 'valueFunction' in locals():\n",
    "        del valueFunction\n",
    "    if 'valueFunctionPower' in locals():\n",
    "        del valueFunctionPower\n",
    "    if 'delta_plus_expanded' in locals():\n",
    "        del delta_plus_expanded\n",
    "    if 'delta_minus_expanded' in locals():\n",
    "        del delta_minus_expanded\n",
    "\n",
    "    \n",
    "    return jt\n",
    "\n",
    "# Sample points which are in Scheiddegger\n",
    "def sample_state_points(D):\n",
    "    points = []\n",
    "\n",
    "    # Add the zero row\n",
    "    points.append([0.0] * D)\n",
    "\n",
    "    # Add rows with a single 1 and the rest zeros\n",
    "    for i in range(D):\n",
    "        row = [0.0] * D\n",
    "        row[i] = 1.0\n",
    "        points.append(row)\n",
    "\n",
    "    # Add combinations of rows with values 1/d, summing to 1\n",
    "    for d in range(2, D + 1):\n",
    "        value = 1.0 / d\n",
    "        for indices in combinations(range(D), d):\n",
    "            row = [0.0] * D\n",
    "            for idx in indices:\n",
    "                row[idx] = value\n",
    "            points.append(row)\n",
    "\n",
    "    # Convert to tensor\n",
    "    points_tensor = torch.tensor(points, dtype=torch.float64)\n",
    "    return points_tensor\n",
    "\n",
    "# Functions for Sampling points in step 2.b (Solutions over the designed space)\n",
    "def point_in_convex_hull(hull, point):\n",
    "    \"\"\"\n",
    "    Check if a point is inside the convex hull.\n",
    "    \n",
    "    Args:\n",
    "        hull (scipy.spatial.ConvexHull): Convex hull object defining the NTR.\n",
    "        point (ndarray): Point to check, shape [D].\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the point is inside the convex hull, False otherwise.\n",
    "    \"\"\"\n",
    "    return np.all(np.dot(hull.equations[:, :-1], point) + hull.equations[:, -1] <= 0)\n",
    "\n",
    "def create_grid(ntr_vertices, grid_density=100):\n",
    "    \"\"\"\n",
    "    Creates a grid of points in the simplex (sum(x_i) <= 1).\n",
    "\n",
    "    Args:\n",
    "        ntr_vertices (ndarray): Vertices defining the convex hull (NTR), shape [n_vertices, D].\n",
    "        grid_density (int): Number of points along each dimension.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Grid of points inside the simplex.\n",
    "    \"\"\"\n",
    "    D = ntr_vertices.shape[1]\n",
    "    grid_ranges = [np.linspace(0, 1, grid_density) for _ in range(D)]\n",
    "    mesh = np.meshgrid(*grid_ranges, indexing='ij')\n",
    "    grid = np.stack(mesh, axis=-1).reshape(-1, D)\n",
    "    simplex_mask = np.sum(grid, axis=1) <= 1\n",
    "    points = grid[simplex_mask]\n",
    "    return points\n",
    "\n",
    "def create_grid_excluding_ntr(ntr_vertices, grid_density=100):\n",
    "    \"\"\"\n",
    "    Creates a grid of points in the simplex (sum(x_i) <= 1), excluding those inside the convex hull defined by NTR vertices.\n",
    "\n",
    "    Args:\n",
    "        ntr_vertices (ndarray): Vertices defining the convex hull (NTR), shape [n_vertices, D].\n",
    "        grid_density (int): Number of points along each dimension.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Grid of points excluding the points inside the convex hull.\n",
    "    \"\"\"\n",
    "    hull = ConvexHull(ntr_vertices)\n",
    "    grid_points = create_grid(ntr_vertices, grid_density)\n",
    "    mask = np.array([not point_in_convex_hull(hull, point) for point in grid_points])\n",
    "    outside_points = grid_points[mask]\n",
    "    return outside_points\n",
    "\n",
    "def sample_points_around_ntr_separated(ntr_vertices, num_samples, kink_ratio=0.25, inside_ratio=0.25, grid_density=25, seed=None):\n",
    "    \"\"\"\n",
    "    Samples points around kinks, inside the NTR, and in the general state space excluding NTR.\n",
    "\n",
    "    Args:\n",
    "        ntr_vertices (ndarray): Vertices defining the convex hull (NTR), shape [n_vertices, D].\n",
    "        num_samples (int): Total number of samples to generate.\n",
    "        kink_ratio (float): Fraction of samples to be kink points.\n",
    "        inside_ratio (float): Fraction of samples to be inside the NTR.\n",
    "        grid_density (int): Number of points along each dimension for the grid.\n",
    "        seed (int, optional): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (inside_points, kink_points, general_points)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    hull = ConvexHull(ntr_vertices)\n",
    "\n",
    "    # Sample points inside the NTR\n",
    "    num_inside = int(num_samples * inside_ratio)\n",
    "    inside_points = []\n",
    "    for _ in range(num_inside):\n",
    "        # Random convex combination using Dirichlet\n",
    "        coefficients = np.random.dirichlet(np.ones(len(hull.vertices)), size=1)\n",
    "        point = coefficients @ ntr_vertices[hull.vertices]\n",
    "        point = np.maximum(point, 0)  # Ensure non-negative\n",
    "        inside_points.append(point.squeeze(0))\n",
    "    inside_points = np.array(inside_points)\n",
    "\n",
    "    # Sample points around the kinks using linear interpolation with noise\n",
    "    num_kinks = int(num_samples * kink_ratio)\n",
    "    kink_points = []\n",
    "    num_vertices = len(ntr_vertices)\n",
    "    kinks_per_vertex = max(1, num_kinks // num_vertices)  # Ensure at least one kink per vertex\n",
    "\n",
    "    for i in range(num_vertices):\n",
    "        for _ in range(kinks_per_vertex):\n",
    "            attempt = 0\n",
    "            max_attempts = 100  # Prevent infinite loops\n",
    "            while attempt < max_attempts:\n",
    "                alpha = np.random.uniform(1.1, 1.15)  # Interpolation factor to push outside\n",
    "                beta = 1 - alpha\n",
    "                # Linear interpolation between vertex i and vertex (i + 1) % num_vertices\n",
    "                point = alpha * ntr_vertices[i] + beta * ntr_vertices[(i + 1) % num_vertices]\n",
    "                # Add small noise\n",
    "                noise = np.random.uniform(-0.025, 0.04, size=ntr_vertices.shape[1])\n",
    "                point += noise\n",
    "                point = np.maximum(point, 0)  # Ensure non-negative\n",
    "\n",
    "                # Check if the point is outside the convex hull\n",
    "                if not point_in_convex_hull(hull, point):\n",
    "                    kink_points.append(point)\n",
    "                    break  # Valid point found\n",
    "                attempt += 1\n",
    "            else:\n",
    "                print(f\"Failed to generate kink point outside the hull after {max_attempts} attempts for vertex {i}\")\n",
    "\n",
    "    kink_points = np.array(kink_points)\n",
    "\n",
    "    # Create a grid and exclude points inside the NTR\n",
    "    general_points = create_grid_excluding_ntr(ntr_vertices, grid_density)\n",
    "    num_general = num_samples - len(inside_points) - len(kink_points)\n",
    "    if num_general > 0:\n",
    "        if len(general_points) < num_general:\n",
    "            raise ValueError(\"Not enough general points to sample from. Increase grid_density or reduce num_samples.\")\n",
    "        selected_indices = np.random.choice(len(general_points), size=num_general, replace=False)\n",
    "        general_points = general_points[selected_indices]\n",
    "    else:\n",
    "        general_points = np.array([]).reshape(0, ntr_vertices.shape[1])\n",
    "\n",
    "    return inside_points, kink_points, general_points\n",
    "\n",
    "# Function whether a point is in the NTR for the Bellman\n",
    "def is_in_ntr(x, convex_hull, delta_plus=None, delta_minus=None, epsilon_ntr=1e-5, t=None):\n",
    "    \"\"\"\n",
    "    Determines whether each point in x is inside the NTR.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Points to check. Shape: [n_points, D]\n",
    "        convex_hull (ConvexHull or None): Convex hull defining the NTR.\n",
    "        delta_plus (torch.Tensor or None): Adjustments (increases). Shape: [n_points, D]\n",
    "        delta_minus (torch.Tensor or None): Adjustments (decreases). Shape: [n_points, D]\n",
    "        epsilon_ntr (float): Tolerance for delta policy.\n",
    "        t (int): Current time step.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Boolean tensor indicating NTR membership. Shape: [n_points]\n",
    "    \"\"\"\n",
    "    if convex_hull is None:\n",
    "        return torch.zeros(x.size(0), dtype=torch.bool, device=x.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract convex hull equations and perform tensor operations\n",
    "        equations_A = torch.tensor(convex_hull.equations[:, :-1], dtype=torch.float64)\n",
    "        equations_b = torch.tensor(convex_hull.equations[:, -1], dtype=torch.float64)\n",
    "        inequalities = torch.matmul(x, equations_A.T) + equations_b.unsqueeze(0)  # Shape: [n_points, num_constraints]\n",
    "        epsilon = epsilon_ntr\n",
    "        in_convex_hull = torch.all(inequalities <= epsilon, dim=1)\n",
    "        if delta_plus is not None and delta_minus is not None:\n",
    "            delta = delta_plus - delta_minus\n",
    "            delta_policy = torch.all(torch.abs(delta) < epsilon_ntr, dim=-1)  # Shape: [n_points]\n",
    "            return torch.logical_or(in_convex_hull, delta_policy)  # Shape: [n_points]\n",
    "        return in_convex_hull  # Shape: [n_points]\n",
    "\n",
    "# Function for projecting a point towards the NTR for initial guess\n",
    "def project_onto_convex_hull(x, convex_hull):\n",
    "    \"\"\"\n",
    "    Projects point x onto the convex hull defined by convex_hull.\n",
    "    This is used in order to generate direction of optimization.\n",
    "    When we already have an idea of the NTR\n",
    "\n",
    "    Args:\n",
    "        x (np.array): Current position. Shape: [D]\n",
    "        convex_hull (scipy.spatial.ConvexHull): Convex hull of the NTR.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Projected point within the convex hull.\n",
    "    \"\"\"\n",
    "    D = x.shape[0]\n",
    "    hull_eq = convex_hull.equations  # Shape: [num_facets, D+1]\n",
    "    A = hull_eq[:, :-1]  # Coefficients of inequalities\n",
    "    b = -hull_eq[:, -1]  # Constants of inequalities\n",
    "\n",
    "    # Objective function (squared distance) (euclidian norm)\n",
    "    def objective(x_proj):\n",
    "        return np.sum((x_proj - x) ** 2)\n",
    "\n",
    "    # Define the constraints (x_proj inside convex hull)\n",
    "    constraints = [{'type': 'ineq', 'fun': lambda x_proj, A_row=A[i], b_val=b[i]: b_val - np.dot(A_row, x_proj)} for i in range(len(b))]\n",
    "\n",
    "    # Variable bounds (e.g., x_proj between 0 and 1)\n",
    "    bounds = [(0, 1) for _ in range(D)]\n",
    "\n",
    "    # Initial guess for x_proj (could be current x)\n",
    "    x0 = np.copy(x)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    # result = minimize(objective, x0, bounds=bounds, constraints=constraints, tol=1e-6)\n",
    "    # Solve the optimization problem\n",
    "    result = minimize(\n",
    "        objective,\n",
    "        x0,\n",
    "        method='SLSQP',\n",
    "        bounds=bounds,\n",
    "        constraints=constraints,\n",
    "        options={'ftol': 1e-5, 'disp': False}\n",
    "    )\n",
    "    if result.success:\n",
    "        x_proj = result.x\n",
    "        return x_proj\n",
    "    else:\n",
    "        # If projection fails, fall back to current x\n",
    "        return None\n",
    "\n",
    "# Function for the Merton point (No costs solution)\n",
    "def MertonPoint(mu, Sigma, r, gamma):\n",
    "    \"\"\"\n",
    "    Computes the Merton portfolio weights.\n",
    "\n",
    "    Args:\n",
    "        mu (np.array): Expected returns vector of risky assets.\n",
    "        Sigma (np.array): Covariance matrix of asset returns.\n",
    "        r (float): Risk-free rate.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Optimal portfolio weights in risky assets.\n",
    "    \"\"\"\n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "    mu_r = mu - r\n",
    "    pi_star = (1.0 / gamma) * Sigma_inv.dot(mu_r)\n",
    "    return pi_star\n",
    "\n",
    "# Problem class for the optimization\n",
    "class PortfolioOptimization(cyipopt.Problem):\n",
    "    def __init__(\n",
    "        self,\n",
    "        D,\n",
    "        xt,\n",
    "        vt_next_in,\n",
    "        vt_next_out,\n",
    "        t,\n",
    "        T,\n",
    "        beta,\n",
    "        gamma,\n",
    "        Delta_t,\n",
    "        tau,\n",
    "        Rf,\n",
    "        mu,\n",
    "        Sigma,\n",
    "        c_min,\n",
    "        include_consumption=False,\n",
    "        convex_hull=None,\n",
    "        quadrature_nodes_weights=None,  # Added parameter\n",
    "        integration_method='quadrature',\n",
    "        num_mc_samples=1000\n",
    "    ):\n",
    "        self.D = D\n",
    "        self.xt = xt.detach().clone()  # Shape: [1, D]\n",
    "        self.vt_next_in = vt_next_in\n",
    "        self.vt_next_out = vt_next_out\n",
    "        self.t = t\n",
    "        self.T = T\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.Delta_t = Delta_t\n",
    "        self.tau = tau\n",
    "        self.Rf = Rf\n",
    "        self.mu = mu\n",
    "        self.Sigma = Sigma\n",
    "        self.c_min = c_min\n",
    "        self.include_consumption = include_consumption\n",
    "        self.convex_hull = convex_hull\n",
    "        self.quadrature_nodes_weights = quadrature_nodes_weights  # Store quadrature data\n",
    "        self.integration_method = integration_method\n",
    "        self.num_mc_samples = num_mc_samples\n",
    "\n",
    "        if not isinstance(xt, torch.Tensor):\n",
    "            raise TypeError(f\"xt must be a torch.Tensor, but got {type(xt)}\")\n",
    "\n",
    "        # **Define the number of variables (self.n)**\n",
    "        self.n = 2 * D + (1 if self.include_consumption else 0)\n",
    "\n",
    "        # **Define Constraint Count**\n",
    "        # Constraints:\n",
    "        # - 2 * D Asset Allocation Constraints (lower and upper bounds per asset)\n",
    "        # - 2 Sum(x + delta) Constraints (sum >=0 and sum <=1)\n",
    "        # - 1 Bond Holdings Constraint (bt >=0)\n",
    "        # - 1 Consumption Constraint (c_t >= c_min) if included\n",
    "        if self.include_consumption:\n",
    "            self.m = 2 * D + 5  # 2D asset constraints + 2 sum constraints + bt + c_t >= c_min\n",
    "        else:\n",
    "            self.m = 2 * D + 4  # 2D asset constraints + 2 sum constraints + bt\n",
    "\n",
    "        # **Variable Bounds**\n",
    "        lb = np.zeros(self.n)\n",
    "        ub = np.ones(self.n)\n",
    "\n",
    "        # **Set Lower Bound for c_t to c_min**\n",
    "        if self.include_consumption:\n",
    "            lb[2 * D] = self.c_min  # Assuming c_t is the last variable\n",
    "\n",
    "        # **Set Upper Bounds for delta_plus and delta_minus based on xt**\n",
    "        # delta_plus <= 1 - xt\n",
    "        ub[:D] = (1.0 - self.xt.cpu().numpy()).flatten()\n",
    "        # delta_minus <= xt\n",
    "        ub[D:2 * D] = self.xt.cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "        # **Predetermine delta bounds **\n",
    "        if self.convex_hull is not None:\n",
    "            if is_in_ntr(self.xt, self.convex_hull):\n",
    "                for i in range(D):\n",
    "                        #No buying or sellting allowed\n",
    "                        lb[D + i] = 0  # delta_minus_lb[i] = 0\n",
    "                        ub[D + i] = 0  # delta_minus_ub[i] = 0  # No selling allowed\n",
    "                        lb[i] = 0  # delta_plus_lb[i] = 0\n",
    "                        ub[i] = 0  # delta_plus_ub[i] = 0  # No buying allowed                                  \n",
    "            # Project onto the NTR convex hull\n",
    "            else:\n",
    "                x_proj = project_onto_convex_hull(self.xt.cpu().numpy().flatten(), self.convex_hull)\n",
    "                if x_proj is not None:\n",
    "                    # Compute delta between projected point and current point\n",
    "                    delta_np = x_proj - self.xt.cpu().numpy().flatten()\n",
    "                    delta_plus_np = np.maximum(delta_np, 0)\n",
    "                    delta_minus_np = np.maximum(-delta_np, 0)\n",
    "\n",
    "                    for i in range(D):\n",
    "                        if delta_plus_np[i] > 0+1e-8:\n",
    "                            # Suggests buying in asset i; set selling bounds to zero\n",
    "                            lb[D + i] = 0  # delta_minus_lb[i] = 0\n",
    "                            ub[D + i] = 0  # delta_minus_ub[i] = 0  # No selling allowed\n",
    "                        elif delta_minus_np[i] > 0+1e-8:\n",
    "                            # Suggests selling in asset i; set buying bounds to zero\n",
    "                            lb[i] = 0  # delta_plus_lb[i] = 0\n",
    "                            ub[i] = 0  # delta_plus_ub[i] = 0  # No buying allowed\n",
    "                        else:\n",
    "                            # No action suggested; bounds remain as initially set\n",
    "                            pass\n",
    "                else:\n",
    "                    # Projection failed; proceed with default bounds\n",
    "                    pass\n",
    "\n",
    "        # **Constraint Bounds**\n",
    "        cl = np.zeros(self.m)\n",
    "        cu = np.full(self.m, np.inf)  # All constraints are inequalities (>= 0)\n",
    "\n",
    "        # **Set Lower Bound for c_t to c_min**\n",
    "        if self.include_consumption:\n",
    "            lb[2 * D] = self.c_min  # Assuming c_t is the last variable\n",
    "            ub[2 * D] = 1.0  # Upper bound for c_t\n",
    "        # **Set Bounds for the New Budget Sum Constraint**\n",
    "        # The budget sum constraint: sum(xt) + (1+tau)*sum(delta_plus) - (1-tau)*sum(delta_minus) + bt + c_t * Delta_t = 1.0\n",
    "        budget_sum_rhs = 0.0\n",
    "        cl[-1] = budget_sum_rhs  # Lower bound for budget sum (equality)\n",
    "        cu[-1] = budget_sum_rhs  # Upper bound for budget sum (equality)\n",
    "\n",
    "\n",
    "\n",
    "        super().__init__(n=self.n, m=self.m, problem_obj=self, lb=lb, ub=ub, cl=cl, cu=cu)\n",
    "\n",
    "    def objective(self, params):\n",
    "        \"\"\"\n",
    "        Objective function for the optimization problem.\n",
    "        \"\"\"\n",
    "        # Convert params to a tensor\n",
    "        params_tensor = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "        delta_plus = params_tensor[:self.D].unsqueeze(0)    # Shape: [1, D]\n",
    "        delta_minus = params_tensor[self.D:2 * self.D].unsqueeze(0)  # Shape: [1, D]\n",
    "        if self.include_consumption:\n",
    "            ct = params_tensor[2 * self.D].unsqueeze(0)  # Shape: [1]\n",
    "        else:\n",
    "            ct = None\n",
    "\n",
    "        vt = bellman_equation(\n",
    "            self.vt_next_in,\n",
    "            self.vt_next_out,\n",
    "            self.xt,\n",
    "            delta_plus,\n",
    "            delta_minus,\n",
    "            self.beta,\n",
    "            self.gamma,\n",
    "            self.Delta_t,\n",
    "            self.tau,\n",
    "            self.Rf,\n",
    "            ct,\n",
    "            self.include_consumption,\n",
    "            self.convex_hull,\n",
    "            self.t,\n",
    "            self.mu,\n",
    "            self.Sigma,\n",
    "            self.quadrature_nodes_weights,\n",
    "            self.integration_method,  # 'monte_carlo' or 'quadrature'\n",
    "            self.num_mc_samples\n",
    "        )\n",
    "\n",
    "        if torch.isnan(vt).any() or torch.isinf(vt).any():\n",
    "            raise ValueError(\"NaN or Inf detected in objective function!\")\n",
    "\n",
    "        vt_scalar = vt.squeeze(0)\n",
    "        obj_value = -vt_scalar.item()  # Only convert to scalar at the return statement\n",
    "        return obj_value\n",
    "\n",
    "    def gradient(self, params):\n",
    "        \"\"\"\n",
    "        Gradient of the objective function.\n",
    "        \"\"\"\n",
    "        # Use automatic differentiation\n",
    "        params_tensor = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "        delta_plus = params_tensor[:self.D].unsqueeze(0)    # Shape: [1, D]\n",
    "        delta_minus = params_tensor[self.D:2 * self.D].unsqueeze(0)  # Shape: [1, D]\n",
    "        if self.include_consumption:\n",
    "            ct = params_tensor[2 * self.D].unsqueeze(0)  # Shape: [1]\n",
    "        else:\n",
    "            ct = None\n",
    "\n",
    "\n",
    "        vt = bellman_equation(\n",
    "            self.vt_next_in,\n",
    "            self.vt_next_out,\n",
    "            self.xt,\n",
    "            delta_plus,\n",
    "            delta_minus,\n",
    "            self.beta,\n",
    "            self.gamma,\n",
    "            self.Delta_t,\n",
    "            self.tau,\n",
    "            self.Rf,\n",
    "            ct,\n",
    "            self.include_consumption,\n",
    "            self.convex_hull,\n",
    "            self.t,\n",
    "            self.mu,\n",
    "            self.Sigma,\n",
    "            self.quadrature_nodes_weights,\n",
    "            self.integration_method,  # 'monte_carlo' or 'quadrature'\n",
    "            self.num_mc_samples\n",
    "        )\n",
    "\n",
    "        # Compute gradients\n",
    "        vt.backward()\n",
    "\n",
    "        # Extract gradients\n",
    "        grads = params_tensor.grad.detach().cpu().numpy()\n",
    "        return -grads  # Return negative of the gradients\n",
    "\n",
    "    def constraints_method(self, params):\n",
    "        \"\"\"\n",
    "        Computes the constraints for the optimization problem.\n",
    "        \"\"\"\n",
    "        # Convert NumPy array to PyTorch tensor\n",
    "        params_tensor = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "        constraints_tensor = self.compute_constraints(params_tensor)\n",
    "        constraints_array = constraints_tensor.detach().cpu().numpy()\n",
    "        return constraints_array\n",
    "\n",
    "    def compute_constraints(self, params_tensor):\n",
    "        D = self.D\n",
    "        tau = self.tau\n",
    "        xt = self.xt\n",
    "        Delta_t = self.Delta_t\n",
    "        c_min = self.c_min  # Use the passed c_min\n",
    "\n",
    "        if self.include_consumption:\n",
    "            delta_plus = params_tensor[:D].unsqueeze(0)             # Shape: [1, D]\n",
    "            delta_minus = params_tensor[D:2 * D].unsqueeze(0)       # Shape: [1, D]\n",
    "            c_t = params_tensor[2 * D].unsqueeze(0)                 # Shape: [1]\n",
    "        else:\n",
    "            delta_plus = params_tensor[:D].unsqueeze(0)             # Shape: [1, D]\n",
    "            delta_minus = params_tensor[D:2 * D].unsqueeze(0)       # Shape: [1, D]\n",
    "            c_t = torch.tensor([0.0], dtype=torch.float64)          # Shape: [1]\n",
    "\n",
    "        delta = delta_plus - delta_minus                            # Shape: [1, D]\n",
    "\n",
    "        # Constraint 1: Asset Allocation Constraints (xt + delta >= 0)\n",
    "        constraints_xt_delta_lower = (xt + delta).squeeze(0)        # Shape: [D]\n",
    "\n",
    "        # Constraint 2: Asset Allocation Constraints (xt + delta <= 1)\n",
    "        constraints_xt_delta_upper = 1.0 - (xt + delta + 1e-4).squeeze(0)  # Shape: [D]\n",
    "\n",
    "        # Constraint 3: Sum(x + delta) >= 0\n",
    "        sum_x_plus_delta = torch.sum(xt + delta)                    # Scalar\n",
    "        constraint_sum_geq_zero = sum_x_plus_delta                # >=0\n",
    "\n",
    "        # Constraint 4: Sum(x + delta) <= 1\n",
    "        constraint_sum_leq_one = 1.0 - sum_x_plus_delta          # >=0  (since 1 - sum(x + delta) >=0)\n",
    "\n",
    "        # Constraint 5: Bond Holdings Constraint (bt >= 0). Added small epsilon to prevent numerical issues\n",
    "        bt = normalized_bond_holdings(xt, delta_plus, delta_minus, tau, Delta_t, c_t, self.include_consumption)\n",
    "        constraint_bt = bt.squeeze(0) # Shape: []\n",
    "\n",
    "        # Constraint 6: Consumption Constraint (c_t >= c_min)\n",
    "        if self.include_consumption:\n",
    "            constraint_ct_geq_cmin = c_t.squeeze(0) - c_min  # Shape: []\n",
    "            # budget_sum = torch.sum(xt + delta) + bt + c_t\n",
    "        else:\n",
    "            constraint_ct_geq_cmin = torch.tensor(0.0, dtype=torch.float64)  # No constraint\n",
    "\n",
    "        # Concatenate all constraints in the desired order:\n",
    "        # Asset Allocation Lower Bounds, Asset Allocation Upper Bounds,\n",
    "        # Sum(x + delta) >=0, Sum(x + delta) <=1, Bond Holdings, Consumption\n",
    "        if self.include_consumption:\n",
    "            constraints_tensor = torch.cat([\n",
    "                constraints_xt_delta_lower,               # D constraints: xt + delta >= 0\n",
    "                constraints_xt_delta_upper,               # D constraints: xt + delta <= 1\n",
    "                constraint_sum_geq_zero.unsqueeze(0),    # Sum(x + delta) >= 0\n",
    "                constraint_sum_leq_one.unsqueeze(0),     # Sum(x + delta) <= 1\n",
    "                constraint_bt.unsqueeze(0),               # bt >= 0\n",
    "                constraint_ct_geq_cmin.unsqueeze(0)       # c_t >= c_min\n",
    "            ])\n",
    "        else:\n",
    "            constraints_tensor = torch.cat([\n",
    "                constraints_xt_delta_lower,               # D constraints: xt + delta >= 0\n",
    "                constraints_xt_delta_upper,               # D constraints: xt + delta <= 1\n",
    "                constraint_sum_geq_zero.unsqueeze(0),    # Sum(x + delta) >= 0\n",
    "                constraint_sum_leq_one.unsqueeze(0),     # Sum(x + delta) <= 1\n",
    "                constraint_bt.unsqueeze(0)                # bt >= 0\n",
    "            ])\n",
    "        \n",
    "        budget_sum = torch.sum(xt) + (1.0 + tau) * torch.sum(delta_plus) - (1.0 - tau) * torch.sum(delta_minus) + bt + c_t * Delta_t\n",
    "        constraint_budget_sum = budget_sum - 1.0\n",
    "        constraints_tensor = torch.cat([constraints_tensor, constraint_budget_sum])\n",
    "        return constraints_tensor\n",
    "\n",
    "    # Assign the constraints method to comply with cyipopt's requirements\n",
    "    constraints = constraints_method\n",
    "\n",
    "    def jacobianstructure(self):\n",
    "        D = self.D\n",
    "        rows = []\n",
    "        cols = []\n",
    "        seen = set()\n",
    "\n",
    "        # **1. Asset Allocation Constraints (Lower Bounds)**\n",
    "        for i in range(D):\n",
    "            # dC_i_lower/d(delta_plus_i) = 1\n",
    "            if (i, i) not in seen:\n",
    "                rows.append(i)\n",
    "                cols.append(i)\n",
    "                seen.add((i, i))\n",
    "            # dC_i_lower/d(delta_minus_i) = -1\n",
    "            if (i, D + i) not in seen:\n",
    "                rows.append(i)\n",
    "                cols.append(D + i)\n",
    "                seen.add((i, D + i))\n",
    "\n",
    "        # **2. Asset Allocation Constraints (Upper Bounds)**\n",
    "        for i in range(D):\n",
    "            # dC_i_upper/d(delta_plus_i) = -1\n",
    "            if (D + i, i) not in seen:\n",
    "                rows.append(D + i)\n",
    "                cols.append(i)\n",
    "                seen.add((D + i, i))\n",
    "            # dC_i_upper/d(delta_minus_i) = 1\n",
    "            if (D + i, D + i) not in seen:\n",
    "                rows.append(D + i)\n",
    "                cols.append(D + i)\n",
    "                seen.add((D + i, D + i))\n",
    "\n",
    "        # **3. Sum(x + delta) >= 0 Constraint**\n",
    "        sum_geq_zero_row = 2 * D\n",
    "        for j in range(D):\n",
    "            # dC_sum_geq_zero/d(delta_plus_j) = 1\n",
    "            if (sum_geq_zero_row, j) not in seen:\n",
    "                rows.append(sum_geq_zero_row)\n",
    "                cols.append(j)\n",
    "                seen.add((sum_geq_zero_row, j))\n",
    "        for j in range(D):\n",
    "            # dC_sum_geq_zero/d(delta_minus_j) = -1\n",
    "            if (sum_geq_zero_row, D + j) not in seen:\n",
    "                rows.append(sum_geq_zero_row)\n",
    "                cols.append(D + j)\n",
    "                seen.add((sum_geq_zero_row, D + j))\n",
    "\n",
    "        # **4. Sum(x + delta) <=1 Constraint**\n",
    "        sum_leq_one_row = 2 * D + 1\n",
    "        for j in range(D):\n",
    "            # dC_sum_leq_one/d(delta_plus_j) = -1\n",
    "            if (sum_leq_one_row, j) not in seen:\n",
    "                rows.append(sum_leq_one_row)\n",
    "                cols.append(j)\n",
    "                seen.add((sum_leq_one_row, j))\n",
    "        for j in range(D):\n",
    "            # dC_sum_leq_one/d(delta_minus_j) = 1\n",
    "            if (sum_leq_one_row, D + j) not in seen:\n",
    "                rows.append(sum_leq_one_row)\n",
    "                cols.append(D + j)\n",
    "                seen.add((sum_leq_one_row, D + j))\n",
    "\n",
    "        # **5. Bond Holdings Constraint (bt >= 0)**\n",
    "        bond_constraint_row = 2 * D + 2 if self.include_consumption else 2 * D + 1\n",
    "        for j in range(D):\n",
    "            # dC_bt/d(delta_plus_j) = -1 - tau\n",
    "            if (bond_constraint_row, j) not in seen:\n",
    "                rows.append(bond_constraint_row)\n",
    "                cols.append(j)\n",
    "                seen.add((bond_constraint_row, j))\n",
    "        for j in range(D):\n",
    "            # dC_bt/d(delta_minus_j) = 1 - tau\n",
    "            if (bond_constraint_row, D + j) not in seen:\n",
    "                rows.append(bond_constraint_row)\n",
    "                cols.append(D + j)\n",
    "                seen.add((bond_constraint_row, D + j))\n",
    "        if self.include_consumption:\n",
    "            # dC_bt/d(c_t) = -Delta_t\n",
    "            if (bond_constraint_row, 2 * D) not in seen:\n",
    "                rows.append(bond_constraint_row)\n",
    "                cols.append(2 * D)\n",
    "                seen.add((bond_constraint_row, 2 * D))\n",
    "\n",
    "        # **6. Consumption Constraint (if included)**\n",
    "        if self.include_consumption:\n",
    "            consumption_constraint_row = 2 * D + 3\n",
    "            # dC_consumption/d(c_t) =1\n",
    "            if (consumption_constraint_row, 2 * D) not in seen:\n",
    "                rows.append(consumption_constraint_row)\n",
    "                cols.append(2 * D)\n",
    "                seen.add((consumption_constraint_row, 2 * D))\n",
    "        # **7. Budget Sum Constraint**\n",
    "        budget_sum_row = self.m - 1  # Last constraint row\n",
    "        for j in range(D):\n",
    "            # dC_budget_sum/d(delta_plus_j) = (1 + tau)\n",
    "            rows.append(budget_sum_row)\n",
    "            cols.append(j)\n",
    "        for j in range(D):\n",
    "            # dC_budget_sum/d(delta_minus_j) = -(1 - tau)\n",
    "            rows.append(budget_sum_row)\n",
    "            cols.append(D + j)\n",
    "        if self.include_consumption:\n",
    "            # dC_budget_sum/d(c_t) = Delta_t\n",
    "            rows.append(budget_sum_row)\n",
    "            cols.append(2 * D)\n",
    "        return np.array(rows, dtype=int), np.array(cols, dtype=int)\n",
    "\n",
    "    def jacobian(self, params):\n",
    "        \"\"\"\n",
    "        Computes the Jacobian of the constraints using AutoDiff.\n",
    "        \"\"\"\n",
    "        params_tensor = torch.tensor(params, dtype=torch.float64, requires_grad=True)\n",
    "        delta_plus = params_tensor[:self.D].unsqueeze(0)    # Shape: [1, D]\n",
    "        delta_minus = params_tensor[self.D:2 * self.D].unsqueeze(0)  # Shape: [1, D]\n",
    "        if self.include_consumption:\n",
    "            ct = params_tensor[2 * self.D].unsqueeze(0)  # Shape: [1]\n",
    "        else:\n",
    "            ct = torch.tensor([0.0], dtype=torch.float64, device=params_tensor.device)  # Shape: [1]\n",
    "\n",
    "        # Compute all constraints as a single tensor\n",
    "        constraints = self.compute_constraints(params_tensor)\n",
    "\n",
    "        # Compute gradients of constraints w.r.t params\n",
    "        jacobian = []\n",
    "        for constraint in constraints:\n",
    "            # constraint.backward(retain_graph=False)\n",
    "            constraint.backward(retain_graph=True)\n",
    "            jacobian.append(params_tensor.grad.clone().detach().cpu().numpy())\n",
    "            params_tensor.grad.zero_()\n",
    "\n",
    "        # Flatten the Jacobian based on sparsity structure\n",
    "        rows, cols = self.jacobianstructure()\n",
    "        jacobian_values = [jacobian[r][c] for r, c in zip(rows, cols)]\n",
    "\n",
    "        return np.array(jacobian_values, dtype=float)\n",
    "\n",
    "# Parallel processing of steps 2.a and 2.b and 2.c\n",
    "def solve_bellman_with_ipopt(\n",
    "    D, xt, vt_next_in, vt_next_out, t, T, beta, gamma, Delta_t,tau, Rf, mu, Sigma,c_min,\n",
    "    convex_hull=None, quadrature_nodes_weights=None, include_consumption=False,\n",
    "    integration_method = 'quadrature', num_mc_samples = 1000,\n",
    "    num_starts=10, max_sucess=6\n",
    "):\n",
    "    \"\"\"\n",
    "    Solves the Bellman equation using IPOPT optimization.\n",
    "\n",
    "    Args:\n",
    "        D (int): Number of assets.\n",
    "        xt (torch.Tensor): Current state. Shape: [1, D]\n",
    "        vt_next_in (gpytorch.models.ExactGP or callable): Value function for inside NTR.\n",
    "        vt_next_out (gpytorch.models.ExactGP or callable): Value function for outside NTR.\n",
    "        t (int): Current time step.\n",
    "        T (int): Total number of time periods.\n",
    "        beta (float): Discount factor.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "        tau (float): Transaction cost rate.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        mu (np.array): Mean vector for asset returns.\n",
    "        Sigma (np.array): Covariance matrix for asset returns.\n",
    "        convex_hull (ConvexHull or None): Convex hull defining the NTR.\n",
    "        quadrature_nodes_weights (tuple or None): Quadrature nodes and weights.\n",
    "        include_consumption (bool): Flag to include consumption.\n",
    "        num_starts (int): Number of optimization starts. We tackle the problem by multiple starts.\n",
    "        drop_tolerance (float): Tolerance for dropping starts. (NOT USED)\n",
    "\n",
    "    Returns:\n",
    "        tuple or None: (delta_plus_opt, delta_minus_opt, delta_opt, omega_i_t, bt) if successful, else None.\n",
    "    \"\"\"\n",
    "    best_solution = None\n",
    "    best_info = None\n",
    "    best_obj_val = float('-inf')\n",
    "    failed_attempts = 0\n",
    "    successful_attempts = 0\n",
    "    max_successful_attempts = max_sucess  # Set the threshold for early stopping\n",
    "    max_failed_attempts = int(num_starts)\n",
    "    # max_failed_attempts = int(num_starts) 10 \n",
    "\n",
    "    # logging.info(f\"Solving Bellman equation for xt: {xt}\")\n",
    "    # Ensure xt has a batch dimension\n",
    "    if xt.dim() == 1:\n",
    "        xt = xt.unsqueeze(0)  # Shape: [1, D]\n",
    "\n",
    "    def check_portfolio_constraints(xt, delta_plus, delta_minus, tau, Delta_t, ct=None):\n",
    "        \"\"\"\n",
    "        Directly checks all portfolio constraints.\n",
    "\n",
    "        Args:\n",
    "            xt (torch.Tensor): Current portfolio weights [D]\n",
    "            delta_plus (torch.Tensor): Buy amounts [D]\n",
    "            delta_minus (torch.Tensor): Sell amounts [D]\n",
    "            tau (float): Transaction cost rate\n",
    "            Delta_t (float): Time step\n",
    "            ct (torch.Tensor, optional): Consumption [1]\n",
    "\n",
    "        Returns:\n",
    "            bool: Whether all constraints are satisfied\n",
    "            dict: Dictionary of which constraints failed\n",
    "        \"\"\"\n",
    "        # Initialize failed constraints dictionary\n",
    "        failed = {}\n",
    "\n",
    "        # 1. Check if all variables are in [0,1]\n",
    "        if torch.any((delta_plus < 0) | (delta_plus > 1)):\n",
    "            failed['delta_plus_bounds'] = 'delta_plus must be in [0,1]'\n",
    "        if torch.any((delta_minus < 0) | (delta_minus > 1)):\n",
    "            failed['delta_minus_bounds'] = 'delta_minus must be in [0,1]'\n",
    "\n",
    "        # 2. Check delta_minus <= xt constraint\n",
    "        if torch.any(delta_minus > xt):\n",
    "            failed['delta_minus_xt'] = 'delta_minus cannot be larger than xt'\n",
    "\n",
    "        # 3. Check delta_plus <= 1-xt constraint\n",
    "        if torch.any(delta_plus > (1 - xt)):\n",
    "            failed['delta_plus_xt'] = 'delta_plus cannot be larger than 1-xt'\n",
    "\n",
    "        # 4. Check xt + delta_plus - delta_minus is in [0,1] and sums to  1\n",
    "        new_portfolio = xt + delta_plus - delta_minus\n",
    "        if torch.any((new_portfolio < 0) | (new_portfolio > 1)):\n",
    "            failed['new_portfolio_bounds'] = 'new portfolio weights must be in [0,1]'\n",
    "        if torch.sum(new_portfolio) > 1:\n",
    "            failed['portfolio_sum'] = 'portfolio weights must sum to at most 1'\n",
    "\n",
    "        # 5. Check bond holdings (bt) is in [0,1]\n",
    "        ct_value = 0.0 if ct is None else ct.item()\n",
    "        bt = normalized_bond_holdings(xt, delta_plus, delta_minus, tau, Delta_t, ct_value)\n",
    "        if bt < 0 or bt > 1:\n",
    "            failed['bond_holdings'] = f'bond holdings {bt:.4f} must be in [0,1]. xt: {xt}, delta_plus: {delta_plus}, delta_minus: {delta_minus})'\n",
    "\n",
    "        # 6. If consumption is included, check it's non-negative\n",
    "        if ct is not None and ct < 0:\n",
    "            failed['consumption'] = 'consumption must be non-negative'\n",
    "\n",
    "        return len(failed) == 0, failed\n",
    "\n",
    "    # usage function\n",
    "    def test_constraints(xt, delta_plus, delta_minus, tau, Delta_t, ct=None):\n",
    "        \"\"\"Prints a readable report of constraint satisfaction\"\"\"\n",
    "        satisfied, failed = check_portfolio_constraints(xt, delta_plus, delta_minus, tau, Delta_t, ct)\n",
    "\n",
    "        return satisfied\n",
    "\n",
    "    def generate_feasible_initial_guess(\n",
    "        xt,\n",
    "        D,\n",
    "        tau,\n",
    "        c_min,\n",
    "        include_consumption=False,\n",
    "        convex_hull=None,\n",
    "        quadrature_nodes_weights=None,\n",
    "        t=None,\n",
    "        T=None,\n",
    "        beta=None,\n",
    "        gamma=None,\n",
    "        Delta_t=None,\n",
    "        Rf=None,\n",
    "        mu=None,\n",
    "        Sigma=None,\n",
    "        max_attempts=1500,\n",
    "        epsilon=1e-6  # Tolerance for determining if xt is inside NTR\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generates a feasible initial guess for the optimizer.\n",
    "        If convex_hull is provided and xt is inside the NTR, sets delta_plus and delta_minus to zero.\n",
    "        If xt is outside the NTR, projects xt onto the convex hull and computes delta_plus and delta_minus accordingly.\n",
    "        Falls back to random generation (within constraints) if projection fails or constraints are not satisfied.\n",
    "        \"\"\"\n",
    "        # Clamp xt to avoid numerical issues\n",
    "        xt = torch.clamp(xt, 0.0, 1.0)\n",
    "\n",
    "        # Squeeze xt to ensure it has shape [D]\n",
    "        xt_squeezed = xt.squeeze(0)\n",
    "\n",
    "        if convex_hull is not None:\n",
    "            # Check if xt is inside the NTR\n",
    "            xt_np = xt_squeezed.cpu().numpy()\n",
    "            # Use the is_in_ntr function\n",
    "            xt_tensor = xt_squeezed.unsqueeze(0)  # Shape: [1, D]\n",
    "            with torch.no_grad():\n",
    "                in_ntr = is_in_ntr(xt_tensor, convex_hull)\n",
    "\n",
    "            if in_ntr.item():\n",
    "                # xt is inside NTR; no change\n",
    "                delta_plus = torch.zeros(D, dtype=torch.float64)  # Shape: [D]\n",
    "                delta_minus = torch.zeros(D, dtype=torch.float64)  # Shape: [D]\n",
    "\n",
    "                # Compute available cash before consumption\n",
    "                available_cash = 1.0 - torch.sum(xt_squeezed)\n",
    "\n",
    "                if include_consumption:\n",
    "                    # Ensure there's enough cash for minimum consumption\n",
    "                    max_consumption = available_cash / Delta_t\n",
    "                    if max_consumption < c_min:\n",
    "                        # Not enough wealth for minimum consumption\n",
    "                        raise ValueError(f\"Not enough cash for minimum consumption at xt = {xt_squeezed}\")\n",
    "                    # Allocate consumption (e.g., half of available cash)\n",
    "                    c_t = max(c_min, max_consumption * 0.5)\n",
    "                    # c_t = torch.tensor(c_t_value, dtype=torch.float64)  # Scalar tensor\n",
    "                else:\n",
    "                    c_t = torch.tensor(0.0, dtype=torch.float64)  # Scalar tensor\n",
    "\n",
    "                # Compute bond holdings after consumption\n",
    "                bt = available_cash - c_t * Delta_t\n",
    "\n",
    "                # Form the initial guess vector\n",
    "                deltas_concatenated = torch.cat([delta_plus, delta_minus])  # Shape: [2D]\n",
    "                if include_consumption:\n",
    "                    initial_guess = torch.cat([deltas_concatenated, c_t.unsqueeze(0)])  # Shape: [2D + 1]\n",
    "                else:\n",
    "                    initial_guess = deltas_concatenated  # Shape: [2D]\n",
    "\n",
    "                # Verify constraints\n",
    "                if test_constraints(xt_squeezed, delta_plus, delta_minus, tau, Delta_t, c_t):\n",
    "                    return initial_guess\n",
    "                else:\n",
    "                    # If constraints are not satisfied, proceed to random generation\n",
    "                    pass\n",
    "            else:\n",
    "                # xt is outside NTR; proceed with projection onto convex hull\n",
    "                x_proj = project_onto_convex_hull(xt_np, convex_hull)\n",
    "                if x_proj is not None:\n",
    "                    # Compute delta_plus and delta_minus based on projection\n",
    "                    delta_np = x_proj - xt_np  # Compute delta in numpy\n",
    "                    delta_np *= 0.975  # Scale the delta slightly\n",
    "                    delta_plus_np = np.maximum(delta_np, 0)\n",
    "                    delta_minus_np = np.maximum(-delta_np, 0)\n",
    "\n",
    "                    delta_plus = torch.tensor(delta_plus_np, dtype=torch.float64)  # Shape: [D]\n",
    "                    delta_minus = torch.tensor(delta_minus_np, dtype=torch.float64)  # Shape: [D]\n",
    "\n",
    "                    # Compute available cash after transactions (before consumption)\n",
    "                    available_cash = 1.0 - torch.sum(xt_squeezed) - (1 + tau) * torch.sum(delta_plus) + (1 - tau) * torch.sum(delta_minus)\n",
    "\n",
    "                    if include_consumption:\n",
    "                        # Ensure there's enough cash for minimum consumption\n",
    "                        max_consumption = available_cash / Delta_t\n",
    "                        if max_consumption < c_min:\n",
    "                            # Not enough wealth for minimum consumption\n",
    "                            raise ValueError(f\"Not enough cash for minimum consumption at xt = {xt_squeezed}\")\n",
    "                        # Allocate consumption (e.g., half of available cash)\n",
    "                        c_t = max(c_min, max_consumption * 0.5)\n",
    "                    else:\n",
    "                        c_t = torch.tensor(0.0, dtype=torch.float64)  # Scalar tensor\n",
    "\n",
    "                    # Compute bond holdings after consumption\n",
    "                    bt = available_cash - c_t * Delta_t\n",
    "\n",
    "                    # Form the initial guess vector\n",
    "                    deltas_concatenated = torch.cat([delta_plus, delta_minus])  # Shape: [2D]\n",
    "                    if include_consumption:\n",
    "                        initial_guess = torch.cat([deltas_concatenated, c_t.unsqueeze(0)])  # Shape: [2D + 1]\n",
    "                    else:\n",
    "                        initial_guess = deltas_concatenated  # Shape: [2D]\n",
    "\n",
    "                    # Verify constraints\n",
    "                    if test_constraints(xt_squeezed, delta_plus, delta_minus, tau, Delta_t, c_t):\n",
    "                        return initial_guess\n",
    "                    else:\n",
    "                        # If constraints are not satisfied, proceed to random generation\n",
    "                        pass\n",
    "                else:\n",
    "                    # Projection failed, proceed to random generation\n",
    "                    pass\n",
    "\n",
    "        # Fallback to random generation if projection fails or not provided\n",
    "        for attempt in range(max_attempts):\n",
    "            # Generate random delta_plus and delta_minus within feasible bounds\n",
    "            delta_plus = torch.clamp(torch.rand(D, dtype=torch.float64) * (1.0 - xt_squeezed), 0., 1.0)\n",
    "            delta_minus = torch.clamp(torch.rand(D, dtype=torch.float64) * xt_squeezed, 0., 1.0)\n",
    "\n",
    "            # Ensure no simultaneous buying and selling\n",
    "            delta_diff = torch.min(delta_plus, delta_minus)\n",
    "            delta_plus -= delta_diff\n",
    "            delta_minus -= delta_diff\n",
    "\n",
    "            # Scale deltas to make room for bonds\n",
    "            if torch.any(delta_plus > 0):\n",
    "                delta_plus *= 0.975\n",
    "            if torch.any(delta_minus > 0):\n",
    "                delta_minus *= 0.975\n",
    "\n",
    "            delta = delta_plus - delta_minus  # Shape: [D]\n",
    "\n",
    "            # Compute available cash after transactions (before consumption)\n",
    "            available_cash = 1.0 - torch.sum(xt_squeezed) - (1 + tau) * torch.sum(delta_plus) + (1 - tau) * torch.sum(delta_minus)\n",
    "\n",
    "            # Ensure available cash is non-negative\n",
    "            if available_cash < 0:\n",
    "                continue  # Invalid initial guess, try again\n",
    "\n",
    "            if include_consumption:\n",
    "                # Ensure there's enough cash for minimum consumption\n",
    "                max_consumption = available_cash / Delta_t\n",
    "                if max_consumption < c_min:\n",
    "                    continue  # Not enough wealth for minimum consumption\n",
    "\n",
    "                # Allocate a portion of available cash to consumption\n",
    "                c_t = torch.rand(1).item() * 0.95 * (max_consumption - c_min) + c_min\n",
    "                # c_t = torch.tensor(c_t_value, dtype=torch.float64)\n",
    "            else:\n",
    "                c_t = torch.tensor(0.0, dtype=torch.float64)\n",
    "\n",
    "            # Compute bond holdings after consumption\n",
    "            bt = available_cash - c_t * Delta_t\n",
    "\n",
    "            # Ensure bond holdings are non-negative\n",
    "            if bt < 0:\n",
    "                continue  # Invalid initial guess, try again\n",
    "\n",
    "            # Form the initial guess vector\n",
    "            deltas_concatenated = torch.cat([delta_plus, delta_minus])\n",
    "            if include_consumption:\n",
    "                initial_guess = torch.cat([deltas_concatenated, c_t.unsqueeze(0)])\n",
    "            else:\n",
    "                initial_guess = deltas_concatenated\n",
    "\n",
    "            # Verify constraints\n",
    "            if test_constraints(xt_squeezed, delta_plus, delta_minus, tau, Delta_t, c_t):\n",
    "                return initial_guess\n",
    "\n",
    "        # If all attempts failed, raise an error\n",
    "        raise ValueError(f\"Failed to generate a feasible initial guess after max attempts. xt = {xt_squeezed}\")\n",
    "\n",
    "    # Loop through multiple starting points #NOTE OPEN HERE IF WE NEED TO CHANGE SETTINGS\n",
    "    for start_idx in range(num_starts):\n",
    "        initial_guess = generate_feasible_initial_guess(xt, D, tau, c_min, include_consumption, convex_hull, quadrature_nodes_weights, t, T, beta, gamma, Delta_t, Rf, mu, Sigma)\n",
    "        if convex_hull is not None:\n",
    "            scale_factor = 1.0 - start_idx * 5e-4\n",
    "        # Apply the scaling factor to the initial guess\n",
    "            initial_guess *= scale_factor\n",
    "        \n",
    "        # logging.debug(f\"Start {start_idx}: Initial guess generated.\")\n",
    "\n",
    "        try:\n",
    "            # Create the optimization problem\n",
    "            prob = PortfolioOptimization(\n",
    "                D,\n",
    "                xt,\n",
    "                vt_next_in,\n",
    "                vt_next_out,\n",
    "                t,\n",
    "                T,\n",
    "                beta,\n",
    "                gamma,\n",
    "                Delta_t,\n",
    "                tau,\n",
    "                Rf,\n",
    "                mu=mu,\n",
    "                Sigma=Sigma,\n",
    "                c_min=c_min,\n",
    "                include_consumption=include_consumption,\n",
    "                convex_hull=convex_hull,\n",
    "                quadrature_nodes_weights=quadrature_nodes_weights,  # Pass quadrature data\n",
    "                integration_method=integration_method,\n",
    "                num_mc_samples=num_mc_samples\n",
    "            )\n",
    "\n",
    "            # Set IPOPT options\n",
    "            prob.add_option(\"tol\", 1e-8)\n",
    "            # prob.add_option(\"acceptable_tol\", 1e-6)\n",
    "            prob.add_option(\"max_iter\", 1000)\n",
    "            prob.add_option(\"linear_solver\", \"mumps\")  # Use an efficient sparse solver\n",
    "            prob.add_option(\"sb\", \"yes\") #Omit annoying header\n",
    "            prob.add_option(\"print_level\", 0)\n",
    "            # prob.add_option(\"mu_strategy\", \"monotone\")        # adaptive, monotone\n",
    "            prob.add_option(\"mu_strategy\", \"adaptive\")        # adaptive, monotone\n",
    "            prob.add_option(\"mu_oracle\", \"quality-function\")  # Control step quality. 'probing', 'quality-function', 'loqo'\n",
    "            # prob.add_option(\"mu_oracle\", \"probing\")  # Control step quality. 'probing', 'quality-function', 'loqo'\n",
    "            # prob.add_option(\"fixed_mu_oracle\", \"probing\")  # average_compl, probing, loqo, quality-function\n",
    "            prob.add_option(\"line_search_method\", \"filter\")   # filter, cg-penalty  (note only filter officially suported!?)\n",
    "            prob.add_option('jacobian_approximation', 'exact') #exact, finite-difference-values\n",
    "            prob.add_option(\"hessian_approximation\", 'limited-memory')  # limited-memory, exact\n",
    "            prob.add_option(\"hessian_approximation_space\", \"all-variables\") # nonlinear-variables , all-variables\n",
    "            prob.add_option(\"max_resto_iter\", 0)\n",
    "\n",
    "            prob.add_option(\"nlp_scaling_method\", \"gradient-based\") #gradient-based, none\n",
    "            prob.add_option(\"fast_step_computation\", 'yes')\n",
    "            # prob.add_option(\"warm_start_init_point\", \"yes\")\n",
    "            # prob.add_option(\"constr_viol_tol\", 1e-5)  # Lessen constraint violation tolerance. This is the most important of the 3 tolerances i think\n",
    "\n",
    "            solution, info = prob.solve(initial_guess.cpu().numpy())\n",
    "\n",
    "            # Check if the solution is not valid\n",
    "            if solution is None:\n",
    "                logging.warning(f\"Start {start_idx}: Solver returned None solution.\")\n",
    "                failed_attempts += 1\n",
    "                if failed_attempts > max_failed_attempts:\n",
    "                    logging.error(f\"Exceeded maximum allowed failed attempts: {max_failed_attempts}\")\n",
    "                    if include_consumption:\n",
    "                        return None, None, None, None, None, None\n",
    "                    else:\n",
    "                        return None, None, None, None, None\n",
    "                continue\n",
    "\n",
    "            # Check if the solution is valid\n",
    "            if solution is not None and info['status'] == 0:  # Success condition\n",
    "                successful_attempts += 1\n",
    "                logging.info(f\"Start {start_idx}: Successful solution found. Successful attempts: {successful_attempts}\")\n",
    "\n",
    "            # Check if this solution is better than the current best\n",
    "            if info['status'] == 0 and (best_solution is None or info['obj_val'] > best_obj_val):\n",
    "                best_solution = solution\n",
    "                best_obj_val = info['obj_val']\n",
    "                logging.info(f\"Start {start_idx}: New best solution found with obj_val: {best_obj_val}\")\n",
    "\n",
    "                # Check if the number of successful attempts has reached the threshold\n",
    "                if successful_attempts >= max_successful_attempts:\n",
    "                    # logging.info(f\"Early stopping after {successful_attempts} successful attempts.\")\n",
    "                    break  # Exit the loop early\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Optimization failed for start {start_idx}: {e}\")\n",
    "            # logging.error(f\"Optimization failed for start {start_idx}: {e}\", exc_info=True)\n",
    "            failed_attempts += 1\n",
    "            if failed_attempts > max_failed_attempts:\n",
    "                print(f\"Exceeded maximum allowed failed attempts: {max_failed_attempts}\")\n",
    "                logging.error(f\"Exceeded maximum allowed failed attempts: {max_failed_attempts}\")\n",
    "                if include_consumption:\n",
    "                    return None, None, None, None, None, None\n",
    "                else:\n",
    "                    return None, None, None, None, None\n",
    "            continue\n",
    "        # After each optimization attempt\n",
    "        del initial_guess\n",
    "        if 'prob' in locals():\n",
    "            del prob\n",
    "        # torch.cuda.empty_cache()  # If using CUDA\n",
    "\n",
    "    if best_solution is None:\n",
    "        print(f\"No optimizer solution found for point {xt}!\")\n",
    "        # logging.error(f\"No optimizer solution found for point {xt}!\")\n",
    "        if include_consumption:\n",
    "            return None, None, None, None, None, None\n",
    "        else:\n",
    "            return None, None, None, None, None\n",
    "    try:\n",
    "        # After finding the best solution, extract the variables\n",
    "        idx = 0\n",
    "        delta_plus_opt = best_solution[idx : idx + D]          # Shape: [D]\n",
    "        delta_minus_opt = best_solution[idx + D : idx + 2 * D]  # Shape: [D]\n",
    "        if include_consumption:\n",
    "            ct_opt = best_solution[idx + 2 * D]                    # Scalar\n",
    "        delta_opt = delta_plus_opt - delta_minus_opt          # Shape: [D]\n",
    "\n",
    "        # Convert delta_plus_opt and delta_minus_opt to tensors and reshape to [1, D]\n",
    "        delta_plus_tensor = torch.tensor(delta_plus_opt, dtype=torch.float64).unsqueeze(0)   # [1, D]\n",
    "        delta_minus_tensor = torch.tensor(delta_minus_opt, dtype=torch.float64).unsqueeze(0) # [1, D]\n",
    "\n",
    "        if include_consumption:\n",
    "            c_t_tensor = torch.tensor(ct_opt, dtype=torch.float64).unsqueeze(0)  # Shape: [1]\n",
    "        else:\n",
    "            c_t_tensor = torch.tensor([0.0], dtype=torch.float64)  # Shape: [1]\n",
    "\n",
    "        # Compute omega_i_t and bond holdings (bt)\n",
    "        omega_i_t = xt.cpu().numpy() + delta_opt                                            # [1, D] + [D] -> [1, D]\n",
    "        bt = normalized_bond_holdings(\n",
    "            xt, delta_plus_tensor, delta_minus_tensor,tau,Delta_t, c_t_tensor, include_consumption\n",
    "        ).item()\n",
    "\n",
    "        torch.set_printoptions(sci_mode=False, precision=4)\n",
    "        np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "        if 'prob' in locals():\n",
    "            del prob\n",
    "        # Clean up\n",
    "        del best_solution, best_info\n",
    "        # torch.cuda.empty_cache()  # If using CUDA\n",
    "        \n",
    "        if include_consumption:\n",
    "            ct_opt = np.round(ct_opt, 4)\n",
    "            return delta_plus_opt, delta_minus_opt, delta_opt, omega_i_t, bt, ct_opt\n",
    "        else:\n",
    "            return delta_plus_opt, delta_minus_opt, delta_opt, omega_i_t, bt\n",
    "    except Exception as e:\n",
    "        # logging.error(f\"Error processing best solution: {e}\", exc_info=True)\n",
    "        if include_consumption:\n",
    "            return None, None, None, None, None, None\n",
    "        else:\n",
    "            return None, None, None, None, None\n",
    "\n",
    "def approximate_ntr(vt_next_in, vt_next_out, D, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min,include_consumption=False, quadrature_nodes_weights=None,integration_method = 'quadrature', num_mc_samples = 1000,):\n",
    "    \"\"\"\n",
    "    Approximates the Non-Trading Region (NTR) at time t.\n",
    "\n",
    "    Args:\n",
    "        vt_next_in (gpytorch.models.ExactGP or callable): Value function for inside NTR.\n",
    "        vt_next_out (gpytorch.models.ExactGP or callable): Value function for outside NTR.\n",
    "        D (int): Number of assets.\n",
    "        t (int): Current time step.\n",
    "        T (int): Total number of time periods.\n",
    "        beta (float): Discount factor.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "        tau (float): Transaction cost rate.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        mu (np.array): Mean vector for asset returns.\n",
    "        Sigma (np.array): Covariance matrix for asset returns.\n",
    "        include_consumption (bool): Flag to include consumption.\n",
    "        quadrature_nodes_weights (tuple): Quadrature nodes and weights.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (tilde_omega_t, convex_hull)\n",
    "    \"\"\"\n",
    "    # Step 1: Sample state points at vertices and midpoints\n",
    "    tilde_X_t = sample_state_points(D)  # Shape: [num_points, D]\n",
    "    N = tilde_X_t.size(0)\n",
    "    tilde_omega_t = []\n",
    "    convex_hull = None  # Initialize convex_hull\n",
    "\n",
    "    for i in range(N):\n",
    "        tilde_x_i_t = tilde_X_t[i:i+1]  # Shape: [1, D]\n",
    "        solution = solve_bellman_with_ipopt(\n",
    "            D, tilde_x_i_t.squeeze(0), vt_next_in, vt_next_out, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma,\n",
    "            c_min,convex_hull=None,\n",
    "            quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "            include_consumption=include_consumption,\n",
    "            integration_method = integration_method, num_mc_samples = num_mc_samples,\n",
    "        )\n",
    "        if include_consumption:\n",
    "            delta_plus, delta_minus, delta_opt, omega_i_t, bt, ct_opt = solution\n",
    "        else:\n",
    "            delta_plus, delta_minus, delta_opt, omega_i_t, bt = solution\n",
    "\n",
    "        if delta_plus is None:\n",
    "            print(f\"Delta is None for point {tilde_x_i_t}\")\n",
    "            continue\n",
    "\n",
    "        tilde_omega_i_t = (tilde_x_i_t + delta_plus - delta_minus).numpy()\n",
    "        tilde_omega_t.append(tilde_omega_i_t.squeeze(0))\n",
    "\n",
    "    # Construct convex hull\n",
    "    if len(tilde_omega_t) >= D + 1:\n",
    "        tilde_omega_t = np.vstack(tilde_omega_t)  # Shape: [num_points, D]\n",
    "        convex_hull = ConvexHull(tilde_omega_t)\n",
    "    else:\n",
    "        convex_hull = None\n",
    "\n",
    "    return tilde_omega_t, convex_hull\n",
    "\n",
    "def process_ntr_point(tilde_x_i_t, vt_next_in, vt_next_out, D, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min, include_consumption, quadrature_nodes_weights, integration_method, num_mc_samples,num_starts=5):\n",
    "    \"\"\"\n",
    "    Processes a single NTR point by solving the optimization problem.\n",
    "\n",
    "    Args:\n",
    "        tilde_x_i_t (torch.Tensor): Current NTR state vector. Shape: [D]\n",
    "\n",
    "    Returns:\n",
    "        np.array: Processed NTR point.\n",
    "    \"\"\"\n",
    "    solution = solve_bellman_with_ipopt(\n",
    "        D, tilde_x_i_t, vt_next_in, vt_next_out, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min,\n",
    "        include_consumption=include_consumption,\n",
    "        quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "        integration_method=integration_method, num_mc_samples=num_mc_samples, num_starts=num_starts\n",
    "    )\n",
    "\n",
    "    if solution[0] is None:\n",
    "        return None  # Indicate failure\n",
    "    if include_consumption:\n",
    "        delta_plus, delta_minus, delta_opt, omega_i_t, bt, ct_opt = solution\n",
    "    else:\n",
    "        delta_plus, delta_minus, delta_opt, omega_i_t, bt = solution\n",
    "    # delta_plus, delta_minus, *_ = solution\n",
    "    return (tilde_x_i_t + delta_plus - delta_minus).numpy()  # Return transformed point\n",
    "\n",
    "def approximate_ntr_parallel(vt_next_in, vt_next_out, D, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min, include_consumption, quadrature_nodes_weights, integration_method, num_mc_samples,backendtype,num_starts=15):\n",
    "    \"\"\"\n",
    "    Approximates the NTR with parallel processing.\n",
    "    \"\"\"\n",
    "    tilde_X_t = sample_state_points(D)  # Shape: [num_points, D]\n",
    "    num_jobs = 3  # Limit to available cores\n",
    "\n",
    "    # Parallel processing of NTR points\n",
    "    tilde_omega_t = Parallel(n_jobs=num_jobs, backend=backendtype)(\n",
    "        delayed(process_ntr_point)(\n",
    "            tilde_x_i_t, vt_next_in, vt_next_out, D, t, T, beta, gamma, Delta_t, tau, Rf, mu, Sigma, c_min,\n",
    "            include_consumption, quadrature_nodes_weights, integration_method, num_mc_samples, num_starts\n",
    "        ) for tilde_x_i_t in tilde_X_t\n",
    "    )\n",
    "\n",
    "    # Filter out failed solutions and form convex hull\n",
    "    tilde_omega_t = [pt for pt in tilde_omega_t if pt is not None]\n",
    "    if len(tilde_omega_t) >= D + 1:\n",
    "        tilde_omega_t = np.vstack(tilde_omega_t)\n",
    "        convex_hull = ConvexHull(tilde_omega_t)\n",
    "    else:\n",
    "        convex_hull = None\n",
    "\n",
    "    return tilde_omega_t, convex_hull\n",
    "\n",
    "def process_point(\n",
    "    x_i_t,\n",
    "    quadrature_nodes_weights,\n",
    "    V_t_plus1_in,\n",
    "    V_t_plus1_out,\n",
    "    t,\n",
    "    T,\n",
    "    beta,\n",
    "    gamma,\n",
    "    Delta_t,\n",
    "    tau,\n",
    "    Rf,\n",
    "    mu,\n",
    "    Sigma,\n",
    "    c_min,\n",
    "    NTR_t,\n",
    "    D,\n",
    "    include_consumption=False,\n",
    "    integration_method='quadrature',\n",
    "    num_mc_samples=1000,\n",
    "    num_starts=8,\n",
    "    max_sucess=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a single state point by solving the optimization problem or\n",
    "    setting optimal actions directly if the point is inside the NTR.\n",
    "\n",
    "    Args:\n",
    "        x_i_t (torch.Tensor): Current state vector. Shape: [D]\n",
    "        quadrature_nodes_weights (tuple): Quadrature nodes and weights.\n",
    "        V_t_plus1_in (gpytorch.models.ExactGP or callable): Value function for inside NTR.\n",
    "        V_t_plus1_out (gpytorch.models.ExactGP or callable): Value function for outside NTR.\n",
    "        t (int): Current time step.\n",
    "        T (int): Total number of time periods.\n",
    "        beta (float): Discount factor.\n",
    "        gamma (float): Coefficient of relative risk aversion.\n",
    "        tau (float): Transaction cost rate.\n",
    "        Rf (float): Risk-free rate factor.\n",
    "        mu (np.array): Mean vector for asset returns.\n",
    "        Sigma (np.array): Covariance matrix for asset returns.\n",
    "        c_min (float): Minimum consumption.\n",
    "        NTR_t (ConvexHull or None): Convex hull defining the NTR.\n",
    "        D (int): Number of assets.\n",
    "        include_consumption (bool): Flag to include consumption.\n",
    "\n",
    "    Returns:\n",
    "        tuple or None:\n",
    "            If include_consumption=True: (x_i_t, v_i_t_value, in_ntr_value, c_t)\n",
    "            Else: (x_i_t, v_i_t_value, in_ntr_value)\n",
    "            If unsuccessful, returns None.\n",
    "    \"\"\"\n",
    "    torch.set_printoptions(sci_mode=False, precision=4)\n",
    "    np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "    # Check if the point is inside the NTR\n",
    "    x_i_t_tensor = x_i_t.unsqueeze(0)  # [1, D]\n",
    "    with torch.no_grad():\n",
    "        in_ntr_value = is_in_ntr(x_i_t_tensor, NTR_t)\n",
    "    # if not include_consumption:\n",
    "    if in_ntr_value.item() and not include_consumption:\n",
    "            # Point is inside NTR; set delta_plus and delta_minus to zero\n",
    "            delta_plus_tensor = torch.zeros_like(x_i_t_tensor)\n",
    "            delta_minus_tensor = torch.zeros_like(x_i_t_tensor)\n",
    "            if include_consumption:\n",
    "                # Set consumption to c_min or compute optimal consumption if applicable\n",
    "                ct_tensor = torch.tensor([c_min], dtype=torch.float64)  # Shape: [1]\n",
    "            else:\n",
    "                ct_tensor = torch.tensor([0.0], dtype=torch.float64)  # Shape: [1]\n",
    "\n",
    "            # Compute the value function directly\n",
    "            v_i_t = bellman_equation(\n",
    "                V_t_plus1_in, V_t_plus1_out, x_i_t_tensor, delta_plus_tensor, delta_minus_tensor,\n",
    "                beta, gamma, Delta_t, tau, Rf, ct=ct_tensor, include_consumption=include_consumption,\n",
    "                convex_hull=NTR_t, t=t, mu=mu, Sigma=Sigma,\n",
    "                quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "                integration_method=integration_method, num_mc_samples=num_mc_samples\n",
    "            )\n",
    "\n",
    "            # Since delta_plus and delta_minus are zeros, omega_i_t equals x_i_t\n",
    "            omega_i_t = x_i_t_tensor.numpy()\n",
    "            bt = normalized_bond_holdings(\n",
    "                x_i_t_tensor, delta_plus_tensor, delta_minus_tensor, tau, Delta_t, ct_tensor,\n",
    "                include_consumption\n",
    "            ).item()\n",
    "\n",
    "            # Print the results\n",
    "            if include_consumption:\n",
    "                print(f\"Point inside NTR. Point: {x_i_t}, Delta+: {delta_plus_tensor.squeeze().numpy()}, \"\n",
    "                    f\"Delta-: {delta_minus_tensor.squeeze().numpy()}, Omega: {omega_i_t.squeeze()}, \"\n",
    "                    f\"bt: {np.round(bt, 4)}, Consumption: {ct_tensor.item()}\")\n",
    "            else:\n",
    "                print(f\"Point inside NTR. Point: {x_i_t}, Delta+: {delta_plus_tensor.squeeze().numpy()}, \"\n",
    "                    f\"Delta-: {delta_minus_tensor.squeeze().numpy()}, Omega: {omega_i_t.squeeze()}, \"\n",
    "                    f\"bt: {np.round(bt, 4)}\")\n",
    "\n",
    "            # Prepare the result\n",
    "            if include_consumption:\n",
    "                result = (x_i_t, v_i_t.item(), True, ct_tensor.item())\n",
    "            else:\n",
    "                result = (x_i_t, v_i_t.item(), True)\n",
    "    else:\n",
    "        # Point is outside NTR; proceed with optimization  \n",
    "        solution = solve_bellman_with_ipopt(\n",
    "            D, x_i_t, V_t_plus1_in, V_t_plus1_out, t, T, beta, gamma, Delta_t, tau,\n",
    "            Rf, mu, Sigma, c_min, convex_hull=NTR_t,\n",
    "            quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "            include_consumption=include_consumption,\n",
    "            integration_method=integration_method, num_mc_samples=num_mc_samples,\n",
    "            num_starts=num_starts, max_sucess=max_sucess\n",
    "        )\n",
    "\n",
    "        if include_consumption:\n",
    "            delta_plus, delta_minus, delta_opt, omega_i_t, bt, ct_opt = solution\n",
    "        else:\n",
    "            delta_plus, delta_minus, delta_opt, omega_i_t, bt = solution\n",
    "\n",
    "        if delta_plus is None:\n",
    "            # Optimization failed\n",
    "            print(f\"Optimization failed for point {x_i_t}. Skipping.\")\n",
    "            return None  # Indicate failure\n",
    "\n",
    "        # Convert arrays to tensors\n",
    "        delta_plus_tensor = torch.tensor(delta_plus, dtype=torch.float64).unsqueeze(0)  # [1, D]\n",
    "        delta_minus_tensor = torch.tensor(delta_minus, dtype=torch.float64).unsqueeze(0)  # [1, D]\n",
    "\n",
    "        if include_consumption:\n",
    "            ct_tensor = torch.tensor([ct_opt], dtype=torch.float64)  # Shape: [1]\n",
    "        else:\n",
    "            ct_tensor = torch.tensor([0.0], dtype=torch.float64)  # Shape: [1]\n",
    "\n",
    "        # Compute the value function\n",
    "        v_i_t = bellman_equation(\n",
    "            V_t_plus1_in, V_t_plus1_out, x_i_t_tensor, delta_plus_tensor, delta_minus_tensor,\n",
    "            beta, gamma, Delta_t, tau, Rf, ct=ct_tensor, include_consumption=include_consumption,\n",
    "            convex_hull=NTR_t, t=t, mu=mu, Sigma=Sigma,\n",
    "            quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "            integration_method=integration_method, num_mc_samples=num_mc_samples\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        if include_consumption:\n",
    "            print(f\"Best solution found. Point: {x_i_t}, Delta+: {delta_plus}, Delta-: {delta_minus}, \"\n",
    "                  f\"Delta: {delta_opt}, Omega: {omega_i_t}, bt: {np.round(bt, 4)}, Consumption: {ct_opt}\")\n",
    "        else:\n",
    "            print(f\"Best solution found. Point: {x_i_t}, Delta+: {delta_plus}, Delta-: {delta_minus}, \"\n",
    "                  f\"Delta: {delta_opt}, Omega: {omega_i_t}, bt: {np.round(bt, 4)}\")\n",
    "\n",
    "        # Prepare the result\n",
    "        if include_consumption:\n",
    "            result = (x_i_t, v_i_t.item(), in_ntr_value, ct_opt)\n",
    "        else:\n",
    "            result = (x_i_t, v_i_t.item(), in_ntr_value)\n",
    "\n",
    "    # Clean up\n",
    "    del delta_plus_tensor, delta_minus_tensor, v_i_t, x_i_t_tensor\n",
    "    if 'ct_tensor' in locals():\n",
    "        del ct_tensor\n",
    "    if 'solution' in locals():\n",
    "        del solution\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "\n",
    "    T = 6       # Number of time period (years)\n",
    "    Delta_t = 1.0 # time step (in years). Delta_t = T/M <=> M = T/Delta_t\n",
    "    M = int(T/Delta_t) # needs to be integer for the range function\n",
    "    # rho = 0.1 # Utility discount rate, see Cai Judd Xu.\n",
    "    # beta = np.exp(-rho*Delta_t)\n",
    "    beta = 0.97\n",
    "    tau = 0.005\n",
    "\n",
    "    Schober_Parameters = False #Parameters of Schober 2020 \n",
    "    Cai_Judd_Identical = True #Assumes a correlation coefficent of 0\n",
    "    Cai_Judd_High_Correlation = False #Assumes a correlation coefficient of 0.75\n",
    "\n",
    "    if Schober_Parameters:\n",
    "        gamma = 3.5\n",
    "        r = np.round(np.log(1.0408),4)\n",
    "        mu = np.array([0.0572, 0.0638, 0.07, 0.0764, 0.0828])\n",
    "        Sigma = np.array([\n",
    "                        [0.0256, 0.00576, 0.00288, 0.00176, 0.00096], \n",
    "                        [0.00576, 0.0324, 0.0090432, 0.010692, 0.01296],\n",
    "                        [0.00288, 0.0090432, 0.04, 0.0132, 0.0168],\n",
    "                        [0.00176, 0.010692, 0.0132, 0.0484, 0.02112],\n",
    "                        [0.00096, 0.01296, 0.0168, 0.02112, 0.0576]\n",
    "                        ])\n",
    "    if Cai_Judd_Identical:\n",
    "        gamma = 3.0\n",
    "        r = np.log(np.round(np.exp(0.03),4))\n",
    "        mu = np.array([0.07, 0.07, 0.07, 0.07,0.07])\n",
    "        Sigma = np.array([\n",
    "                        [0.04, 0.00, 0.00, 0.00, 0.00], \n",
    "                        [0.00, 0.04, 0.00, 0.00, 0.00],\n",
    "                        [0.00, 0.00, 0.04, 0.00, 0.00],\n",
    "                        [0.00, 0.00, 0.00, 0.04, 0.00],\n",
    "                        [0.00, 0.00, 0.00, 0.00, 0.04]\n",
    "                        ])\n",
    "    if Cai_Judd_High_Correlation:\n",
    "        gamma = 3.0\n",
    "        r = np.log(np.round(np.exp(0.03),5))\n",
    "        mu = np.array([0.07, 0.07, 0.07, 0.07,0.07])\n",
    "        Sigma = np.array([\n",
    "                        [0.04, 0.03, 0.03, 0.03, 0.03], \n",
    "                        [0.03, 0.04, 0.03, 0.03, 0.03],\n",
    "                        [0.03, 0.03, 0.04, 0.03, 0.03],\n",
    "                        [0.03, 0.03, 0.03, 0.04, 0.03],\n",
    "                        [0.03, 0.03, 0.03, 0.03, 0.04]\n",
    "                        ])\n",
    "    Rf = np.exp(r*Delta_t)\n",
    "\n",
    "\n",
    "    def select_mu_sigma(mu, Sigma, D):\n",
    "        \"\"\"\n",
    "        Selects the first D elements from mu and the corresponding D x D submatrix from Sigma.\n",
    "        \"\"\"\n",
    "        selected_mu = mu[:D]\n",
    "        selected_Sigma = Sigma[:D, :D]\n",
    "        return selected_mu, selected_Sigma\n",
    "\n",
    "    D = 2\n",
    "    mu, Sigma = select_mu_sigma(mu, Sigma, D)\n",
    "    refinement = np.array([2 * D + 2] * D)\n",
    "    # refinement = np.array([3 * D] * D)\n",
    "\n",
    "    N = 50 * D  # Number of state points to sample\n",
    "\n",
    "    include_consumption = True  # Set to False if consumption is not included\n",
    "    c_min = 0.05  # Minimum consumption for numerical stability\n",
    "    if not include_consumption:\n",
    "        c_min = 0.0\n",
    "\n",
    "    integration_method = 'quadrature' # 'quadrature' or 'monte_carlo' 'quasi_monte_carlo'\n",
    "    num_mc_samples = 1000\n",
    "\n",
    "    # number_of_quadrature_points = 5 # In each dimension #Only for old quad\n",
    "    merton_p = MertonPoint(mu, Sigma, r, gamma)\n",
    "\n",
    "    # Print all parameters when running the script\n",
    "    do_print = True\n",
    "    if do_print:\n",
    "        print(\"===== Dynamic Portfolio Optimization Parameters =====\")\n",
    "        print(f\"Number of Assets (D): {D}\")\n",
    "        print(f\"Total Years (T): {T}\")\n",
    "        print(f\"Time Step Size (Delta_t): {Delta_t}\")\n",
    "        print(f\"Number of Time Steps (step size * T): {M}\")\n",
    "        print(f\"Discount Factor (beta): {beta}\")\n",
    "        print(f\"Relative Risk Aversion (gamma): {gamma}\")\n",
    "        print(f\"Transaction Cost Rate (tau): {tau}\")\n",
    "        print(f\"Yearly Net Risk-Free Rate (r): {r}\")\n",
    "        print(f\"Expected Yearly Net Returns (mu): {mu}\")\n",
    "        print(f\"Covariance Matrix (Sigma):\\n{Sigma}\")\n",
    "        print(f\"Include Consumption: {include_consumption}\")\n",
    "        print(f\"Minimum Consumption (c_min): {c_min}\")\n",
    "        print(f\"Number of State Points (N): {N}\")\n",
    "        print(f\"merton_p: {merton_p}\")\n",
    "        print(f\"Integration Method: {integration_method}\")\n",
    "        print(\"==============================================\\n\")\n",
    "\n",
    "    # Initialize value function V\n",
    "    V = [[None, None] for _ in range(M + 1)]\n",
    "\n",
    "    # Set terminal value function\n",
    "    V[M][0] = lambda x: V_terminal(x, tau, gamma,r,Delta_t)  # For inside NTR\n",
    "    V[M][1] = lambda x: V_terminal(x, tau, gamma,r,Delta_t)  # For outside NTR\n",
    "\n",
    "    NTR = [None for _ in range(M)]  # Store NTR for each period\n",
    "\n",
    "    # Generate quadrature nodes and weights using helper functions\n",
    "    # n_q = number_of_quadrature_points  # Number of quadrature points per dimension (adjust as needed)\n",
    "    sparse = False\n",
    "\n",
    "    # nodes, weights, L = gauss_hermite_quadrature(n_q, mu, Sigma, Delta_t)\n",
    "    # expnodes, weights, L = gauss_hermite_log_normal_quadrature(n_q, mu, Sigma, Delta_t)\n",
    "    expnodes, weights, L = TasmanianSGLogQuadNorm(refinement, mu, Sigma)\n",
    "    quadrature_nodes_weights = (expnodes, weights, L)  # Include L for scaling\n",
    "    backendtype = 'loky' # Type of parallelization 'threading' or 'loky'\n",
    "    number_of_parallel_processes = 3 # Number of parallel processes (for 2.b only)\n",
    "    Starts2A = 100\n",
    "    Starts2B = 15\n",
    "\n",
    "    for t in reversed(range(M)):\n",
    "        print(f\"Time step {t}\")\n",
    "\n",
    "        include_consumption = include_consumption\n",
    "        print(f\"include consumption: {include_consumption}\")\n",
    "        # Step 2a: Approximate NTR\n",
    "        print(\"Step 2a: Approximate NTR\")\n",
    "        tilde_omega_t, convex_hull = approximate_ntr_parallel(\n",
    "            vt_next_in=V[t+1][0],\n",
    "            vt_next_out=V[t+1][1],\n",
    "            D=D,\n",
    "            t=t,\n",
    "            T=T,\n",
    "            beta=beta,\n",
    "            gamma=gamma,\n",
    "            Delta_t=Delta_t,\n",
    "            tau=tau,\n",
    "            Rf=Rf,\n",
    "            mu=mu,\n",
    "            Sigma=Sigma,\n",
    "            c_min=c_min,\n",
    "            include_consumption=include_consumption,\n",
    "            quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "            integration_method=integration_method,\n",
    "            num_mc_samples=num_mc_samples,\n",
    "            backendtype=backendtype,\n",
    "            num_starts=Starts2A # I want to make absolutely sure that we get a solution\n",
    "        )\n",
    "\n",
    "        NTR[t] = convex_hull\n",
    "        print(tilde_omega_t)\n",
    "\n",
    "        print(f\"len tilde_omega_t: {len(tilde_omega_t)}\")\n",
    "        # Step 2b: Sample state points\n",
    "        print(\"Step 2b: Sample state points\")\n",
    "        # i sample points with a new seed at each iteration!\n",
    "        points_inside_ntr, points_around_kinks, points_outside_ntr = sample_points_around_ntr_separated(tilde_omega_t, N,seed=12012001+t)\n",
    "        all_points = np.vstack([points_inside_ntr, points_around_kinks, points_outside_ntr])\n",
    "        # shuffled_indices = np.random.permutation(all_points.shape[0])\n",
    "        # Reorder the points using the shuffled indices\n",
    "        # all_points = all_points[shuffled_indices]\n",
    "        #Round the points to 8 decimals\n",
    "        all_points = np.round(all_points, 8)\n",
    "        X_t = torch.tensor(all_points, dtype=torch.float64)\n",
    "\n",
    "        data_in = []\n",
    "        data_out = []\n",
    "        failed_points = 0\n",
    "\n",
    "        # Step 2c: Parallel processing of points\n",
    "        num_jobs = number_of_parallel_processes  # NEVER use all cores. num_jobs should be <= N # NOTE threading / loky backend . loky is faster\n",
    "        results = Parallel(n_jobs=num_jobs, backend=backendtype)(\n",
    "            delayed(process_point)(\n",
    "                x_i_t,\n",
    "                V_t_plus1_in=V[t+1][0],\n",
    "                V_t_plus1_out=V[t+1][1],\n",
    "                t=t,\n",
    "                T=T,\n",
    "                beta=beta,\n",
    "                gamma=gamma,\n",
    "                Delta_t=Delta_t,\n",
    "                tau=tau,\n",
    "                Rf=Rf,\n",
    "                mu=mu,\n",
    "                Sigma=Sigma,\n",
    "                c_min=c_min,\n",
    "                NTR_t=NTR[t],\n",
    "                D=D,\n",
    "                include_consumption=include_consumption,\n",
    "                quadrature_nodes_weights=quadrature_nodes_weights,\n",
    "                integration_method=integration_method,\n",
    "                num_mc_samples=num_mc_samples,\n",
    "                num_starts=Starts2B,\n",
    "                max_sucess=2\n",
    "            ) for x_i_t in X_t\n",
    "        )\n",
    "\n",
    "        total_points = len(results)\n",
    "        for result in results:\n",
    "            if result is None:\n",
    "                failed_points += 1\n",
    "                continue\n",
    "            if include_consumption:\n",
    "                x_i_t, v_i_t_value, in_ntr_value, c_t = result\n",
    "            else:\n",
    "                x_i_t, v_i_t_value, in_ntr_value = result\n",
    "            if in_ntr_value:\n",
    "                data_in.append((x_i_t, v_i_t_value))\n",
    "                # Optionally, store c_t if needed\n",
    "            else:\n",
    "                data_out.append((x_i_t, v_i_t_value))\n",
    "                # Optionally, store c_t if needed\n",
    "\n",
    "        # Calculate failure rate\n",
    "        failure_rate = failed_points / total_points\n",
    "        print(f\"Failure Rate: {failure_rate * 100:.2f}%\")\n",
    "        # Check if failure rate exceeds 20%\n",
    "        if failure_rate > 0.25:\n",
    "            print(\"Failure rate exceeded 20%. Stopping optimization.\")\n",
    "            break  # Exit the optimization loop early\n",
    "\n",
    "        # Step 2e: Train GPR models for inside and outside NTR (V_{t+1}^{in/out})\n",
    "        print(\"Step 2e: Train GPR models for inside and outside NTR\")\n",
    "        if data_in:\n",
    "            train_x_in = torch.stack([d[0] for d in data_in])  # [num_in, D]\n",
    "            train_y_in = torch.tensor([d[1] for d in data_in], dtype=torch.float64)  # [num_in]\n",
    "            model_in, likelihood_in = train_gp_model(train_x_in, train_y_in)\n",
    "            V[t][0] = model_in\n",
    "            print(f\"train gp model_in done \")\n",
    "\n",
    "        if data_out:\n",
    "            train_x_out = torch.stack([d[0] for d in data_out]) # [num_out, D]\n",
    "            train_y_out = torch.tensor([d[1] for d in data_out], dtype=torch.float64) # [num_out]\n",
    "            model_out, likelihood_out = train_gp_model(train_x_out, train_y_out)\n",
    "            V[t][1] = model_out\n",
    "            print(f\"train gp model_out done\")\n",
    "\n",
    "        # Clear previous value functions to free memory\n",
    "        if t < T - 1:\n",
    "            if V[t+1][0] is not None:\n",
    "                del V[t+1]\n",
    "\n",
    "        # Clear other variables if necessary\n",
    "        del data_in, data_out, train_x_in, train_y_in, train_x_out, train_y_out\n",
    "        del tilde_omega_t, convex_hull, X_t, results     \n",
    "        # torch.cuda.empty_cache()  # If using CUDA\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the NTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTR array saved to NTRs/NTR_Cai_Identical_d2_tau_0.005__with_consumption.pkl\n"
     ]
    }
   ],
   "source": [
    "def save_ntr_array_to_file(NTR, filename_prefix, D, tau,include_consumption):\n",
    "    \"\"\"\n",
    "    Saves the NTR array to a file with a dynamically generated name using pickle in the \"NTRs\" folder.\n",
    "\n",
    "    Parameters:\n",
    "    - NTR: List of ConvexHull objects (or None).\n",
    "    - filename_prefix: A string to indicate the parameter set (e.g., \"Schober_Parameters\").\n",
    "    - D: The number of assets (dimensionality).\n",
    "    - tau: The transaction cost rate.\n",
    "\n",
    "    The file will be named `NTR_<filename_prefix>_d<D>_tau_<tau>.pkl` and saved in the \"NTRs\" folder.\n",
    "    \"\"\"\n",
    "    # Ensure the \"NTRs\" folder exists\n",
    "    os.makedirs(\"NTRs\", exist_ok=True)\n",
    "\n",
    "    if include_consumption:\n",
    "        consumption = \"_with_consumption\"\n",
    "    else:\n",
    "        consumption = \"_no_consumption\"\n",
    "\n",
    "    # Construct the full file path\n",
    "    filename = f\"NTRs/NTR_{filename_prefix}_d{D}_tau_{tau}_{consumption}.pkl\"\n",
    "\n",
    "    # Save the NTR array using pickle\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(NTR, file)\n",
    "    print(f\"NTR array saved to {filename}\")\n",
    "\n",
    "def load_ntr_array_from_file(filename):\n",
    "    \"\"\"\n",
    "    Loads the NTR array from a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: The name of the file to load.\n",
    "\n",
    "    Returns:\n",
    "    - The NTR array (list of ConvexHull objects or None).\n",
    "    \"\"\"\n",
    "    # Ensure the \"NTRs\" folder exists\n",
    "    os.makedirs(\"NTRs\", exist_ok=True)\n",
    "\n",
    "    # Construct the full file path\n",
    "    full_filename = os.path.join(\"NTRs\", filename)\n",
    "\n",
    "    with open(full_filename, \"rb\") as file:\n",
    "        NTR = pickle.load(file)\n",
    "    print(f\"NTR array loaded from {full_filename}\")\n",
    "    return NTR\n",
    "\n",
    "# Choose the parameter prefix based on the active parameter set\n",
    "if Schober_Parameters:\n",
    "    filename_prefix = \"Schober_Parameters\"\n",
    "elif Cai_Judd_Identical:\n",
    "    filename_prefix = \"Cai_Identical\"\n",
    "elif Cai_Judd_High_Correlation:\n",
    "    filename_prefix = \"Cai_High_Correlation\"\n",
    "else:\n",
    "    filename_prefix = \"Unknown_Parameters\"\n",
    "\n",
    "save_ntr_array_to_file(NTR, filename_prefix, D, tau,include_consumption)\n",
    "# NTR = load_ntr_array_from_file(f\"NTR_Cai_Identical_d2_tau_0.001__no_consumption.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Quasi Monte Carlo (Sobol) integral over R_t samples: [1.0618 1.0618]\n",
      "Monte Carlo integral over R_t samples: [1.0621 1.0601]\n",
      "Quasi Monte Carlo (Halton) integral over R_t samples: [1.0613 1.0611]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"MC\", low_discrepancy=\"sobol\"):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo, Quasi Monte Carlo, or Randomized Quasi Monte Carlo integration\n",
    "    for multivariate normal distributions.\n",
    "\n",
    "    Parameters:\n",
    "        mu (np.array): Mean vector for the normal distribution.\n",
    "        Sigma (np.array): Covariance matrix.\n",
    "        Delta_t (float): Time step.\n",
    "        num_mc_samples (int): Number of Monte Carlo samples.\n",
    "        method (str): Sampling method - \"MC\" for Monte Carlo, \"QMC\" for Quasi-Monte Carlo, \"RQMC\" for Randomized QMC.\n",
    "        low_discrepancy (str): Low discrepancy sequence method for QMC - \"sobol\" or \"halton\".\n",
    "\n",
    "    Returns:\n",
    "        mc_integral_Rt (torch.Tensor): Monte Carlo integral approximation for E[R_t].\n",
    "    \"\"\"\n",
    "\n",
    "    # Adjusted mean according to Cai, Judd, Xu (2013)\n",
    "    adjusted_mu = torch.tensor(mu * Delta_t - 0.5 * np.diag(Sigma) * Delta_t, dtype=torch.float64)\n",
    "\n",
    "    # Sampling\n",
    "    if method == \"MC\":\n",
    "        # Standard Monte Carlo sampling\n",
    "        standard_normal_samples = torch.randn((num_mc_samples, len(mu)), dtype=torch.float64)\n",
    "\n",
    "    elif method == \"QMC\":\n",
    "        # Quasi-Monte Carlo (deterministic)\n",
    "        if low_discrepancy == \"sobol\":\n",
    "            sampler = qmc.Sobol(d=len(mu), scramble=False)\n",
    "        elif low_discrepancy == \"halton\":\n",
    "            sampler = qmc.Halton(d=len(mu), scramble=False)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported low discrepancy method. Choose 'sobol' or 'halton'.\")\n",
    "\n",
    "        # Generate low-discrepancy samples in [0,1] and map to standard normal\n",
    "        samples = sampler.random(num_mc_samples)\n",
    "        \n",
    "        # Avoid values at exactly 0 or 1 to prevent `nan` in inverse CDF transformation\n",
    "        epsilon = 1e-10\n",
    "        samples = samples * (1 - 2 * epsilon) + epsilon\n",
    "\n",
    "        # Transform [0,1] samples to standard normal using inverse CDF\n",
    "        standard_normal_samples = torch.tensor(samples, dtype=torch.float64)\n",
    "        standard_normal_samples = torch.erfinv(2 * standard_normal_samples - 1) * np.sqrt(2)\n",
    "\n",
    "    elif method == \"RQMC\":\n",
    "        # Randomized Quasi-Monte Carlo (with scrambling)\n",
    "        if low_discrepancy == \"sobol\":\n",
    "            sampler = qmc.Sobol(d=len(mu), scramble=True)\n",
    "        elif low_discrepancy == \"halton\":\n",
    "            sampler = qmc.Halton(d=len(mu), scramble=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported low discrepancy method. Choose 'sobol' or 'halton'.\")\n",
    "\n",
    "        # Generate scrambled low-discrepancy samples in [0,1] and map to standard normal\n",
    "        samples = sampler.random(num_mc_samples)\n",
    "        \n",
    "        # Avoid values at exactly 0 or 1 to prevent `nan` in inverse CDF transformation\n",
    "        epsilon = 1e-10\n",
    "        samples = samples * (1 - 2 * epsilon) + epsilon\n",
    "\n",
    "        # Transform [0,1] samples to standard normal using inverse CDF\n",
    "        standard_normal_samples = torch.tensor(samples, dtype=torch.float64)\n",
    "        standard_normal_samples = torch.erfinv(2 * standard_normal_samples - 1) * np.sqrt(2)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose 'MC', 'QMC', or 'RQMC'.\")\n",
    "\n",
    "    # Cholesky decomposition for covariance transformation\n",
    "    cholesky_factor = torch.tensor(np.linalg.cholesky(Sigma * Delta_t), dtype=torch.float64)\n",
    "\n",
    "    # Apply transformation to obtain log-normal samples\n",
    "    log_Rt_samples = adjusted_mu[:, None] + cholesky_factor @ standard_normal_samples.T\n",
    "    log_Rt_samples = log_Rt_samples.T\n",
    "\n",
    "    # Transform samples to R_t\n",
    "    Rt = torch.exp(log_Rt_samples)\n",
    "\n",
    "    # Monte Carlo integration approximation for E[R_t]\n",
    "    mc_integral_Rt = torch.mean(Rt, axis=0)\n",
    "\n",
    "    return mc_integral_Rt\n",
    "\n",
    "# Example usage:\n",
    "mu = np.array([0.06, 0.06])\n",
    "Sigma = np.array([[0.04, 0.0], [0.0, 0.04]])\n",
    "Delta_t = 1.0\n",
    "num_mc_samples = 5000\n",
    "\n",
    "# Run Randomized Quasi Monte Carlo (Sobol)\n",
    "result_rqmc = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"RQMC\", low_discrepancy=\"sobol\")\n",
    "print(\"Randomized Quasi Monte Carlo (Sobol) integral over R_t samples:\", result_rqmc.numpy())\n",
    "\n",
    "# Run standard Monte Carlo\n",
    "result_mc = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"MC\")\n",
    "print(\"Monte Carlo integral over R_t samples:\", result_mc.numpy())\n",
    "\n",
    "# Run Quasi Monte Carlo with Halton\n",
    "result_qmc_halton = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"QMC\", low_discrepancy=\"halton\")\n",
    "print(\"Quasi Monte Carlo (Halton) integral over R_t samples:\", result_qmc_halton.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: double != float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m num_mc_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Run Randomized Quasi Monte Carlo\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m result_rqmc \u001b[38;5;241m=\u001b[39m monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRQMC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomized Quasi Monte Carlo integral over R_t samples:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result_rqmc\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Run standard Monte Carlo\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 48\u001b[0m, in \u001b[0;36mmonte_carlo_integration\u001b[0;34m(mu, Sigma, Delta_t, num_mc_samples, method, low_discrepancy)\u001b[0m\n\u001b[1;32m     45\u001b[0m cholesky_factor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky(Sigma \u001b[38;5;241m*\u001b[39m Delta_t), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Apply transformation to obtain log-normal samples\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m log_Rt_samples \u001b[38;5;241m=\u001b[39m adjusted_mu[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m cholesky_factor \u001b[38;5;241m@\u001b[39m standard_normal_samples\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     49\u001b[0m log_Rt_samples \u001b[38;5;241m=\u001b[39m log_Rt_samples\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Transform samples to R_t\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: double != float"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"MC\", low_discrepancy=\"sobol\"):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo, Quasi Monte Carlo, or Randomized Quasi Monte Carlo integration\n",
    "    for multivariate normal distributions.\n",
    "\n",
    "    Parameters:\n",
    "        mu (np.array): Mean vector for the normal distribution.\n",
    "        Sigma (np.array): Covariance matrix.\n",
    "        Delta_t (float): Time step.\n",
    "        num_mc_samples (int): Number of Monte Carlo samples.\n",
    "        method (str): Sampling method - \"MC\" for Monte Carlo, \"QMC\" for Quasi-Monte Carlo, \"RQMC\" for Randomized QMC.\n",
    "        low_discrepancy (str): Low discrepancy sequence method for QMC - only \"sobol\" is supported.\n",
    "\n",
    "    Returns:\n",
    "        mc_integral_Rt (torch.Tensor): Monte Carlo integral approximation for E[R_t].\n",
    "    \"\"\"\n",
    "    # Adjusted mean according to Cai, Judd, Xu (2013)\n",
    "    adjusted_mu = torch.tensor(mu * Delta_t - 0.5 * np.diag(Sigma) * Delta_t, dtype=torch.float64)\n",
    "\n",
    "    # Sampling\n",
    "    if method == \"MC\":\n",
    "        # Standard Monte Carlo sampling\n",
    "        standard_normal_samples = torch.randn((num_mc_samples, len(mu)))\n",
    "    elif method in [\"QMC\", \"RQMC\"]:\n",
    "        if low_discrepancy != \"sobol\":\n",
    "            raise ValueError(\"Only 'sobol' is supported for low discrepancy sampling.\")\n",
    "\n",
    "        # Sobol sequence sampling with optional scrambling\n",
    "        sobol_engine = torch.quasirandom.SobolEngine(dimension=len(mu), scramble=(method == \"RQMC\"))\n",
    "        samples = sobol_engine.draw(num_mc_samples)\n",
    "        \n",
    "        # Avoid values at exactly 0 or 1 to prevent `nan` in inverse CDF transformation\n",
    "        epsilon = 1e-10\n",
    "        samples = torch.clamp(samples, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Transform [0,1] samples to standard normal using inverse CDF\n",
    "        standard_normal_samples = torch.erfinv(2 * samples - 1) * np.sqrt(2)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose 'MC', 'QMC', or 'RQMC'.\")\n",
    "\n",
    "    # Cholesky decomposition for covariance transformation\n",
    "    cholesky_factor = torch.tensor(np.linalg.cholesky(Sigma * Delta_t), dtype=torch.float64)\n",
    "\n",
    "    # Apply transformation to obtain log-normal samples\n",
    "    log_Rt_samples = adjusted_mu[:, None] + cholesky_factor @ standard_normal_samples.T\n",
    "    log_Rt_samples = log_Rt_samples.T\n",
    "\n",
    "    # Transform samples to R_t\n",
    "    Rt = torch.exp(log_Rt_samples)\n",
    "\n",
    "    # Monte Carlo integration approximation for E[R_t]\n",
    "    mc_integral_Rt = torch.mean(Rt, axis=0)\n",
    "\n",
    "    return mc_integral_Rt\n",
    "\n",
    "# Example usage:\n",
    "mu = np.array([0.06, 0.06])\n",
    "Sigma = np.array([[0.04, 0.0], [0.0, 0.04]])\n",
    "Delta_t = 1.0\n",
    "num_mc_samples = 5000\n",
    "\n",
    "# Run Randomized Quasi Monte Carlo\n",
    "result_rqmc = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"RQMC\")\n",
    "print(\"Randomized Quasi Monte Carlo integral over R_t samples:\", result_rqmc.numpy())\n",
    "\n",
    "# Run standard Monte Carlo\n",
    "result_mc = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"MC\")\n",
    "print(\"Monte Carlo integral over R_t samples:\", result_mc.numpy())\n",
    "\n",
    "# Run Quasi Monte Carlo with Sobol\n",
    "result_qmc_sobol = monte_carlo_integration(mu, Sigma, Delta_t, num_mc_samples, method=\"QMC\", low_discrepancy=\"sobol\")\n",
    "print(\"Quasi Monte Carlo (Sobol) integral over R_t samples:\", result_qmc_sobol.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "def plot_ntr_at_time(NTR_history, t):\n",
    "    hull = NTR_history[t]\n",
    "    \n",
    "    if hull is not None:\n",
    "        vertices = hull.points  # Vertices are stored in the 'points' attribute of ConvexHull\n",
    "        D = vertices.shape[1]  # Dimension of the state space\n",
    "        plt.figure(figsize=(4,3),dpi=200)\n",
    "\n",
    "        if D == 2:\n",
    "            # 2D plot\n",
    "            plt.fill(vertices[hull.vertices, 0], vertices[hull.vertices, 1], color = colors[1], alpha=0.2,label='NTR')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            plt.scatter(merton_p[0], merton_p[1],label='Merton Point')\n",
    "            plt.legend()\n",
    "            plt.xlabel('State dimension 1')\n",
    "            plt.ylabel('State dimension 2')\n",
    "            x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "            y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "            plt.xlim(x_min - 0.1, x_max + 0.1)\n",
    "            plt.ylim(y_min - 0.1, y_max + 0.1)\n",
    "            plt.grid(alpha=0.5)\n",
    "\n",
    "        elif D == 3:\n",
    "                # 3D plot\n",
    "                ax = plt.axes(projection='3d')\n",
    "                ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], color=colors[1],alpha=0.2,s=10,marker='*')\n",
    "                \n",
    "                # Plot only the convex hull surfaces without edges\n",
    "                faces = hull.simplices\n",
    "                poly3d = [[vertices[face] for face in simplex] for simplex in faces]\n",
    "                ax.add_collection3d(Poly3DCollection(poly3d, facecolors=colors[4], edgecolor='none', alpha=0.2))\n",
    "                \n",
    "                ax.scatter(merton_p[0], merton_p[1], merton_p[2], color=colors[0], s=75, label='Merton Point')\n",
    "                ax.legend()\n",
    "                ax.set_xlabel('State dimension 1')\n",
    "                ax.set_ylabel('State dimension 2')\n",
    "                ax.set_zlabel('State dimension 3')\n",
    "                plt.title(f'NTR at time {t}')\n",
    "                x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "                y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "                z_min, z_max = vertices[:, 2].min(), vertices[:, 2].max()\n",
    "                ax.set_xlim(x_min - 0.05, x_max + 0.05)\n",
    "                ax.set_ylim(y_min - 0.05, y_max + 0.05)\n",
    "                ax.set_zlim(z_min - 0.05, z_max + 0.05)  \n",
    "                ax.view_init(elev=35, azim=25)  # Adjust elev and azim for desired viewing angle\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"Not enough vertices to form an NTR at time {t}\")\n",
    "\n",
    "# Example: Plot NTR at time t=1\n",
    "plot_ntr_at_time(NTR,int(T/Delta_t)-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuYAAAIeCAYAAAD3WMonAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAB7CAAAewgFu0HU+AAB6oUlEQVR4nO39bXAbWZof+P4TpESJEsUkq8cWXZ7pYqJrptlzZ7oIUOt1+I4jugR02bE72pguQFrvqD9NEaiauBNxw+4Gin1vhKSIvUOBXeH7YeLOFKB29IfWeC0C3bPr8a6jBLA6Ytv2xloESu25Nmu6CylVb7dZO1NFpN7fSJz9wMosgMgEkEACyAT+vwhWkcyDzCeRj8AHByfPkYQQAkRERERENFC+QQdAREREREQszImIiIiIXGF80AEQEQ2aJEkNv5NlGcViEYqimD4ml8shGo0abXWapiEUCiGfzwMACoUCksmkI3FeuXIFgUAAADAzMwNN01o+RlEU4ysejxuPJyIi92GPORGNPCEEhBCoVCpGka1pmlF4m4lEIhBCIJ/PY3Z2FpqmYWVlBZVKxSjKAaBUKqFUKkHTNMTjcVy5cgXZbNb4UhTFaLO0tFS3LZVK4dy5c9A0DaVSCaqqGvutVCoQQqBcLhu/k2XZ+L3+VSwWEY/HsbOzg2AwiHA4XLefUVcqlTAzM4NgMNjWGx0vKxQKiEaj8Pv9kCQJwWAQ8Xic+UDkJoKIiAyKoohUKiUACAAilUq1fEw2mxWhUMh0WyKREIqiWD42nU4bx8pms6ZtKpWKkGXZMhZFUQQAEQgEmsaZSCQEACHLsiiXy03b9ks2m+1JLO3uNxKJGM9/Op12PA63SCQSIhQKiWKxKITYz6na3EskEgOOkIiEEII95kREByQSCWPIRzKZbNmjqChK3XCWWpqmtT2UxWofsixjZWUFn3zyia3HHZRKpSDLMjRNQzAYbOsxvZbP53vSU93ufs+dO2d8HwqFHI/DDTKZDDRNQz6fN/JalmXEYjEUi0UAwNraGjKZzCDDJCJwKAsRkalsNmt832xISyuqqjpS8IVCIUcK2KWlJQD7bxjcUIhtbm4OdL+RSMQY/mN1P4GX6W8M0+m06fZAIIBIJAIAiMfjQz+ch8jtWJgTEZlQFAWpVArA/jjktbW1jvazs7PjSMGnKIojY4FrYxl0EaaPnR/0ftv9xMGLNjc3oWka/H6/5XNS+6lBoVDoV2hEZIKFORGRBbtDWnpJlmXs7Ox0vZ/acxj0DC1OzVbTr/16kX69VVVt2muuu3HjRl/iIiJzLMyJiJrodkiLPobXCd3uS9M0o0c0EAgMdEx1r8Y0c6x0vdprHA6HTdsM+pMTIvoMC3MioiacGtLiBnpPsqIo2NjYcGSf+hjmcDiMaDRq/N9qSEShUIDf76/r1Q4Gg5AkyfiKx+O24+hkv/F4HMFgEH6/HzMzM8jlcnXbw+Fw3XZ9KEgmkzHO0+/3IxwO1w0TUVUV8Xgc0WjUeHw7eZPL5RAOh419R6PRrnv/FUVBpVJBpVIxxpIfVDse/9SpU10dj4i6NOhpYYiI3MRqasNAIGBMLXdwGr5isSgikUhHx6udsi6fz3e0Dz02s+kSK5WKyOfzIhQKCVmWHZ0Wr1KpiEAg0BB3NpsVAEQsFmv6eH2aR30KP6e0u998Pt90usqD2/P5vIjFYg3t9Oe/WCwauVCpVIzt+vNhlSOVSsW4PgdjDgQCQlGUnk5vGQqFjGk0iWiwuPInEVEbstks/H4/gP0hLU4OUXGKqqp1w200TYOqqsbMMJVKxdHjJZNJlEol5PP5uiETkUgEsVgMmUwGsiwbnzi4jR5zPp9v6C2v3Z7NZlEoFJBOp3Hu3LmGnueVlRVEo1Gsrq4a0xLWikQikGUZuVwOqqo23Aysf8JQO52hbmNjAzMzMz3LuVKpZHy6ceXKFcf3T0T2cCgLEVEbFEUxbp4rlUquvMFQUZS6lUPz+TzK5TKKxSI2NzdNh2t0Qx8CYbZP/Q2Ck8frldnZ2abb9VlbVFU1HQ6iF9q5XM4yL/Q2B28gzmQyKBQKCIVCpmP+ZVlGKBSqK6CdpF+nVCplOdSFiPqHhTkRUZtisZjRo7m2ttaTqf56IRAIYGNjA5qmNR3/bVcqlUIoFDLtEdfnSx+m5d71c2rG6oZavfg/eKOl/mav2Qw5+k2bTudbPB6HqqpIJBJIJBKO7puIOsOhLERENhwc0lIulwccUXsCgYAxF3oymXRkWMTBXl5VVVEoFFAul4dypg/9ulvpZD50vdguFAqWN73qn0xYrfzaiVwuh0wmg1QqxaKcyEVYmBMR2aAPadF7G5PJZN0CLW6mF+ZO9ryqqopUKoVCoYBAIIBz584ZxfqwTVvo9EJEtW9e4vE4YrGYo/u3UigUEI1Gkc1mOXyFyGU4lIWIyKZYLGYUn2traz1bVr6XnCjOM5kM/H6/ceOiXugpitJy3Har/faC294o1Bb6/fqEoVQqIRqNIp/PmxblwzT0iMiLWJgTEXWgdhXFTubdHoTaQrDbNxO1Qy/y+XzDTCNm2n0zkM/ne1Ko9mq/3dDHlvdjSJQ+a8/GxobpWPhSqWS5OigR9QcLcyKiDtTO0uIVtb3YBwtBfSq/dunnHgqFTItys30tLy/X/ay/UdjZ2an7vaZpXQ0b6dV+e0G/cXZ9fb1pu0Kh0NXiVvqNv2ZTMtYegwsMEQ0WC3Miohqqqrbdq1o7pMUJnfbm6o9r9fjaJdkPzsxy7do1W8dsNVTFbH8HH2M1heDBgtouu/vVf9/quN30tlvtOxQKIZFIQNO0poV3KpXqeAy6pmkIBoM4d+4cSqUScrlcw1cmk0E6nW7rkw8i6qFBr3BEROQGlUpFRCIRAUCEQqG2V1qsVCpNV3Vs95j4dKXM2hUjm0kkEiIWi9WtSKrHHovFLFf4rD2evspkuVwWoVDIVuzlclnIsmy6wmY+nzfiw6crZpbL5YbnSN+HoijGeafTaZFKpWzFYhVbu/vVn0Or50xfSdRqJdPa1UGtrp/+XFkdI5FImG7Xr02nq8IKIRpypNkXEQ2WJIQQfXoPQETkSpIkGd/LslzXM1qpVFoOf8jlcsjn820NbQkGg20PGQmFQshms6bb2pmL3Ko3P5fLIZ1OQ1VVBAIBzM7OIpVK2R7moWkaVldXUSgUsLS0ZDx3wWAQsVisbt50/VwOHkNfrGlzcxNLS0sIBAKOrBTazn5nZmaMa1173fUpBK22BwIBFItFJJNJo5dbPy99uMzGxgYURcH8/LzpPiKRSMO11cd41+aHoigdXRtdJpNp+x4IWZYdXx2WiOxhYU5ERERE5AIcY05ERERE5AIszImIiIiIXICFORERERGRC7AwJyIiIiJyARbmREREREQuwMKciIiIiMgFWJgTEREREbkAC3MiIiIiIhdgYU5ERERE5AIszImIiIiIXICFORERERGRC7AwJyIiIiJyARbmREREREQuwMKciIiIiMgFWJgTEREREbkAC3MiIiIiIhcYH3QA1NrHH3+Md955By+88AKOHj066HCIiIiIqEuPHj3C7du38corr+Bzn/scABbmnvDOO+/g/Pnzgw6DiIiIiBx29epV/O7v/i4AFuae8MILLwDYv3ALCws9O87W1hbOnz/f8+MM8pjVahXvvXcTsdgyvve97+FLX/pSz48JjMZzOyrHZA7xmN1iDg3fMQdxXOaR94+pH0Ov8wAW5p6gD19ZWFhAIBDo+fH6dZxBHLNareLBg4cAgC9+8YtDe548Zu8wh3jMbjGHhveY/Twu82h4jlk7TJk3fxIRERERuQALcyIiIiIiF2BhTkRERETkAizMiYiIiIhcgIU5EREREZELsDAnw9zcHC5cuIC5ubmhPubY+FjfjqUbled2VI7JHOIxu8UcGq5jDuq4zKPhOiYASEII0dcjkm2lUgnBYBDFYnEgUz8NGz6f1C3mEHWLOUROYB55m9n1Y485EREREZELsDAnIiIiInIBFuY0UqrVKh49emR8T2QXc4i6xRwiJzCPhhMLcxo5u7t7gw6BPI45RN1iDpETmEfDZ3zQARD128mTJ5FMvtn3O61peDCH3KlareL+/fu4e/cunj59ir099xYt09Mn8Od//ueYmJjAT3/600GHQx7FPOq/sbExHD58GCdOnMDx48fh8znbx83CnEbOyZMnsbKygqmp44MOhTyKOeQ+9+7dwy9+8Qt4YaIxIQQOHTqE+fl5SJKE3d3dQYdEHsQ8Gozd3V08efIE9+7dgyRJeP755zE1NeXY/lmYe8jW1pbltrm5OfbeEdFIMivKJUnC2Fj/53hulx6rJEkDjoS8jHnUf3t7e8bzLoTAL37xi6bF+fb2Nra3t023mdV1LMw95Pz585bbLly4gIsXL/YvGCIiF6hWq3VF+fHjxzE7O4vJyUnXFitCCOzt7d+sNzbmc22c5G7Mo8EQQuDhw4fY2dnB/fv3jeL8V3/1V02HtaTTaVy6dKnt/bMw95CrV69iYWHBdBt7y4loFOl/GIH9ovxv/+2/zQKFiHpGkiQcO3YMk5OT+PnPf268Bt2/fx8nTpxoaB+Px3HmzBnTfW1tbTV0urIw95CFhQWu7EVEVOPu3bvG97OzsyzKiagvJEnC7Ows7t+/D2D/tcisMLc71JiFOY0USZJweOKw8T2RXcwhd3n69CmA/WsxOTk54Gja5/Mxd6h7zKPB0ofMCSGM16JusTCnkSJJEo4eOTLoMMjDmEPuok+JODY25pk3SpIkeSZWci/m0eDpN5nv7u46Nj0rFxgiIiIiInIBFuZERERERC7AoSw0UqrVKh48eAAAOHbsmOMrdtHwYw5Rt4QQqFb3p7nz+TjNHXWGeTScWJjTyKlW3b8yILkbc4i65YEFSskDmEfDh4U5ERGNjO2f/ZVjN2l1TAjs7e1XVGNjEtCnns6xsTHM/crf6MuxiKgzLMyJiGhk7O3t4dH9x3j6xJmpzTohBA4MQej9MQ9PHMbR45xNiMjtWJgTEdFIefrkKR7ceQjf2GDuDxBCoPrpGARfH6a8q+5VgWn0vDA3Ow9ZllEsFqEoiuljcrkcotGo0VanaRpCoRDy+TwAoFAoIJlMOhLnlStXjMX6ZmZmoGlay8coimJ8xeNxLvZHPcPCnIiIRo5vzIe/8fznBnJsIQT2Pu0xH+vDTXt/9YuPe7p/nfj0zYamaZifn4emadA0DdFoFMVi0fQxkUgEQggUCgXE43GoqopUKoVYLFZXqJdKJZRKJSiKgmQyiaWlpbrtyWQSuVwOABCLxeqKeFVVUSqVkE6noaoqVFU1CutKpWK08fv9APbfINy6davhjUKhUMC1a9cQDAYRCoWQTqct33AQdYrTCRAREZFjZFnG7OwsUqkUgP2iem1treljQqEQUqkUQqEQEolEXVEMAJ988gkURUG5XEYsFkMgEKjrxQ6Hw0bbcDhct03fZ7FYhCzLUFW14fh6W/37g8eXZRmRSATZbBaJRAKFQgHBYNB0X0TdYGFOREREjkskEkbPdDKZbFnEmhXEOk3T2h7KYrUPWZaxsrKCTz75xNbjDkqlUpBlGZqmIRgMtvUYonaxMKeRIkkSJiePYnLyKOd8pY4wh8gJPkmCbwTyJ5vNGt/rY8k7oaoqQqFQ1/GEQqG2xpS3srS0BGD/DUMmk+l6f53y+ST4fMOfR6OEhTmNFEmScOjQIRw6dIhFFXWEOUTdkiQJPp9vJBaFURTF1pAWKzs7O46M51YUxZHhJ7WxOFHod2KU8miUsDAnIiKinrE7pKWXZFnGzs5O1/upPQfO0EJO4qwsHrK1tWW5bW5uDnNzc32MxpuEEMbMAVIfpimj4cMcom6JA8s1jkIOZbNZY9aTZrO0WLHbvpf70mdoAfaLcieG2HRiFPPIi7a3t7G9vW26zayuY2HuIefPn7fcduHCBVy8eLF/wXiUEAL37t0HAExNHecLGdnGHCIn1E6XOAr0IS3JZNIY0pJIJAYdVkf0m1AVRcHGxsZAY9nb+zSPBjQnP7WWTqdx6dKlttuzMPeQq1evYmFhwXQbe8uJiMjNEokErl27hlKphGQyiUgk4pl5wDVNw+bmJlKpFDY3N5FIJIyx80TNxONxnDlzxnTb1tZWQ6crC3MPWVhY4Fg2IiLyrG6HtPSDqqp1M8hommYsTBQKhYxFiYjaYXeoMT/7ICIior5QFAXpdBoAjJ5zt1EUBdls1vjK5/Mol8soFovY3NzEzMyMscookdNYmBMREVHf6Ct3AsDa2hpKpdKAI2pPIBDAxsYGNE1DNBo1bgAlchILcyIiIuorpxYe6rdAIGCMi3djbz95HwtzIiIi6qvaIS2qqnqqyNULc6/09JO3sDAnIiKivovFYsYc4Gtra9jc3BxwRPaxOCensTCnkSJJEqamjnP+aeoYc4icMObzjcwc5s3ovebA/rRyXiDLsvH9oN9MjI35OIf5kOHVpJEiSRJ8Ph98Ph+LKuoIc4i6pa8Yy5Vj64e0eMXs7KzxfblcrtuWy+Wgqmpf4mAeDScW5kREROQoVVWhaVpbbWuHtDih3eNaPa7V48PhsPH9wZlZrl271tGxiXQszGmkCCHw7NkzPHv2DEKIQYdDHsQcom4JIVCtVlGtVocuh/SpBIH92Vba7T2unaWlk2Pm83nj53w+33ZxnkwmEY/HEQwGjVhVVUU4HEY8Hje9KTUSiSASiQDYH2OujzPX34z0azXTYc6jUcaVP2mkCCHw8OEjAOAYYeoIc2g4VPeq+KtffDyQYwshUP20kPL1YRhCda/a0/3ras9DlmUUCgVjlc9KpVI3NvsgWZaNxXzaUVtI1+4DANbX17G+vm78PhQKWRb+eu+33Skbs9kscrkc0uk0otEoAoEAZmdnu3qD0YlqdT+Pxsb4OjQsWJgTEdFIOTxxGJge3PGFAKrV/WJ5/16F3h/z8MThnh+j217b2p7oVorFYlfH0nUzhMZOvETtYmFOREQjY2xsDEePH8HR40cGF4QQ2Nur6ens06cuY2NjfTkOEXWOhTkREY2MuV/5G4MOAUII7H06vGRsjLP7ENFnePMnEREREZELsDAnIiIiInIBDmXxkK2tLcttc3NzmJub62M0RERERNTM9vY2tre3TbeZ1XUszD3k/PnzltsuXLiAixcv9i8YD/P5OJ6TusMcom5xWDk5gXnkful0GpcuXWq7PQtzD7l69SoWFhZMt7G3vD0+nw9TU1ODDoM8jDlE3ZIkiTOkUNeYR94Qj8dx5swZ021bW1sNna4szD1kYWEBgUBg0GEQERERURvsDjXmzZ9ERERERC7AHnMaKUIIPH7yBABwZGKC8weTbcwh6pYQwlglU5Ik5hB1hHk0nNhjTiNFCIGnT57i6ZOnXS8fTaOJOUROqFYFqlXmD3WHeTR8WJgTEREREbkAC3MiIiIiIhdgYU5ERERE5AIszImIiIiIXMCTs7KoqopUKgVVVSHLMjRNg6IoSCaTUBSlJ8f0+/3IZrNN5xEfRFxERERENBw812NeKBQQDAbh9/uRz+eRzWaRz+cRDofh9/uRyWQcP2Y8HoeqqtjZ2XFVXEREREQ0PDxVmGuahnA4jLNnzyKRSNRti0QiSKVSiMfjKJVKjh2zUCi0LKoHERd17tChcRw65MkPi8glmEPULUna/yLqBvNo+HiqMF9eXgYAJJNJ0+2xWAwAEI1GHTtmKpWCLMuui4s64/P5MDk5icnJSfh8nkp/cgnmEHVLkiSMjY1hbGyMi8JQx5hHw8kzf1U0TUMulwMAy/HasiwjEAhAVVVHeqfj8ThSqZTr4iIiIiKi4eOZwnx9fR2AdfGrm52dBQBcu3atq+PlcjmjoHZTXERERG7k9/uNpeFrvzrpkMrlcqb74ifPzpiZmTF9fs2+ZmZmEA6HkUwmoWnaoEMfep4pzIvFIgC0HFaiF8jd9ExrmoZ0Ot2yt7zfcVH3qtUq7j94gPsPHqBarQ46HPIg5hB1SwiBvb097O3tQYjhWU69XC5DCIFyuQxZlo2/e6urq7b3de3aNePvaiAQQKVSgRAC2WzWyZA9rZs80p/Pcrls/E6WZQghGr5u3bqFaDSKTCaDmZkZy2G73SiVSpiZmUEwGBz54t8zhbk+I4re89yKqqodH2t5ebmtorzfcZEz9nb3sLe7N+gwyMOYQ9QtIfa/hpGiKFAUBfF4HACM4Z7tUlUVp06dMv6uLi0ttez86pdcLueqv+Pd5pF+rfTvzciyjFgshlu3bkGWZaytrRnX1imrq6vQNA2lUskYidArbruGB3mmMLf7DqrZ1IbN5HI5nDp1quUQFl2/4gL2e+qsvmrfLQshmrY92Mtnt32rtgffudtp304s3Z6r/uWFcx3l6+Tmcz2YQ16KfVivkx5Psy87bZ1uf+fBY/ynD/8KN97/BbZ+9te4+/CxrX0fvE5uPlchBGZnZ/Hqq68abfTZzdrZdzqdNiZNcNN1FULg+vXrRm/zoK/Tp4/69Mv88e3s3+xNj1m76elpvPnmm8b1rJ2xrttzPXv2rLHt9OnTXV+nZl/6NXQqdv13ADp63TvIM/N9tVvQ6gnWyUch+hCWfD7vqrh07713Ew8ePDTddvToEYyP71/O3d1dPHq0/6J/8uRJnDx5sqH99PQJ4/unT5/i8eMnlscdGx/D8WPHjJ8fP36MZ892LdsfnjiMo0eOGD8/ePAA1ar1W/rJyaM4dOgQgP3kvnfvvmVbAJiaOm7cgb67u4uHDx9ZtvX5JExNTRk/P3nyFE+ePt3/4T4a7mQ/dGgck5OTxs8PHz1q2jN65MgEJiYmjJ9bxX7s2KRxnfb29iyvp25Ur9PjJ0/w9MlTy/aDvE5CiIYc4nUy14/rVGtvr/nQovHxMeN7IUTT51GSgLGxz9rvvxGw3rfPJ9W9nuz/0RX40V/8DFf+lxL+1f/+E+zVHG/MJ+G3/8tfRey/DuLv/8bnm8YCAGNjn/Wj2Y291+dq9rzvF3IyXnttGd/5zpW6YrvVddIX6ftsX9aPceI62Wm/uVnEa69VLePp/3Xab7+3tweg/u9ZO9dp/7jmxzNr/5WvvGx8X3tNu82x3/mdr+Gv//pj47oLIbq6Ts1ybHOziNoO/26vk16gP3jwAD/60b/B+PgYjh49amxv9rr3k5/8pOF3ninM+2F5eRnpdHrQYViKxZZtPyaZfBMrKys9iIaIiKzcLH+E2P/3X2HrZx+bbt+rCvyP/+4v8T/+u7/Ewq98Dun/53+Nl/yNnShet7y8X5iXSiWoqor5+fmm7b///e/j3LlzfYrOHk3T8N57o32fWO0bJqeHg/RjuFIvr+HPf/5z/PZv/3bX+/FMYd7uGG69R9ruBc5kMgiHwy1nV+l3XLW+973v4Ytf/KLpNv3uaQB1H6/Mzc1haup40/0ePnzY6GFrx5EjR1DTgWcaS61jNb2DrdpLktQy3tr24+PjLdvXmpg4jKdPDwMAjh8/1nIe6smad72tYgFgK/axsTFbsY/SdToyMYGJw4fbbt/P61StVoFPO3LNcojXyVovrxNQ31vZyv4c0O3P/WxnzvqN91T8t/99Dg8eP2ur/dbPPsY//Naf4n/4f0VwerF54QrYj72X5wqYP+/7x/Th1KklKIoCVVWRTqdx+fLlptcpl8s23OC532PZXkx2Y7fTXr/pcWzM11Y8/bhO+t/62h5dK1YxW02Bbtb+3r27xve19U+vc8yJnASAb32rsaOy2+uk11+f//zncePGjYZ4zYar6N5//318/etfr/udZwpzuwVtuwUzsP+uL5vN2hrCoutlXAd96Utfanvsux21RX07evkPym4s3bT3+XwtY/PyuXo5drefa7Mccnvsg2zf6z/GdmPvxb7f+2DbVlGue/D4Gf7R/yeH66mvY/ELc47EMuj2en7E43Ekk0lkMpmmEytommbaOWYnz3p1rmtra7hy5YqteHr9vH/6qLYf78S/j42NDeP72htA3ZSTVm0PXkMnY5EkCUeOHMFv/MZv2NqX2WucZ27+1AvaVmO69e12CuZ4PN7xFEy9jIuIiLxDCIHlf/rntoty3YPHzxD7p39ucZOfd+njkGsX5DOTyWQ6HsaSy+UQDocRDocRjUYRjUZNp/XTNA3hcBjBYNCYd13TNGiahmg0inA4DL/fb8RZKBTg9/vr9hUMBuvm+W42Q4mqqohGowgGg8Zxo9EoCoWCafva2GZmZowplvVP9aPRKPx+P8Lh8ECmX9aH+0YiESQSCdM2ds85Ho/XnfPBHOn2Oen2GvabZwrzYDAIoPWYJn17KBRqa7+qqqJQKGB+fh4zMzOmX/owlHA4bPxOT7BexUW9sf+udgJHjkx02DtBo445RFb+1//wIf7Th3/d1T7+44d/jR/9xc8cisgdZFk2/vY1u4/rxo0btj8V1gttfZrjfD6PbHZ/OIxekNX+fZZlGclkEufOnTN+v7Ozg2g0iitXriAajRqFJbD/N1ufn13vzS8Wi3Wzclid09raGoLBIOLxOIrFIvL5PIrFIlZWVhCNRk2LwWQyiXg8DlVVoWkadnZ2EI/HMTs7a5xbuVzGzs4OlpaWcPPme/D5ev86VCqVEAwGoaoqYrGYZWdmJ+es/14/54PsPCfBYLChOO/mGg6CZwpzfSqdVrOa1BbR7VAUBUIIVCoVyy9dPp83fqe/yPQqLuoNSZIwMbE/8wOLKuoEc4isZP7noqv24yZ6QVYoFEz/XpZKpY7+Puo9sdlstqGo39jYqCuydaFQCIlEwijSkskk0ul03aJI3XaiJZNJJJNJbGxsNOwrEAigWCwaPb4HY4vFYnVvZMLhMCKRSF07fVKHVCoFn8/nyGuRXnzXfvn9fvj9fiwvL2NpaQnlctmyiO32nA+e48Ht7T4nnSxo5SaeKcxr33FbfRyiqipUVYWiKJb/qJxeUcqpuIiIyLvuPnyCf/m//aUj+/qf/t37uPvQespNL4pEIsZQztr5r3XpdLpuLut2ZDIZFAoFhEIh07+t+t/nUqlk+ve5dmhpbUEuhOjonjNdqVTC2toaAoGA5ScAiqIgEomgUCiYPh96bKqqmhasvVhNXJZlFIvFuq9yuYxyuYxisYh0Om05QYYT59zqHrxBPCeD4JnCHPjsIzCrd2uttuvDUMwSwko7hXy3cRERkbf94uO7dfOUd2OvKvCfP77nyL7cRB9rbvW30O49WPp+mg1/0XtnmxVrTn+Svby8P7Vxq444fTx9syXul5aWmu6jm0ULneTkObfileekU54qzBVFQT6fRy6Xw9raWt02/XfpdNo0MWo/PrNzo+fm5qbxvdU76G7iov6qVqu4c+cu7ty523QKIyIrzCEyc/+R9UJLnbj3aLh6zIHPhrOoqlpXKGcymYbhJu3Q91EoFBCPx02/rl27BgD45JNPLPdjd5rkduPy+/1N29UuPGh1n1qrfQDA7u7ewG8YdvKcW2nnOfEyz0yXqNMH8adSKQSDQSiKAk3TjI9grN456x91qara1ju12ps+9URaW1vD2toaZFnGxsZG3bE6jYuIiLzv+NH253Nvx9TRidaNPEZRFAQCAZRKJaTTaaPHW7+Bz47aT7Pj8bjRG9+JbqYxPshOsVl7XH2460FemMnN6XNuxQvPSTc8V5gD+/+4OxkWYmfMWO1Nn+3qNC4iIvK25z93AmM+yZHhLONjPvytz005EJX76D3ZmUwG6XTakeLM6XvH7MpkMsYbAztFfu2QCyffHPTbMJxz7TUcNE8NZSEiInKjE5MTOPN3f82RfZ35u7+GE5PD12MOoK740YvzTueQ1j+JLpfLjsTWqXw+X/cJu/5Go1VctT3NXv5UfRjOufYaDhoLcyIiIgfE/qugq/YzSM1uwNNn1OimxxyAsYro+vp603aFQqHh/q9O6L30B89NH7Z6MK5miykBn32Kb7VQj5d45ZzbvYaDxMKciIjIAX//Nz+PL33+l7rax69//pfwW7/xKw5FNDjNbu7Te8hLpVLTlT5bza6hz0euaVrTwjuVSjkyTEF/A3HwvA7GGYlEEIlEjAUMzZRKJeRyOQQCAaOoNdOPXlwnjuHEOevPY6vr3k287V7DQWJhTkRE5ABJknDlH/82jh051NHjjx05hMw//m1PL1ylaRqSySRUVcXy8rLpNIWhUAiKokCWZctFZWpXgdzc3LQsxlKpFBKJhLG4zcF9hMNhJJPJht7Q2jcOVoWk2bFkWUYqlTLiyWQypm8ustksYrEYotFoQy9yoVBAMBhEJBLBxsaG6bH0581qaIg+Y5ymaV0Vqvo6K/q+Op0pBej+nPVjW52zE8+JnWs4KJIY9Bw71JK+Ghdnd+letVrFvXv3AQBTU8fh8/G9KdnDHHKXn/70p9jd3cX4+DhefPHFQYcDANh4T8V/+9/n8ODxs7Yfc+zIIfyL/3cEpxednbqvn/x+v1FcybJcVxwd/PuVyWSMmcxqzczMND1GKBQyncFFn+mltrBUFMUoxHSqqiIYDNaNCa/9vlgsNh1aUyqVkEwmsbm5iaWlpZY93npcetE4OzsLWZYRj8dNp1A+OCOc/r2+cmYymTQ+HaidetBstrhm/H5/y17iTibBAJw7Z/1Nl9PPid1r2Eo3r0Fm9R0Lcw9gYe4cIQT29vYAAGNjY57umaLBYA65ixsLcwB474NtLP/TP8d/+vCvW7b99c//EjL/+Lex+IW5PkRGw+Jg+cbXosFwujD35HSJRJ2SJAnj40x76hxziNqx+IU53Pj/LeNHf/EzpP/VJv7l//aXdVMpjo/5cObv/hpi/1UQv/Ubv8Kiimxjzgwn/nXxkK2tLcttc3NzmJtjbwsRkVtIkoS//5ufx9//zc/j7sMn+M8f38O9R08wdXQCf+tzU0M7JSIRfWZ7exvb29um28zquqaF+d27d1EoFHDjxg0AwKlTp/C1r33NtO2tW7eQyWRw6tQpKIqCl156yWbo1Mr58+ctt124cAEXL17sXzAexWEI1C3mEHXixOQETvzKfiGuD0HQ/88cok5wKIs3pNNpXLp0qe32loX5lStX8Prrrzf8fmZmBleuXMHv/M7v1P1+fn4eZ8+eRaFQQCKRwK1btzAzM4OPP/7YRvjUzNWrV7GwsGC6jb3l7RFC4MGDhwD2b9zjCxnZxRwiJ+ztVQEAY2O8eZg6xzxyv3g8jjNnzphu29raauh0NS3MV1ZWsLa21vBuDNif6zESiWBtbQ3/5J/8k7pti4uLWFxcxPT0NF5//fWO7+glcwsLC7z5k4iIiMgj7A41bniLdevWLaRSKQghEIlEkM1mUS6XUSwWkU6nEQqFIIRAIpHAt771LdOdPvfcc52fARERERHRCGroMdfnciyVSg3jxBcXF40FA6LRKFKpFJ577rmGnnMiIiIiIrKnocd8c3MTmUym6c2bgUAA5XIZr732GhKJBP7sz/6slzESEREREQ29hsL8vffew9mzZ9t6cDqdxrVr1xCJRPDDH/7Q8eCIiIiIiEZFQ2E+Pz+PEydOtL2DSCSCd955B5FIBD/+8Y8dDY6IiIiIaFQ0FOaBQAA3b960tZNQKIR8Po9IJIIPP/zQqdiIiIiIiEZGQ2Eej8eRTCaNn2/evIk33nij5TjyQCCAd955B6+++ipu3brlfKREDvD5fJiePoHp6RPw+TjvK9nHHKJuSZKE8fExjI9zgSrqHPNoODX8VTl9+jReeuklvPHGGwD2h6pkMhlEo1HcvXu36c4URUGhUMDbb7/dm2iJiIhqjI2NAQD29vZM194gIuqVgytBO8G0uyeVSmFxcRGzs7NQVRVCCFSr1bZ2KMsyNjc3sbi46EiAREREVg4fPgxg/w/kw4cPBxwNEY2Shw8fGh0C+mtRtyw/h43FYrh16xby+TzS6TTK5XLbN4XKsoxisciec3IdIQSePHmCJ0+esHeNOsIccpfav0s7OzueuCZ6Z1e1WvVEvOROzKPBEkJgZ2fH+NnOxCnNNCwwVGt6ehqnT5/G6dOnO9r58vJyR48j6hUhBB4/fgIAOHToEMflkW3MIXc5fvw4JEmCEAL379/Hz3/+c8zOzmJyctLV16Za3S+kxsbcGyO5H/Oo//RP53Z2dnD//n0A++P9jx8/7sj+mxbmREREbubz+fD888/jF7/4hVGc379/H5IkOTbmsxf0Hk43v3kg92Me9d/B+1kkScLzzz/v2GQALMyJiMjTpqam6opzYL9g2d3dHXBk5oQQdQUViyrqBPNo8PSifGpqyrF9sjAnIiLPm5qawq/+6q/i/v37uHv3Lp4+fWrMluBG+puG8XH+GabOMY/6b2xsDIcPH8aJEydw/Phxx6fN5ZUkIqKh4PP5cOLECcduwuqVarWKe/f2x6ZOTTn/h51GA/NoOLEw95CtrS3LbXNzc5ibm+tjNERERETUzPb2Nra3t023mdV1LMw95Pz585bbLly4gIsXL/YvGCIiIiJqKp1O49KlS223Z2HuIVevXsXCwoLpNvaWt29s3L0zNZA3MIeoW8whcgLzyP3i8TjOnDljum1ra6uh05WFuYcsLCwgEAgMOgxP8/l8OH7s2KDDIA9jDlG3mEPkBOaRN9gdasw7BYiIiIiIXICFORERERGRC3AoC42UarWKx48fAwCOHDnC6aXINuYQdYs5RE5gHg2nnl7Fmzdv9nL3RB159mwXz565c0VA8gbmEHWLOUROYB4Nn54W5qdPn+7l7omIiIiIhkbPCvM7d+6gUqn0avdEREREREPF9hjzmzdvYnV1FaVSCTs7O5btNE3DzMxMV8EREREREY0KW4X5e++9h2Aw2KtYiIiIiIhGlq3CPJlMIhAIYGVlBYqiNG1748YNvPHGG10FR0REREQ0KmwV5qqq4oMPPmir7eLiIl5//fWOgiIiIiIiGjW2CnO7y8EnEglb7Yl6TZIkHJ44bHxPZBdziLrFHCInMI+Gk63CXNM0Wzu/fPmyrfZEvSZJEo4eOTLoMMjDmEPULeYQOYF5NJxsTZcYjUbxgx/8oO32p06dsh0QEREREdEoslWYLy8v4/r1620X56VSqaOgiIiIiIhGja2hLDdv3kQ0GkUmk8Hq6iqWlpbg9/shy3JdO03TUC6XnYyTyBHVahUPHjwAABw7dgw+X08Xv6UhxByibjGHyAnMo+FkqzB/+eWXcefOHQCAEKJlj/jBgp3IDapVMegQyOOYQ9Qt5hA5gXk0fGwV5rOzs9A0DaFQqGXRXSwWcfv27S5Co4O2trYst83NzWFubq6P0RARERFRM9vb29je3jbdZlbX2SrMZVlGJpPBa6+91lb7sbExO7unFs6fP2+57cKFC7h48WL/giEiIiKiptLpNC5dutR2e9s95q1W/Kw1PT1tZ/fUwtWrV7GwsGC6jb3lRERERO4Sj8dx5swZ021bW1sNna62CvPr16/bCmZnZ8dWe2puYWHB9iJPRERERDQYdoca2yrMzdy+fRuqqmJ2dhYvvfRSt7sjIiIiIhpJHc+t853vfAfPPfcc/H4/wuEwgsEgxsbG8K1vfcvJ+IiIiIiIRkJHPeavvPIKCoUChGicpieVSqFQKKBQKODEiRNdB0jkJEmSMDl51PieyC7mEHWLOUROYB4NJ9uF+RtvvIF8Po9IJIJz585BlmXMzs5iZ2cHqqri+vXr+P73v49YLIZ/8S/+RS9iJuqYJEk4dOjQoMMgD2MOUbeYQ+QE5tFwslWYb2xs4Nq1ayiXy5ifn2/Yfvr0aSwvL6NUKmFpaQnxeBxf+cpXHAuWiIiIiGhY2RpjnslksLGxYVqU1woEArh+/TrefvvtroIjcpoQAtVqFdVq1XQoFlErzCHqFnOInMA8Gk62CvNyuYzFxcW22oZCIWia1klMRD0jhMC9e/dx7959vpBRR5hD1C3mEDmBeTScbBXmzz33nK2dcx5zIiIiIqL22CrM7RbafAdHRERERNQeW4X5/Pw8fvjDH7bV9gc/+AGWlpY6CoqIiIiIaNTYmpXl8uXLOHXqFN599118+ctftmy3sbGB5eVlbGxsdB0gEREREdEosFWYK4qCZDKJQCCAYDCI06dPw+/3G9vL5TJyuRxUVcXy8jJeeuklp+MlIiIiIhpKthcYSiQS+OSTT/Dtb38bxWKxYbsQApFIhFMlEhERERHZYGuMuS6VSmFzcxMvvfQShBDG1/z8PLLZLNbX152Ok4iIiIhoqNnuMdcFAgGjx/zWrVuYnZ3F9PS0Y4ER9YIkSZiaOm58T2QXc4i6xRwiJzCPhlPHhXktq5VA33rrLXzjG99w4hAEYGtry3Lb3Nwc5ubm+hiNN0mSxBcw6gpziLrFHCInMI+8YXt7G9vb26bbzOo6SfRwsvGxsTHs7e31avcjo1QqIRgMNm1z4cIFXLx4sT8BEREREVFLFy9exKVLl5q2KRaLCAQCAEx6zO/evYv19XWEQiG88MILddt+8IMftBXEzs4OyuVymyFTu65evYqFhQXTbewtb48QAru7uwCA8fFx9jaQbcwh6hZziJzAPPKGeDyOM2fOmG7b2trC+fPn637XUJifPn0apVIJkiQZF1z32muv4c6dO20HI8ty222ptYWFBeMdFXVGCIGHDx8BAKamjvOFjGxjDlG3mEPkBOaRN9gdatxQmH/wwQfQR7fcvXsXJ06cMLbNzs5C0zREIhHMzs5a7lTvMb9586aN0ImIiIiIRldDYb6xsYHLly/j3LlzdUU5sN8Dnslk8Nprr7W187GxMWeiJCIiIiIacg2FeSAQsJyHfGlpCYqitL1zTp9IRERERNQeW9Ml2l3Nc2dnx1Z7IiIiIqJR1dHKn0RERERE5Cxbhfnt27frvmq99dZbOHXqFF588UX8/u//Pu7evetknEREREREQ81WYR6JROD3+xEMBpFMJo3i+9y5c0gmkyiXyzh9+jQ+/vhjy9VAh1UwGEQ8HkehUICmaQAATdNQKpWQyWQQDodRKBQGGyQBAHw+CT4fp5WizjGHqFvMIXIC82j42BpjvrKygnw+XzfWfGNjA9lsFjMzM9jc3DQK8lwuh5WVFayurjobMQBVVZFKpaCqKmRZhqZpUBQFyWTS1s2pZkqlElZXV6FpmjFGXlEUrKysNJ1DXFVVowg3k0gkEAqFuoqNuufz+TA1NTXoMMjDmEPULeYQOYF5NJxs9ZgXCoWGG0DT6TQkSUIsFqvrJY9EIlBV1ZkoD8QQDAbh9/uRz+eRzWaRz+cRDofh9/stC+N2rK2tYXV1FalUCvl8HsViERsbG1BV1fiUwC5FUZDNZpFKpTqOi4iIiIiGn60ec33hoVr68Ixz5845E1ETmqYhHA4jFoshkUjUbYtEIkilUojH41haWrK9QmYul8ONGzeQzWbrfi/LMrLZLPx+P9bW1uD3+xGLxUz3kc/noaoqyuUyTp06BUVRuFInEREREbXFVmF+0K1bt6BpGiRJwksvveRQSNaWl5cBwLLnOhaLIZlMIhqNolwu29p3Op1GoVBAOBxGPp+v26YoijFkJp1OWxbmHKrifkIIPH7yBABwZGKCSxiTbcwh6hZziJzAPBpOtoayzMzM1P2s95ZbjeuuVCodhtVI0zTkcrmmx5NlGYFAwBjvbYc+7Kb25s1a+jHt7pfcRQiBp0+e4umTp6afABG1whyibjGHyAnMo+FkqzCvVCr48MMPjZ/18eXxeLyh7crKiunvO6WvRtrq5s7Z2VkAwLVr12ztP5lMQpZlxGIxyLLcsF0v1ru9uZSIiIiIyIytoSyXL1/G0tISotEoSqUSSqUSZmZm6oZ23Lx5E8lkEpubm/jWt77lWKDFYhEATIvmWp32bMdiMcshKqqqGj3qrd5saJqG9fV1I95wOIxIJGIrFiIiIiIaPbYKc1mWsb6+jlgshlKphFAohHQ6jRMnTgAAvvCFL9TNxBIIBPDTn/7UkUD1qQv1HvFWnJwRRp9RJRQKNdx0WiuTySCfz2NlZQVnz57Fzs4O4vE4VldXsbGx0fJNRSvVahXVatV0myRJxvgyIUTLj7V8vs8+LLHb3ioGs1jstm8nFqfO1SouN50rr1N77ft5rtVqtSGHvBK7E+29fK5uiV3PIV6n1rF4LfZ+n2uzv2e8Ts6179W5mm2zffNnIBDA5uam6bYPPvjA7u7aZjbuuxm9kO9GqVRCOp3G+vo6UqlU06IcAMrlct2sLvqMLvPz85ifn8etW7e6Ks7fe+8mHjx4aLrt6NEjGB/fv5y7u7t49OgxAODkyZM4efJkQ/vp6RPG90+fPsXjx08sjzs2Pobjx44ZPz9+/BjPnu1atj88cRhHjxwxfn7w4AGqVesknpw8ikOHDgHYT/h79+5btgWAqanjxj+o3d1dPHz4yLKtzyfVzfP65MlTPHn6dP+H+2i4WebQoXFMTk4aPz989Ah7u3uW+z9yZAITExPGz61iP3Zs0rhOe3t7ltdTN6rX6fGTJ3j65Kll+0FeJyFEQw7xOpnjvyfz6ySEQLVaxdjYmPEzr9Nn3HKdAHf/e3r06HHTv2e8TtZ6cZ0++ugjfPTRRxgfH8PRo0eN3zf79/STn/yk4XddzcrSys2bNx2braXdQlsvfO0W8rXi8ThUVcXOzg5KpRISiUTL4SipVMp0KIw+br12jvROxWLLth+TTL6JlZWVjo9JRERERM1997vfRSp1uev9SKKHt/I+99xz+OSTTxzZVzAYNIbPHJzOsFYymcTa2hoA83nXOxGNRpHL5RCJRBrmOW+HPg0jsH8Drd1e81KphGAwiO9973v44he/aNrG6mOZubk5zM3NNbQf1Y+g9vb2jHfSx48fq9tm1n7Q5zqq18nN51qtVnH//gMAn+WQV2J3or2Xz9Utses5JEmS0XPH62Qei9di7+e57u7uNrwWWcUC8Dp1076dc93e3sb29nZD+2axv//++/j617+OYrForHvTsx7zO3fuODpdYrtjy/We8m7Hc9fSFxjK5XIIBoPGjZ3tqp3JpVAodHwz6Je+9KWeLFh08B9AK2bFrFPt7cbSSfvDhw8ZcbWKzcvn6uXY3X6uzXLI7bEPsr2Xz9Xp2PUc6iQWr51rN7GMUuydnGuv/p7xOtlv//zzz+P5559vez+A+XnZe2awPzzl3LlzePHFF/Hcc89Zfs3OzjbMe94Nu4V2u4V8u/TZWEqlktEj30ksTt6USvb5fD5MTk5icnLS9gsDEcAcou4xh8gJzKPhZKvH/L333kMwGOxVLE3pxW2rseb6druFvL54kVVvdm2vdz6fN24EVVUV4XAYsiy3NfOK3RVJiYiIiGg02CrMk8kkAoEAVlZWWi60c+PGDbzxxhtdBVdLf0PQqsdZ3x4Khdred+24dKvZV2oL7to3B4VCwTimPpVkM04OsSEiIiKi4WGrMFdVte0pERcXF/H66693FJSZs2fPIh6Pt5xtRd+u32zZjtpi36pHu/a4S0tLxvd6T34gEMDZs2dNH1s7vaSduMh51WoVDx/tT4s0efQoP/4j25hD1C3mEDmBeTScbF1Fuzcetpr32w5Zlo1e8EKhYNpGX6FTURTLHnOzwl4vlkOhEJLJpOnjameCiUajxvehUAihUAjFYtGyN1x/bCAQsNWTT72xt7vXdI5eolaYQ9Qt5hA5gXk0fGwV5nbnBr98ufv5HGul0+m6/9vdPjMzg5mZGWQymbrfnz17FoqiIJlMmg7R0TTNeEwsFqsrrmVZRjgcbtinTlVVY1snUy0SERER0WiwVZhHo1H84Ac/aLv9qVOnbAfUjKIoyOfzyOVyDTOj6L9Lp9OmvdKFQsF4Y3GwQJZlGfl8HvF4HMlksm5oi6qqOH36NID9otys6E8kEsbja9+86POPz87OolgsthyXT0RERESjy9YY8+XlZWPc+Ne+9rWW7UulUmdRNREKhVAul5FKpRAMBqEoCjRNgyzLdRO0mz0uFApBVVXT4SqKoqBcLiOXyyEej2NnZ8fY79LSEq5cudJ0KE82m0Uul8Py8rJx3oqiYGVlxdEhPUREREQ0nGyt/Hnz5k188sknyGQyUFUVS0tL8Pv9DWOrNU1DuVxGJpPB3h7HPnVL73lv9saD2lOtVo2VP6emjvNmGbKNOUTdYg6RE5hH3mdW39nqMX/55Zdx584dAPtLkrbqEefUgERERERE7bFVmM/OzkLTNIRCoZZFd7FYxO3bt7sIjYiIiIhodNgqzGVZRiaTwWuvvdZW+7GxsY6CIuoVSZJw5MiE8T2RXcwh6hZziJzAPBpOtnvM7cwsMj09bTsgol6SJAkTExODDoM8jDlE3WIOkROYR8PJVmF+/fp1WzuvXbqeiIiIiIis8RZeIiIiIiIX6Lgwf/fdd/HWW29hZWWl7vdvvfUW7t6923VgRL1QrVZx585d3LlzF9VqddDhkAcxh6hbzCFyAvNoONkaygIAt2/fRjQaRalUghACkiRhdXXV2L64uIhIJIKVlRV85StfcTTYUbe1tWW5bW5uDnNzc32MhoiIiIia2d7exvb2tuk2s7rOdmGur54ZCoUQDodx7dq1uu2nT5/G6dOn8dWvfhXBYBAnTpywewiycP78ecttFy5cwMWLF/sXDBERERE1lU6ncenSpbbb2yrM33zzTciyjEqlYsy4Ui6XTdu+/fbbSCaT+JM/+RM7h6Amrl69ioWFBdNt7C0nol766P/4K+w+2wNqZmWTUD9FW92MbQemb5MsG9b/2Gzat4ZtTWORTNvVbjt2YhJHjnJWCyLqnXg8jjNnzphu29raauh0tVWY37p1C5ubm3W/s3oRVRQFqqra2T21sLCwYCzZSkTUT0IAjx89wZNHT4zf1b/8N59Hue2C26KIbnmEFvM4HzzGxMRhTBw5DLAwJ6IesjvU2PZQFiIiGj0+n4TdZ7t4cOchfOOfzhsgPtsuDj5ACLNvG1s3bGvuwZNn+Ov7j/Ho6R6OHh7DLx0/gmMTh+ztBMDf/OVfgmgMjIhooGwV5pqm2do5X/SIiIaDJEnwfdrr/LmTs/D5ejfbbt3fDrH/87//4CP883/7l9j4//8Me9XPto/5JJz+v/0K/tHf+zWc8v+Nz3rGxcF97v//yaMnuKfd598nInIlW4W5EAI//vGP8eUvf7nud2ZWVlbg9/u7i46IiFxBkiRjuEivi9raYSf/8eef4M0//RF++pFm2navKnD9P3yI6//hQ7x4Usbl3/0t/PovP2e572dPuXwHEbmXrVeoWCyGl19+GT/84Q+N35mNG/z2t7+NtbU1xOPx7iMkcpAkSTh2bBLHjk02HfNKZGVUc0jyScb5ij5Nmfxv//I/4+t/9K8ti/KDfvqRhq//0b/Gv/3L/2zZpvaSDarXfFRziJzFPBpOtnrMI5EI0um0MVXi4uIiNjc38Z3vfAeapqFcLmN9fR2apuGb3/wmXnrppR6FTdQZSZIwPs5bK6hzo5pDkiRB8vWnxxwA/uP/8Qn+4J+9i4dPd2097uHTXfzBP3sX3/uDf2jRc/7pOUCYjH3vj1HNIXIW82g42b6iuVwOkUgE169fRz6fB4C6nnEhBBKJBC5fvuxclERENFCSTzKmJOx1YS6EwJt/+iPbRbnu4dNdvPnPf4R/mfhv2JNIRJ5ie7Dd9PQ08vk83n77bSwuLkIIYXwtLi4in8+zKCfXEkJgd3cXu7u7vPmLOjKqOeSTJGMYSK/P+3//4KO2h69Y+em2hn//wUeNG/Q6XRj/6btRzSFyFvNoOHX8GUgsFkMsFgMA3Llzx1hwiMjNhBB48OAhAGBq6jh708i2Uc0hyde/oSz/w79535n9/Nu/xN95sX7+4IMLEQ3CqOYQOYt5NJwcuT3dqig/d+6cE7snIqIBkySpZirC3hXm9x8/ReEvfubIvvL/4UPcf/zUdNv+J72OHIaIyDE9nTcql8v1cvdERNQntYV5L3vMP9Ie1s1T3o29qsD/qT2s/2XtUBZW5kTkMh0NZbl9+zZUVW264NCNGzc6jYmIiFzGmC5R6u10iQ+fPHN0fw8c3h8RUS/ZLszPnTvXdk+4LMt2d09ERC7kkz79gFWSUO1hZT45ccjR/R07sL/6ecwdPRQRUddsFebf/va3kc1mIcsyFEXB7OysabudnZ2WPepEROQd+o2fkk/q6VCWk/IkxnySI8NZxn0S/qY8eeC3+nCc/bnMiYjcxFZhnk6nkc1m8eqrr7bVfmxsrKOgiIjIXfTC3IfeDmU5fuQwQr/xK3jnxx92va/Qb34ex48cdiAqIqL+sHXzpyzLbRflgPVsLURE5C2+T8eASFJve8wB4B/937/ozH7+3q81/O6zoSxiUNOYExFZstVjriiKrZ3funXLVntqbmtry3Lb3Nwc5ubmLLfTPp/Ph+npE4MOgzxsVHPIGMoy5ut5Yf53vnASL56Uu1pk6MU5Gf/FF06abPlskPmgFmUZ1RwiZzGPvGF7exvb29um28zqOluF+ezsLO7evYsTJ9pLhFu3buGll16ycwhq4vz585bbLly4gIsXL/YvGCIaKfpUiRKknt81KUkSLv/ub+Hrf/Sv8fDpru3HTx4ex+X/7reaLrjCznIi6od0Oo1Lly613d5WYZ5MJrG8vIxr16611f706dP45JNP7ByCmrh69SoWFhZMt7G3nIh6yegxl/rT0/zrv/wc/uj3XsYf/LN3bRXnk4fH8Ue/9zJ+/ZefM93+2RpJLM2JqPfi8TjOnDljum1ra6uh09VWYT4/P49kMolXXnkFb775Jr7yla9Ytr1z5w4qlYqd3VMLCwsLCAQCgw7D04QQePp0fyXAw4cPcwljsm1Uc8joMfdJqO718O7PGn/v1/4WvvcH/xBv/umP2hrW8uKcjMv/3W9ZFuVuMao5RM5iHnmD3aHGtucx3x/TNI1QKATAeq5yTdMwMzNjd/dEPSWEwOPHTwAAhw4d4gsZ2TaqOeTzfTaPeT87m3/9l5/Dv0z+N/j3H3yEf/5v3kfhL35WN5XiuE9C6Dc/j3/0934N/8UXTrZxPfQu88H1mo9qDpGzmEfDyVZh/t5772FpaanuxYy94kREo0GS9lf/FA7MMW73uH/nxTn8nRfncP/xU/yf2kM8ePIMxyYO4W/Kk7amRKwbysLRLETkMrbHmC8uLmJlZaXlDC03btzAG2+80VVwRETkHpJPgq8P0yU2c/zIYRw/ybnJiWg42SrMVVXFBx980FbbxcVFvP766x0FRURE7iNJEiSfx2+crPm039PnQURDydYCQ3ZvPEwkErbaExGRe+3PzDLYHvNuSbXzmHMsCxG5jK3CXNM0Wzu/fPmyrfZERORexhhzDxfmhmE4ByIaOrYK82g0ih/84Adttz916pTtgIiIyJ18Pmm/13yAM5p0rXbiCo+eAhENL1uF+fLyMq5fv952cV4qlToKiqiXxsbHMDY+NugwyMNGNYckaf/mT8DDhblLjGoOkbOYR8PH1s2fN2/eRDQaRSaTwerqKpaWluD3+xvmMtc0DeVy2ck4iRzh8/lw/NixQYdBHjbKOSRJkjHfoFcLc32MucDgzmGUc4icwzwaTrYK85dffhl37twBsP+C1qpH3GrxISIi8h5JH8oC7M9l7sWOutp5zImIXMZWYT47OwtN0xAKhVoW3cViEbdv3+4iNCIichMOZSEi6i1bhbksy8hkMnjttdfaaj825sXuFBpm1WoVjx8/BgAcOXLks2XGido0yjnk8/mMZb+9Wpgby5YP8AbWUc4hcg7zaDjZ7jFvteJnrenpadsBEfXas2e7AIAjRwYcCHnWqOaQ5JOMoSCVj+9Ckj4ds137/08L3/3/Scb/jd9ZbN/fZrI//YCSyT7rjmuyP5jvWzfI9xajmkPkLObR8LFVmF+/ft3Wznd2dmy1JyIi95Ikaf+GM/kYALFf2Ir9AldA7H+vz0EohNErbWwTgED1081CvwNz/xGf/n//+5rt0P/vLK/2+BPRcLNVmNv11ltv4Rvf+EYvD0FERH0yNu7D4SOHcXjiUH0xLmqK8h7Wu0IIo6A+eOz97cYWo33dkBXjscChQ+NcZIiIXKenhXkymWRhTkQ0JI6fOIbjJ1pPz1ZbQONAAW8UzzW95QcL6LpiG8J0e8N+Dr5RqImlsed+fzvnfyYit2kozO/evYv19XWEQiG88MILddvaXVhoZ2eH85j3wNbWluW2ubk5zM3N9TEaIiJzkiR9dpMlEdEI297exvb2tuk2s7quoTA/ffo0SqUSJEnC7u5u3bbXXnvNmMe8HZzH3Fnnz5+33HbhwgVcvHixf8EQERERUVPpdBqXLl1qu31DYf7BBx8YH/PdvXsXJ06cMLbp85hHIhHMzs5a7lTvMb9586aN0KmVq1evYmFhwXQbe8uJiIiI3CUej+PMmTOm27a2tho6XRsK842NDVy+fBnnzp2rK8oBzmM+aAsLCwgEAoMOw9MkScLhicPG90R2MYeoW8whcgLzyBvsDjVuKMwDgQDW19dNGy8tLXEec/I0SZJwlBO+UheYQ9Qt5hA5gXk0nGzNyvL222/b2jnnMSciIiIiag/XbyUiIiIicoGeFeYbGxt45ZVXerV7oo5Uq1Xcu3cP9+7dQ7VaHXQ45EHMIeoWc4icwDwaTj1bYEhVVQ5lIVeqVrnaH3WHOUTdYg6RE5hHw6euMH/jjTccK6ZzuZytG0WJiIiIiEZZXWF+7do13Llzp245YzOSJDVto29njzkRERERUXvqCvPZ2Vk899xzSCQSlgsIXbt2DZqmIRwOm24XQhjzoLPHnIiIiIioPXWFuaIoOHv2rOUCQrdu3UI+n7ec51wXi8UQi8WQSqWci5SIiIiIaIjVzcoSCASwtLRk2fjNN9/E2tpay53KsoxUKoXV1dXuIyQiIiIiGgF1PeaXL19u2rhSqeDEiRNt7Xh+fh6qqnYeGRERERHRCLE1XaIkSb2Kg6gvJEnC5ORR43siu5hD1C3mEDmBeTScbBXmnGWFvE6SJBw6dGjQYZCHMYeoW8whcgLzaDjZWvkzGAzi93//99tq+9Zbb1nO7EJERERERPVs9ZinUinMz88DAP74j//YtM3du3fxh3/4h/j2t7+NYrHYfYREDhJCGHPwS5LEj//INuYQdYs5RE5gHg0nW4X59PQ0Ll++jNdffx3pdBqhUKhurnJVVVEoFADs30j60ksvORrsqNva2rLcNjc3h7m5uT5G401CCNy7dx8AMDV1nC9kZBtziLrFHCInMI+8YXt7G9vb26bbzOo6W4U5sD9H+ezsLM6ePYt8Pl+XCPo7t1QqhW9+85t2d00tnD9/3nLbhQsXcPHixf4FQ0RERERNpdNpXLp0qe32tgtzAIhEIiiXy7h8+TI2NjagqioURUEgEKgb7kLOunr1KhYWFky3sbeciIiIyF3i8TjOnDljum1ra6uh07WjwhzYn6c8nU53+nDqwMLCAgKBwKDDICIiIqI22B1qbGtWFiIiIiIi6g0W5kRERERELsDCnIiIiIjIBViYExERERG5QMc3fxJ5kSRJmJo6bnxPZBdziLrFHCInMI+GEwtzGilcHY26xRyibjGHyAnMo+HEoSxERERERC7gyR5zVVWRSqWgqipkWYamaVAUBclkEoqidLXvUqmE1dVVaJqGnZ0dAICiKFhZWWk5h3gv4yJnCCGwu7sLABgfH2dvA9nGHKJuMYfICcyj4eS5HvNCoYBgMAi/3498Po9sNot8Po9wOAy/349MJtPxvtfW1rC6uopUKoV8Po9isWisbBoMBpFMJgcSFzlHCIGHDx/h4cNHEEIMOhzyIOYQdYs5RE5gHg0nTxXmmqYhHA7j7NmzSCQSddsikQhSqRTi8ThKpZLtfedyOdy4cQPZbLaud1uWZWSzWQD7hbtZgd3LuIiIiIhoNHRcmL/77rt46623sLKyUvf7t956C3fv3u06MDPLy8sAYNlzHYvFAADRaNT2vtPpNHK5HMLhcMM2RVEgy7LRrp9xEREREdFosF2Y3759G6dOnUI4HEYikcDa2lrd9sXFRUQiEfzwhz90LEhgv1c6l8sBgOV4bVmWEQgEoKqq7d5pVVUB7A9J0TStYbt+zIP77XVcRERERDQabBfmoVAIxWIRp0+fRiqVwuLiYt3206dP4/r161hdXXW053x9fR2AdfGrm52dBQBcu3bN1v6TySRkWUYsFjN6x2vpxfrB4/c6LiIiIiIaDbZmZXnzzTchyzIqlQqmp6cBAOVy2bTt22+/jWQyiT/5kz/pPkoAxWIRAEyL5lpWPdutxGIxY8jJQaqqGj3q8Xi8r3ERERER0WiwVZjfunULm5ubdb+zmp5HURSjmHWCPnWh3vPcipPHTqVSAPY/LTh4c2c/46pWq6hWq6bbahcaEEK0vEPb5/vswxK77a1iMIvFbvt2YnHqXK3ictO58jq1176f51qtVhtyyCuxO9Hey+fqltj1HOJ1ah2L12Lv97k2+3vG6+Rc+16dq9k2z8xjbjbuuxm9YO5GqVRCOp3G+vo6UqlUQ1He77jee+8mHjx4aLrt6NEjGB/fv5y7u7t49OgxAODkyZM4efJkQ/vp6RPG90+fPsXjx08sjzs2Pobjx44ZPz9+/BjPnu1atj88cRhHjxwxfn7w4AGqVesknpw8ikOHDgHYT/h79+5btgWAqanjxj+o3d1dPHz4yLKtzydhamrK+PnJk6d4+uwpAOD+/cY3locOjWNyctL4+eGjR9jb3bPc/5EjE5iYmDB+bhX7sWOTxnXa29uzvJ66Ub1Oj588wdMnTy3bD/I6CSEacojXyRz/PZlfp/0/6sL4483rVM8t1wlw97+nR48eN/17xutkrRfX6aOPPsJHH32E8fExHD161Ph9s39PP/nJTxp+Z6swt1uEOjmvZrsFrT6kxG6steLxOFRVxc7ODkqlEhKJBCKRyMDjisWWbT8mmXyzYeacUSb5JEwcnmjdkMiCJDGHqDuSJGFyctIoJFr1BhKZ4d8zd/nud7+LVOpy1/uxVZgLIfDjH/8YX/7yl+t+Z2ZlZQV+v7+76Abk4JSI0WgUfr8fkUjEmNN8EL73ve/hi1/8ouk2q49l5ubmMDV1vOl+Dx8+bPyBaMeRI0dQ80bWNJZax2reJbdqL0lSy3hr24+Pj7dsX+vIxAQmDh9uu/1kzbveVrEAsBX72NiYrdh5nazxOpm353WyxutkjdfJvD2vkzVeJ+AP/uD/gUjkVQDtD2V5//338fWvf73ud7YK81gshpdffhm5XA5f+cpXAJiPMf/2t7+NtbU148ZIJ7Q7hlvvkW51M6Yd2WwWfr8fuVwOwWCw7rz6GdeXvvQlBAKBjh9v5eBYrlZqE87p9nZj6XV7L5+rl2MfpXP1cuyjdK5ejn2UztXLsY/SuXo5dqv2zz//PJ5//vm29wOYn5etZyYSiSAQCCAUCuEf/IN/gJWVFWxubuI73/kO3nrrLbzxxht47rnn8Oabb+Kb3/wmXnrpJVsBNmO3oG23YG6XPhtLqVSqm7t90HGRPUIIPHr8GI8eP+YSxtQR5hB1izlETmAeDSfbN3/mcjlEIhFcv34d+XweQP0UgkIIJBIJXL7c/TibWnpB22pMt77dbsGsLxJkNZa8dp7yfD5v3Aja67jIWUII46aNicOHbb1LJgKYQ9Q95hA5gXk0nGwvMDQ9PY18Po+3334bi4uLxnhmIQQWFxeRz+cdL8oBIBgMAmg93aC+PRQKtb3vZDKJaDSKaDTasJKprragri3CexkXEREREY0O24W5LhaLYXNzE9VqFZVKBdVqFZubmzh9+rST8RnOnj0LoPWsJvr2cDjc9r5ri2qrBZNqj7u0tNSXuIiIiIhodHRcmNfSVwHtJVmWjd7mQqFg2kZfoVNRFMueabMCWi+WQ6EQksmk6eP0YTvA/iwtTsdFRERERKPNkcJcd/fuXSd310CfxvDgdIbtbp+ZmcHMzAwymUzd78+ePQtFUZBMJuvGkus0TTMeE4vFGorrbuMiIiIiIrJVmL/xxhuW265cuYLXXnsNX/3qV3Hq1Cm89dZbXQd3kKIoyOfzyOVyDWPB9d+l02nTXulCoWD0lh+ci1yWZeTzecTjcSSTybqhLaqqGsNzYrGYaXHdTVxERERERAAgCRtz7IyNjWFvz3qZ3lpXrlyBqqpYXV3tODgrqqoilUphc3MTiqJA0zTIsoyVlZWm83yHw2Goqtq0SM7lckin09jZ2TH2u7S0hHg83nIO8U7jaqVUKhnzp/diHvNRUq1WjaV6p6aO255LlYg5RN1iDpETmEfeZ1bf2SrMfT6fraWDX3nlFbzzzjv2I6U6LMydU61W8fjxYwD7K4/xhYzsYg5Rt5hD5ATmkfeZ1Xe25jG3M0fmnTt3sLm5aS9Coh7z+XyYnJwcdBjkYcwh6hZziJzAPBpOpoX57du3G2Yv0TvWf/zjHzddYWpnZ8cY0lE7rSAREREREVkzLcyLxSLy+Tw2NzdRKpWMnnIhRNtDKaanpxtusiQiIiIiInOmhfmrr76KV199FcD+VIHJZBJXrlyBJEmYn59vukNZlqEoClKpVMu2RP1WrVbx8NEjAMDk0aMck0e2MYeoW8whcgLzaDi1HGMuyzLS6TT8fj9WVlbwwQcf9CMuop7Z221vZiEiK8wh6hZziJzAPBo+bb+9SiQS7AEnIiIiIuoRW597cOVKIiIiIqLesDVdor4CppX33nsPy8vLeO655yDLMq5cuYITJ050FSB9Zmtry3Lb3Nwc5ubm+hgNERERETWzvb2N7e1t021mdZ2twryVxcVFY+5yVVURjUa5wJCDzp8/b7ntwoULuHjxYv+CISIiIqKm0uk0Ll261HZ7RwvzWrdu3UKhUOjV7kfS1atXsbCwYLqNveVERERE7hKPx3HmzBnTbVtbWw2drh0V5isrK8jlclBVtWm7UCjUye7JwsLCQtvzyBMRERHRYNkdamy7MH/jjTfaugk0Ho/j8uXLdndP1FOSJOHIkQnjeyK7mEPULeYQOYF5NJxszcqysbGBdDqNWCyGfD6PSqWCWCyGcrmMSqWCSqWCYrGIRCIBWZYxPT3dq7iJOiJJEiYmJjAxMcEXMuoIc4i6xRwiJzCPhpOtHvNMJoNsNmusCgrsL0AkSZJRhC8uLmJxcREbGxv4zne+g9dee83ZiImIiIiIhpCtHvNKpVJXlAOA3+9HqVRqaHv69GkUi8XuoiMiIiIiGhG2CvOZmZmG34VCIVy7ds20PYeykNtUq1XcuXMXd+7cRbVaHXQ45EHMIeoWc4icwDwaTrYKc03TGn43Pz+PYrGIDz/8sGHbnTt3Og6MiIiIiGiU2CrMFxcX8e6772JlZQUvvvgi/uzP/gzA/rCVUChUV5y/9957xmJDRERERETUnK2bP1dWVnD69GljTPnbb7+N3/md30EymcSVK1egKIoxd3mhUEAikXA+YiIiIiKiIWSrx3x6ehobGxtYXl5GIBAwCm9FUfD2229DCIFCoYB8Po/p6WmsrKz0JGgiIiIiomFje4Gh6elp0wWGYrEYFEVBJpPB7OwskskkTpw44UiQRERERETDznZh3kwoFDKGshARERERUftsDWUhIiIiIqLecLTH/O7duxy+Qq4mSRKOHZs0vieyizlE3WIOkROYR8PJVo/5G2+8YbntypUreO211/DVr34Vp06dwltvvdV1cEROkyQJ4+PjGB8f5wsZdYQ5RN1iDpETmEfDyVZhnslkLLctLy9jfX0d169fx40bNzgrCxERERGRDbaGsggh2m67vLyMV155xXZAZG1ra8ty29zcHObm5voYjTcJIbC3twcAGBsbYy8D2cYcom4xh8gJzCNv2N7exvb2tuk2s7rOVmFu56LfuXOHK3867Pz585bbLly4gIsXL/YvGI8SQuDBg4cAgKmp43whI9uYQ9Qt5hA5gXnkDel0GpcuXWq7vWlhfvv2bWiaVvc7vbf8xz/+cdOe852dHaiqilQqhaWlpbYDodauXr2KhYUF023sLSciIiJyl3g8jjNnzphu29raauh0NS3Mi8Ui8vk8Njc3USqVjHdhQggEAoG2ApmenkY2m7UTO7WwsLDQ9vNPRERERINld6ixaWH+6quv4tVXXwUAaJqGZDKJK1euQJIkzM/PN92hLMtQFAWpVKplWyIiIiIi2tdyjLksy0in0/D7/VhZWcEHH3zQj7iIiIiIiEZK29MlJhIJ9oATEREREfWIrXnM0+l0r+IgIiIiIhpptgrz06dP9yoOIiIiIqKRZmsecyt3794FAJw4ccKJ3RH1jM/nw/Q085Q6xxyibjGHyAnMo+FUV5i/++67DfOX6772ta/V/Xz37l0kk0msr68bj5FlGefOncMf//Ef9yRYIiIiIqJhVVeYF4tFJJPJunnLw+EwwuFw3YNu3bqFpaUlaJpmLDakKAp2dnbw9ttvY319HRsbG/jyl7/cp9MgIiIiIvK2ujHm3/zmN1EsFiGEwDe/+U1UKhW88847+MY3vmG0uXPnDoLBICqVCoQQiEQiqFQq+OCDD7Czs4MPPvgAi4uLiEQifT8ZolaEEHjy5AmePHnSdAVbIivMIeoWc4icwDwaTg03f7755pvI5/O4fPkypqenGx6QyWSgaRokSUI8Hsf6+npdO0VRkM/nMT8/j7feequ30RPZJITA48dP8PgxX8ioM8wh6hZziJzAPBpOdYX597//fSwuLjadfaV2ysRUKmXZ7vLly8jn8w6ESEREREQ0/OrGmGcymaZzld+5cweqqkKSJAQCgaazsAQCAWxubjoXKRERERHREKvrMVdVFS+88IJl49pCe2lpqeXO+dEKEREREVF7bC0wVDs05eBMLQfduXMHs7OznUVFRERERDRi6grz6elpY7EgM7lczvg+FAo13XGhUGjZhoiIiIiI9tWNMV9aWsLly5fxh3/4hw0NNzY22h5fDuzf/HnlyhVnox1xW1tbltvm5uYwNzfXx2iIiIiIqJnt7W1sb2+bbjOr6+oK88uXL0NRFPj9fvze7/2e8fubN28iGo0aPzebjQUAvvOd72B+fh4vvfSSndiphfPnz1tuu3DhAi5evNi/YDxsbHxs0CGQxzGHqFvMIXIC88j90uk0Ll261Hb7usJclmVkMhmcPXvWKNJ3dnZQKpWMGzkTiQRefvllyx1++9vfNuZCJ2ddvXoVCwsLptvYW94en8+H48eODToM8jDmEHWLOUROYB55Qzwex5kzZ0y3bW1tNXS6jh9sFIlEsLm5ieXl5briWpZlpFIpLC8v17W/c+cOVldXcevWLRQKBVQqFQD7N4cmEgmsrq52fVK0b2FhAYFAYNBhEBEREVEb7A41bijMgf05yIvFIu7cuYPNzU0oioL5+XnTHUxPTxsztMRisQ5CJiIiIiIi08JcNz093XQVUF07bYjcoFqt4vHjxwCAI0eOwOezNWMoEXOIusYcIicwj4YTryKNnGfPdvHs2e6gwyAPYw5Rt5hD5ATm0fBhYU5ERERE5AIszImIiIiIXICFORERERGRC7AwJyIiIiJyARbmREREREQuwMKciIiIiMgFms5jTjRsJEnC4YnDxvdEdjGHqFvMIXIC82g4sTCnkSJJEo4eOTLoMMjDmEPULeYQOYF5NJw4lIWIiIiIyAVYmBMRERERuQCHstBIqVarePDgAQDg2LFj8Pn43pTsYQ5Rt5hD5ATm0XBiYU4jp1oVgw6BPI45RN1iDpETmEfDh2+viIiIiIhcgD3mHrK1tWW5bW5uDnNzc32MhoiIiIia2d7exvb2tuk2s7qOhbmHnD9/3nLbhQsXcPHixf4FQ0RERERNpdNpXLp0qe32LMw95OrVq1hYWDDdxt5yIiIiIneJx+M4c+aM6batra2GTlcW5h6ysLCAQCAw6DCIiIiIqA12hxrz5k8iIiIiIhdgjzmNFEmSMDl51PieyC7mEHWLOUROYB4NJxbmNFIkScKhQ4cGHQZ5GHOIusUcIicwj4YTh7IQEREREbkAe8xppAghIMT+SmmSJPHjP7KNOUTdYg6RE5hHw4k95jRShBC4d+8+7t27b7ygEdnBHKJuMYfICcyj4cTC3CHBYBDxeByFQgGapgEANE1DqVRCJpNBOBxGoVAYbJBERERE5FqeHMqiqipSqRRUVYUsy9A0DYqiIJlMQlGUrvZdKBSQTqdRKpWgqioCgQCWlpZa7ltVVaMIN5NIJBAKhbqKjYiIiIiGl+d6zAuFAoLBIPx+P/L5PLLZLPL5PMLhMPx+v2Vh3I5kMolUKoWVlRWUy2VUKhXE43FkMhn4/X4kk0nb+1QUBdlsFqlUquO4iIiIiGj4earHXNM0hMNhxGIxJBKJum2RSASpVArxeBxLS0u2V8jMZDLQNA35fN74nSzLiMViWFpaQjAYxNraGvx+P2KxmOk+8vk8VFVFuVzGqVOnoCgKV+okIiIiorZIwkN3DESjUeRyOZTLZdNhJZqmYWZmBoqioFwut71fTdMwPz+PSqXS8tgAUKlUIMty3faZmZmmj+9GqVRCMBhEsVhkod+larWKe/fuAwCmpo7D5/Pch0Y0YMwh6hZziJzAPPI+s/rOM1dR0zSjMLYa6y3LMgKBgDHeu12bm5vQNA1+v9/ycefOnTO+502cREREROQ0zxTm6+vrAKyLct3s7CwA4Nq1a23vW1VV4//pdNq0TW1P9Y0bN9reNxERERFROzwzxrxYLAJAwxCSg/TC3U6Pee1sKeFw2LSNPgViK5qmYX193Yg3HA4jEom0HQv1liRJmJo6bnxPZBdziLrFHCInMI+Gk2cK852dHQCf9Yi3oveCt0NRFGN8uFXhv7m5aXx/6tQp0zaZTAb5fB4rKys4e/YsdnZ2EI/Hsbq6io2NjZZvKlqpVquoVqum22pX/apdDcxK7Vg0u+2tYjCLxW77dmLp5lxrWT3WTec6qtfJK+eqb/Ni7J229/K5ejn2UTpXL8fez3OtbWv2WF4n59r36lzNtnmmMG+3x1qnF/LtalU0Z7NZo51VD3i5XDba6W2z2Szm5+cxPz+PW7dudVWcv/feTTx48NB029GjRzA+vn85d3d38ejRYwDAyZMncfLkyYb209MnjO+fPn2Kx4+fWB53bHwMx48dM35+/Pgxnj3btWx/eOIwjh45Yvz84MEDVKvWSTw5eRSHDh0C8NlKZs1MTR03/kHt7u7i4cNHlm19PglTU1Ofxf7kCZ4+eWrZ/tChcUxOTho/P3z0CHu7e5btjxyZwMTEhPFzq9iPHZs0rtPe3p7l9dTxOpnjdeJ1AnidrPA68ToBvE7N9OI6ffTRR/joo48wPj6Go0ePGr9vdp1+8pOfNPzOM4V5u4W2XvjaLeSbKZVKxg2fV65cMW2TSqVMp1HUp1xcW1vD6upqV/OZx2LLth+TTL6JlZWVjo85dITAXnX/H4jP54MEfvxH9ggIo5eDOUSdEBB4trtflOiFEJFt/HvmKt/97neRSl3uej+emS4xGAyiVCohFArVzTV+UDKZxNraGgC0/KihXX6/31ht9OD86e0oFArG2HWzqRZb0afT+d73vocvfvGLpm2sPpaZm5vD3NxcQ/tR/Qhqb2/PeCd9/Pgx02EubjrXUb1Obj7XarWK+/cfAPgsh7wSuxPtvXyuboldzyF9jLAkSbxOFrF4LfZ+nuvu7m7Da5FVLACvUzft2znX7e1tbG9vN7RvFvv777+Pr3/963XTJXrmrXq7Y8v1nvJux3Pr4vE4VFVFIpHoqCgH6meSKRQKHd8M+qUvfakn85gf/AfQit25Uu20txtLN+0PFlRmvHyuXo7d7efaLIfcHvsg23v5XJ2OvfbYvE7Otfdy7J2ca6/+nvE62W///PPP4/nnn297P4D5eXmmMLdbaLdbyDeTy+WQyWQ67ik3i8XOTalERERENDo8M4+5Xty2Gmuub++2x7xQKCAajSKbzTYtylVVhd/vRzAYbGtcu50VSYmIiIhodHimMA8GgwBa9zjr22vnJrerVCohGo0in8+bDjupjaFQKBgrjeqLIDXj1BAbIiIiIhouninMz549C6D1bCv6dquFglpRVRXRaBQbGxumxX2pVKpbHVTvyQ8EAkaMB9XOgd5pXEREREQ03DxTmMuybBTK+tSFB6mqClVVoSiKZY95s8Je0zSjp9zqJstCoVC3wFAoFEIoFEKxWLTsDddnkQkEAl315BMRERHR8PLMzZ8AkE6n4ff7kU6nTQtcvSe7tke71szMDDRNQzqdbphzXNM0BINBxONxlEollEqlhsfv7OwgnU43LCIUDoeRyWRM5zFXVRWZTAYA6h5Hg+Pzca5X6g5ziLrFHCInMI+Gj6cKc0VRkM/nEQ6Hsba2VndTZi6Xw9rammXRXigUjN7ybDbbUESfPn0aqqoimUy2jONgb3oikUA0GkWxWEQqlTJ6zkulEk6fPo3Z2VlsbGzUTZtIg+Hz+epW8CKyizlE3WIOkROYR8PJU4U5sD90pFwuI5VKIRgMQlEUaJoGWZbrJmg3e1woFDItvjOZjGkPuRmr4SrZbBa5XA7Ly8vGvhRFwcrKSldTLRIRERHRaPDMyp+jTF/5s9kbDyIiIiLyDrP6znM95kTdEELg8ZMnAIAjExO2VvsiAphD1D3mEDmBeTScPDMrC5EThBB4+uQpnj55Cn5YRJ1gDlG3mEPkBObRcGJhTkRERETkAizMiYiIiIhcgIU5EREREZELsDAnIiIiInIBFuZERERERC7A6RI9ZGtry3Lb3Nwc5ubm+hgNERERETWzvb2N7e1t021mdR0Lcw85f/685bYLFy7g4sWL/QvGww4dYtpTd5hD1C3mEDmBeeR+6XQaly5dars9r6iHXL16FQsLC6bb2FveHp/Ph8nJyUGHQR7GHKJuMYfICcwjb4jH4zhz5ozptq2trYZOVxbmHrKwsGAs2UpERERE7mZ3qDFv/iQiIiIicgH2mNNIqVarePjoEQBg8uhR+Hx8b0r2MIeoW8whcgLzaDixMKeRs7e7N+gQyOOYQ9Qt5hA5gXk0fPj2ioiIiIjIBViYExERERG5AAtzIiIiIiIXYGFOREREROQCLMyJiIiIiFyAhTkRERERkQtwukQaKZIk4ciRCeN7IruYQ9Qt5hA5gXk0nFiY00iRJAkTExODDoM8jDlE3WIOkROYR8OJQ1mIiIiIiFyAhTkRERERkQtwKAuNlGq1inv37gMApqaOw+fje1OyhzlE3WIOkROYR8OJV5GIiIiIyAXYY+4hW1tbltvm5uYwNzfXx2iIiIiIqJnt7W1sb2+bbjOr61iYe8j58+ctt124cAEXL17sXzBERERE1FQ6ncalS5fabs/C3EOuXr2KhYUF023sLSciIiJyl3g8jjNnzphu29raauh0ZWHuIQsLCwgEAoMOg4iIiIjaYHeoMW/+pJHz0UcfYXV11XLMF1ErzCHqFnOInMA8Gj4szGnkfPTRR0ilLvOFjDrGHKJuMYfICcyj4cPCnEaKJEk4evSI8T2RXcwh6hZziJzAPBpOLMxppEiShPHxceN7IruYQ9Qt5hA5gXk0nFiYExERERG5AAtzGilCCOzu7hrfE9nFHKJuMYfICcyj4cTCnAzb29u4ePFiX28i6fcxhRB49Oix8X2/jMJzOyrHZA7xmN1iDg3fMQdxXObR8B0TYGFONba3t3Hp0qW+J36/jzkIo/LcjsoxB2FUnttROeYgjMpzO6jryTziMZ3AwpyIiIiIyAVYmBMRERERuQALcyIiIiIiF2BhTkRERETkAizMiYiIiIhcYHzQAVBrjx49AgBsbW319Dj6/nt9nEEes1qt4ic/+QkA4P3334fP15/3pqPw3I7KMZlDPGa3mEPDd8xBHJd55P1j6vvW6zwAkARnpXe9P/3TP8X58+cHHQYREREROezq1av43d/9XQAszD3h448/xjvvvIMXXngBR48eHXQ4RERERNSlR48e4fbt23jllVfwuc99DgALcyIiIiIiV+DNn0RERERELsDCnIiIiIjIBViYExERERG5AAtzIiIiIiIXYGFOREREROQCLMyJiIiIiFyAhTkRERERkQuwMCdqUzAYRDweR6FQgKZpAABN01AqlZDJZBAOh1EoFAYbJBENNb4OEQ03LjBErqSqKlKpFFRVhSzL0DQNiqIgmUxCUZSu9l0oFJBOp1EqlaCqKgKBAJaWllrue2ZmxvhDaCaRSCCVSnUVGzmnlzlUKpWwuroKTdOws7MDAFAUBSsrKwgEAgOLi5zlxhzi65D3DOLfvN/vRzabbZpLfC1yKUHkMvl8XsiyLFKpVN3vs9msACDS6XTH+04kEiIUColisSiEEKJSqYh0Oi0ACAAikUhYPlaWZaNd7ZeiKCKbzXYcEzmvlzmUSqVEJBIR5XLZ+F2lUhGBQKBlDvUyLnKWW3OIr0PeMoh/87FYTAAQ+XzeVXFRe1iYk6tUKhUBQMRiMdPtqVRKADAKazvS6bTlfovFovEHzuoFSZZlkc/nRTqdFolEQmSz2Y7ioN7qZQ5ls1kRiURMt5XL5aY51Mu4yFluzSEh+DrkJYP4N5/P540csirM+VrkbizMyVUikYgAUNeTVEt/QVEUxdZ+K5WKkGW5rWMDEJVKpWF7q8eTO/Qqh4QQIhQKCQAiFAqZbtd7MwOBQF/jIme5NYf07eQNg/g3HwqFjByyKsz5WuRuLMzJNfQXg1YjrPSPe+28m9d7ERRFsXyc/hEeANOPhPkH0f16mUNCCKEoStM3b/p+Dx6/13GRc9yaQzq+DnnDIP7Nx2IxUSwWmxbmfC1yP87KQq6xvr4OAC1vOpmdnQUAXLt2re19q6pq/D+dTpu2qb1J5saNG23vm9yjlzkEAMlkErIsIxaLQZblhu36TXkHj9/ruMg5bs0h8pZ+/5vP5XKQZbnlzed8LXK/8UEHQKQrFosAYPrHqpb+glIqldredygUMr4Ph8OmbZrNdHCw3fr6uhFvOBxGJBJpOxbqnV7mEADEYjHEYjHTbaqqGm8A4/F4X+Mi57g1hw7i65C79fPfvKZpSKfTyOfzroqLOsPCnFxDnzJMf6feiv4HrB2KoqBSqQCwfkHa3Nw0vj916pRpm0wmg3w+j5WVFZw9exY7OzuIx+NYXV3FxsZGyxc76q1e5lAr+hR1oVAIiUTCNXGRPW7NoVp8HXK/fubR8vJy21Nk8rXI/ViYk2u022Ot019g2tXqj1U2mzXaWfU8lctlo53eNpvNYn5+HvPz87h16xb/KA5Qr3PITKlUQjqdxvr6OlKplGlBNYi4qDNuzaFafB1yv37lUS6Xw6lTp1oOYdHxtcj9OMacXKPdFwD9D47dF5hmSqWSsVrelStXTNukUinTXgl9vKimaVhdXXUsJrKvnzkUj8cRDoexvLyMTCaDWCxm+YZukLlN9rg1h3R8HfKGfuSRPoSl1Ru5fsdF3WFhTgQgGo0C2P+jZ/WH0WpcKPDZuPW1tTW+kI0IfUxnsViEEAKqqsLv9xu5RNRKJznE1yHSLS8vW05mQN7Fwpxco90xb/ofHKc+qo3H41BVFYlEwlbPQ63aO9z1nnfqv0HlELA/FEpRFORyOQSDQdfERfa4NYfawdch9+h1HmUyGYTDYduz9/C1yP1YmJNr2H0BaPcFpplcLodMJmP58XAnsfBmmcEZRA7V0mfSKJVKWFtbM34/6LiofYO+VlY5ZDcWvg4NVi/zSFVVZLPZpp+eWBl0flNrLMzJNfQXgFZj4PTt3b6TLxQKiEajyGazTXvK9Y+Xg8FgWx8Pl8vlruKizvU6h3K5HHK5nOX22t6r2qnL+p3b1Dm35hBfh7yll3kUj8frbv51S1zkDBbm5Br6R7etenr07bVzk9tVKpUQjUaRz+dNx5TXxlAoFKCqKkqlkrE4QzN8IRucXuZQMplENBpFNBq17Mmsvfa1f/j6mdvUHbfmEF+HvKVXeaSqKgqFAubn5zEzM2P6pb9xC4fDxu/0oU18LXI/FubkGmfPngXQ+i7w2hedTqiqimg0io2NDdMXHX3qMp3ewxAIBIwYD6qdA73TuKh7vcyh2j9kVr2RtcddWlrqS1zkLLfmEF+HvKVXeaQoCoQQqFQqll+6fD5v/E7/W8fXIg8QRC4SCoUEAJHP5023l8tlAUAoimK5j0ql0nRbIBAQ5XLZsk0qlRLZbLbuMaFQqGnciURCABCBQKBpO+q9XuVQOp0WAEQoFLLMn1gsJgCYHt+JuKg/3JhDfB3ynl7/PbNi9RrkZFzUOyzMyVX0F4RIJGK6Xf/DY/WCIsuyACDS6XTDtkqlIhRFMQpvs690Oi0URRHFYrHusalUynSfesz6cZsV/NQfvcohPX+sHlepVIw/iLFYzPG4qH/cmkN8HfKWXv49s1KbQ60Kb74WuRMLc3KdfD4vAIhUKlX3+2w22/RFSn+c3iN1UCAQMLa3+jITiURELBar68EoFotClmXTYp4Gp1c5VC6XhaIoIpFI1BU/5XLZyC+zgqrbuKj/3JpDfB3yll7lUavjARCJRMLxuKj3JCGEsD8Ahqi3VFVFKpXC5uYmFEWBpmmQZRkrKytNlx4Oh8NQVRXpdLpu/HgmkzGmIWtFluW6cXq1crkcrl27hlKpBGB/vF84HO54/nPqHadzqFYul0M6ncbOzo6x36WlJcTj8ZZLY3caF/WfW3OIr0Pe0ss80tXe9Hlw1U5ZlrGxsdFwLL4WuRMLcyIiIiIiF+CsLERERERELsDCnIiIiIjIBViYExERERG5AAtzIiIiIiIXYGFOREREROQCLMyJiIiIiFyAhTkRERERkQuwMCciIiIicgEW5kRERERELsDCnIiIiIjIBViYExERERG5AAtzIiIiIiIXYGFOREREROQCLMyJiIiIiFyAhTkRERERkQuwMCciz9M0DfF4HMFgEH6/H36/H+FwGLlczmiztraGQqEwwCi9I5lMIhwOw+/3Y2ZmBvF4fNAhERGNBBbmRORpuVwO8/PzkGUZGxsbKJfLKJfLSKfTuHHjBsLhMEqlEpLJJDRNG3S4nnDu3DlEo1EA+296dnZ2TNuVSiXMzMwgGAzyuW3DsD9fa2tr8Pv9gw6DyNNYmBORZ5VKJUSjUaRSKaRSKciybGxTFAWpVArJZBLBYLDlvnK5HFRV7WG0gzlWJwKBAGKxGJLJZNN2q6ur0DQNpVIJ6+vrfYrOu4bx+VJVFZlMBsFgEMlk0vJNHBG1h4U5EXnW8vIyFEVBLBazbBMKhZBIJFruK5/P960Xs5/H6sbs7GzT7efOnTO+D4VCvQ7H84bp+SoUCpiZmUE0GkW5XK47NyLqHAtzIvIkvedRUZSWbVdWVlq22dzcdCKstvTzWL0UiURQqVQghGjrOoy6YXq+QqEQKpUKisUiUqkUAoHAoEMiGgoszInIk/Titp2PzmVZbtpDqRf5/dDPY/VD7fAhao3PFxE1w8KciDxJ73EslUptFbrhcNhyW6ux1E7q57GIiMhbWJgTkScpimL0Pp4+fbrlVIiJRAKRSKTh92tra8hkMr0IcaDHIiIi7xkfdABERJ1KpVKIx+PQNA3hcBiKoiASiSAcDmNpaanpsIFCoYB4PF43O8rB2VtisRjS6XTDYzVNw+rqKkqlEmRZhqZpkGUZ8XjcdMhMN8cC9mdx0bfp56TPOtMtTdOQTCaxublp3Owpy3LLfcfjcWxubhrTKV65cqXujU84HMbOzo6xfWNjA4FAAJlMBtlsFrIsG/cI1I5RVlUVqVQKOzs7UFXVmKO+1Q28dp6jTmOzeu70HKjd/+rqKrLZrPHJTqvnq5aqqkgmk1BVFbOzs9jZ2YGiKJb55dT5EJELCCIiD0skEgKA6ZeiKCKVSolKpdJ0H4qiCACiWCy2PF6lUhGBQEDk8/m632ezWQFAxGIxR48VCoWELMsN7QOBgFAURZTL5Zb7sZJOp4Usyw0xVyoVEYvFRCQSEQBEJBJpeGw+nxfpdNp4rrPZbNPt+XxexGKxhnaBQMB4PorFoohEInXXS39ezWLQY7X7HHUS20HFYtHy+Y/FYgJA3bZWz5culUoJWZYb8qtYLJpeK6fOp1v5fF4AELIsO75volHCwpyIPC+fzxtFh9mXLMtNC1g7xbJedCUSCVvbOjlWKBQyCq2DKpWKACACgUDL/Zhp542EfnyrolgIYRTvVoVm7T7M2tQW3qFQyHQfsiw3FLoH99/Jc2QntoMCgUDT62yVc82eL/1NplVulMtlAcDyeermfLrFwpzIGRxjTkSeFwqFUCwWUalUkM1mEYvF6j6u1zTNsdUW9dlgcrlcwzZ9tUyzbXZlMhkUCgWEQiHT4Qv6TDOlUqnl+PqDVFU1YrUaPgM0v2FW12quc31YiaqqpkM39KEeuVzO8sZYvc3BRZm6fY7ajc3s5uJWNx1bzQJk9XyVSiWsra0hEAhYDjXRh2oVCgXTexW6OR8icgcW5kQ0NGRZRiQSQTqdNgp1ffEhfTxwt1KpFEKhkOnY5aWlJQCNBWQn9IK52XhgvXC2W2jpsfdzkRv9uWmmVTF78I2VU89Rq9jMpuQMhUIoFAoIBoPIZDIN1/zKlSu25ipfXl429tuMvpBPs1zu5HyIyB148ycReZZ+06UVWZaRTqexs7ODXC6H9fX1pj3E7TjYO6uqKgqFAsrlsqOreeqFpH7jqBm99/6TTz6xtW+997ifi9z4/f6m2zuZ39up56hVbGbS6TSCwSBKpZJxbL2H3uomzWb0c2n3edI0Daqqml7DTs6HiNyBhTkReVKhUEA+n29rZpIrV64gl8tB07SWxXw79JlDCoUCAoEAzp07ZxRiTkyHWFvgx+Nxo9ffKU706Nvl9MI6Tj5HncSmKApu3bqFTCaDdDptzCCTy+WQy+UQiUSQzWbb2ped61E7FMaqMOciRkTexaEsRORZ7RY0six31DtsVmRnMhn4/X7jjUE2m0UkEoGiKC3HW7d7rNrCysleeJ3Xl4MHev8ctRtDIpFAuVyGEALFYhGJRAKyLCOXy2Ftba2t/djJm9phKN3kGxG5EwtzIvIsOzc97uzsQJZlW72J+Xy+ruirHTKRz+fbKnDbHf998Fj6uOlyudx2vO2qnTPcy3r5HLViNlwkEAgglUqhWCxClmVcu3atrX3VvnFsdS6114zzkRMNHxbmRORZmqa11SupDzM4e/as6Xa9WD94U9zBYS/6+PRQKGRalJsVuvpNfXaPpQ/RWV9fN41ZVygU2u6ZPbjvQqEwsN5mJ/TyOWpFVVXLN12KouDs2bO2nlv9XFrN6JPP5wGg5YJLRORNLMyJyNOSyWTLcd3xeNy4EdSM1XR8B4vnVkMHzHpIDz6m3WOFQiEkEomWbz5SqZTt8dW1K2Kurq6attFXN21Fj7vVTB/dvAGw2rdTz1GnsTWbGWVnZ8f0BlCr5ysSiSASiRg3E5splUrI5XJGz7yVQbzZ0o/p5Td6RK4w6InUiYg6oS9oks/nRSQSEYFAQGSz2bpVI4vFogiFQkJRlKYL+pTLZSHLslAUxXh8Op0WqVTKtB1MFoHJ5/MikUgYiwzl83lRLpcbFnNp91g6fdGZg4vZlMtlEQqFTBfWaVcqlRIATM8zEokY5wJApNNp02PpCztZLbajL6hktZBR7YqVViu06s+51TE6fY66iQ2fLqZjFlM2mxWyLJueT6vnKxaLCVmWTVdSxaeLA1k9T048152qzZVerCxKNCpYmBORJ+mFsK5YLIpYLCYURRGyLAtZlkUoFLIseA/Si3j9cVaFU6VSEYlEQgQCARGLxYxiPJ1OG9v1FRhDoZBpAdTusQ6eWygUMr5isZgjxZW+70gkYnwlEglRqVSM5eEVRRGBQKBuxUm9WNYLVP17/fm22q6vwqkX0/p2vY0sy6JYLIpKpWK5D7OVK+08R93GJoQw3lhls1kRCoUanr92j2mWn/q5BAIB43mPRCKWbzCcOB+79OvT6qsXq4wSDTNJCCGc6n0nIiIiIqLOcIw5EREREZELsDAnIiIiInIBFuZERERERC7AwpyIiIiIyAVYmBMRERERuQALcyIiIiIiF2BhTkRERETkAizMiYiIiIhcgIU5EREREZELsDAnIiIiInKB/wuVGRE57aD0rwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "def plot_ntr_at_time(NTR_history, t):\n",
    "    hull = NTR_history[t]\n",
    "    \n",
    "    if hull is not None:\n",
    "        vertices = hull.points  # Vertices are stored in the 'points' attribute of ConvexHull\n",
    "        D = vertices.shape[1]  # Dimension of the state space\n",
    "        plt.figure(figsize=(4,3),dpi=200)\n",
    "\n",
    "        if D == 2:\n",
    "            # 2D plot\n",
    "            plt.fill(vertices[hull.vertices, 0], vertices[hull.vertices, 1], color = colors[1], alpha=0.2,label='NTR')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            plt.scatter(merton_p[0], merton_p[1],label='Merton Point')\n",
    "            plt.legend()\n",
    "            plt.xlabel('State dimension 1')\n",
    "            plt.ylabel('State dimension 2')\n",
    "            x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "            y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "            plt.xlim(x_min - 0.1, x_max + 0.1)\n",
    "            plt.ylim(y_min - 0.1, y_max + 0.1)\n",
    "            plt.grid(alpha=0.5)\n",
    "        elif D == 3:\n",
    "            # 3D plot\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], color='red')\n",
    "            ax.add_collection3d(Poly3DCollection(vertices[hull.simplices], facecolors='lightgray', edgecolors='k', alpha=0.4))\n",
    "            ax.scatter(merton_p[0], merton_p[1], merton_p[2], color='blue', s=100, label='Merton Point')\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('State dimension 1')\n",
    "            ax.set_ylabel('State dimension 2')\n",
    "            ax.set_zlabel('State dimension 3')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "            y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "            z_min, z_max = vertices[:, 2].min(), vertices[:, 2].max()\n",
    "            ax.set_xlim(x_min - 0.05, x_max + 0.05)\n",
    "            ax.set_ylim(y_min - 0.1, y_max + 0.1)\n",
    "            ax.set_zlim(z_min - 0.1, z_max + 0.1)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"Not enough vertices to form an NTR at time {t}\")\n",
    "\n",
    "# Example: Plot NTR at time t=1\n",
    "# plot_ntr_at_time(NTR,int(T/Delta_t)-2)\n",
    "def plot_ntr_at_time_select_dims(NTR_history, t, dims=(0, 1)):\n",
    "    hull = NTR_history[t]\n",
    "    \n",
    "    if hull is not None:\n",
    "        vertices = hull.points  # Vertices are stored in the 'points' attribute of ConvexHull\n",
    "        D = vertices.shape[1]  # Dimension of the state space\n",
    "        plt.figure(figsize=(4,3),dpi=200)\n",
    "\n",
    "        if D == 2:\n",
    "            # 2D plot\n",
    "            plt.fill(vertices[hull.vertices, 0], vertices[hull.vertices, 1], color = colors[4], alpha=0.2,label='NTR')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            plt.scatter(merton_p[0], merton_p[1],label='Merton Point')\n",
    "            plt.legend()\n",
    "            plt.xlabel('State dimension 1')\n",
    "            plt.ylabel('State dimension 2')\n",
    "            x_min, x_max = vertices[:, 0].min(), vertices[:, 0].max()\n",
    "            y_min, y_max = vertices[:, 1].min(), vertices[:, 1].max()\n",
    "            plt.xlim(x_min - 0.1, x_max + 0.1)\n",
    "            plt.ylim(y_min - 0.1, y_max + 0.1)\n",
    "            plt.grid(alpha=0.5)\n",
    "        elif D >= 3:\n",
    "            # Select dimensions to plot\n",
    "            vertices_2d = vertices[:, dims]\n",
    "            hull_2d = ConvexHull(vertices_2d)\n",
    "            plt.fill(vertices_2d[hull_2d.vertices, 0], vertices_2d[hull_2d.vertices, 1], color = colors[4], alpha=0.2,label='NTR')\n",
    "            plt.title(f'NTR at time {t}')\n",
    "            plt.scatter(merton_p[dims[0]], merton_p[dims[1]],label='Merton Point')\n",
    "            plt.legend()\n",
    "            plt.xlabel(f'State dimension {dims[0]}')\n",
    "            plt.ylabel(f'State dimension {dims[1]}')\n",
    "            x_min, x_max = vertices_2d[:, 0].min(), vertices_2d[:, 0].max()\n",
    "            y_min, y_max = vertices_2d[:, 1].min(), vertices_2d[:, 1].max()\n",
    "            plt.xlim(x_min - 0.1, x_max + 0.1)\n",
    "            plt.ylim(y_min - 0.1, y_max + 0.1)\n",
    "            plt.grid(alpha=0.5)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"Not enough vertices to form an NTR at time {t}\")\n",
    "\n",
    "# Example: Plot NTR at time t=1, selecting dimensions 0 and 2\n",
    "plot_ntr_at_time_select_dims(NTR, int(T/Delta_t)-4, dims=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Peytz2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
